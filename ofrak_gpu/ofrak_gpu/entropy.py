# Generated by Futhark 0.22.2
import sys
import numpy as np
import ctypes as ct

# Stub code for OpenCL setup.

import pyopencl as cl
import numpy as np
import sys

if cl.version.VERSION < (2015, 2):
    raise Exception(
        "Futhark requires at least PyOpenCL version 2015.2.  Installed version is %s."
        % cl.version.VERSION_TEXT
    )


def parse_preferred_device(s):
    pref_num = 0
    if len(s) > 1 and s[0] == "#":
        i = 1
        while i < len(s):
            if not s[i].isdigit():
                break
            else:
                pref_num = pref_num * 10 + int(s[i])
            i += 1
        while i < len(s) and s[i].isspace():
            i += 1
        return (s[i:], pref_num)
    else:
        return (s, 0)


def get_prefered_context(interactive=False, platform_pref=None, device_pref=None):
    if device_pref != None:
        (device_pref, device_num) = parse_preferred_device(device_pref)
    else:
        device_num = 0

    if interactive:
        return cl.create_some_context(interactive=True)

    def blacklisted(p, d):
        return (
            platform_pref == None
            and device_pref == None
            and p.name == "Apple"
            and d.name.find("Intel(R) Core(TM)") >= 0
        )

    def platform_ok(p):
        return not platform_pref or p.name.find(platform_pref) >= 0

    def device_ok(d):
        return not device_pref or d.name.find(device_pref) >= 0

    device_matches = 0

    for p in cl.get_platforms():
        if not platform_ok(p):
            continue
        for d in p.get_devices():
            if blacklisted(p, d) or not device_ok(d):
                continue
            if device_matches == device_num:
                return cl.Context(devices=[d])
            else:
                device_matches += 1
    raise Exception("No OpenCL platform and device matching constraints found.")


def param_assignment(s):
    name, value = s.split("=")
    return (name, int(value))


def check_types(self, required_types):
    if "f64" in required_types:
        if self.device.get_info(cl.device_info.PREFERRED_VECTOR_WIDTH_DOUBLE) == 0:
            raise Exception(
                "Program uses double-precision floats, but this is not supported on chosen device: %s"
                % self.device.name
            )


def apply_size_heuristics(self, size_heuristics, sizes):
    for platform_name, device_type, size, valuef in size_heuristics:
        if (
            sizes[size] == None
            and self.platform.name.find(platform_name) >= 0
            and (self.device.type & device_type) == device_type
        ):
            sizes[size] = valuef(self.device)
    return sizes


def initialise_opencl_object(
    self,
    program_src="",
    build_options=[],
    command_queue=None,
    interactive=False,
    platform_pref=None,
    device_pref=None,
    default_group_size=None,
    default_num_groups=None,
    default_tile_size=None,
    default_reg_tile_size=None,
    default_threshold=None,
    size_heuristics=[],
    required_types=[],
    all_sizes={},
    user_sizes={},
):
    if command_queue is None:
        self.ctx = get_prefered_context(interactive, platform_pref, device_pref)
        self.queue = cl.CommandQueue(self.ctx)
    else:
        self.ctx = command_queue.context
        self.queue = command_queue
    self.device = self.queue.device
    self.platform = self.device.platform
    self.pool = cl.tools.MemoryPool(cl.tools.ImmediateAllocator(self.queue))
    device_type = self.device.type

    check_types(self, required_types)

    max_group_size = int(self.device.max_work_group_size)
    max_tile_size = int(np.sqrt(self.device.max_work_group_size))

    self.max_group_size = max_group_size
    self.max_tile_size = max_tile_size
    self.max_threshold = 0
    self.max_num_groups = 0

    self.max_local_memory = int(self.device.local_mem_size)

    # Futhark reserves 4 bytes of local memory for its own purposes.
    self.max_local_memory -= 4

    # See comment in rts/c/opencl.h.
    if self.platform.name.find("NVIDIA CUDA") >= 0:
        self.max_local_memory -= 12
    elif self.platform.name.find("AMD") >= 0:
        self.max_local_memory -= 16

    self.free_list = {}

    self.global_failure = self.pool.allocate(np.int32().itemsize)
    cl.enqueue_fill_buffer(self.queue, self.global_failure, np.int32(-1), 0, np.int32().itemsize)
    self.global_failure_args = self.pool.allocate(
        np.int64().itemsize * (self.global_failure_args_max + 1)
    )
    self.failure_is_an_option = np.int32(0)

    if "default_group_size" in sizes:
        default_group_size = sizes["default_group_size"]
        del sizes["default_group_size"]

    if "default_num_groups" in sizes:
        default_num_groups = sizes["default_num_groups"]
        del sizes["default_num_groups"]

    if "default_tile_size" in sizes:
        default_tile_size = sizes["default_tile_size"]
        del sizes["default_tile_size"]

    if "default_reg_tile_size" in sizes:
        default_reg_tile_size = sizes["default_reg_tile_size"]
        del sizes["default_reg_tile_size"]

    if "default_threshold" in sizes:
        default_threshold = sizes["default_threshold"]
        del sizes["default_threshold"]

    default_group_size_set = default_group_size != None
    default_tile_size_set = default_tile_size != None
    default_sizes = apply_size_heuristics(
        self,
        size_heuristics,
        {
            "group_size": default_group_size,
            "tile_size": default_tile_size,
            "reg_tile_size": default_reg_tile_size,
            "num_groups": default_num_groups,
            "lockstep_width": None,
            "threshold": default_threshold,
        },
    )
    default_group_size = default_sizes["group_size"]
    default_num_groups = default_sizes["num_groups"]
    default_threshold = default_sizes["threshold"]
    default_tile_size = default_sizes["tile_size"]
    default_reg_tile_size = default_sizes["reg_tile_size"]
    lockstep_width = default_sizes["lockstep_width"]

    if default_group_size > max_group_size:
        if default_group_size_set:
            sys.stderr.write(
                "Note: Device limits group size to {} (down from {})\n".format(
                    max_tile_size, default_group_size
                )
            )
        default_group_size = max_group_size

    if default_tile_size > max_tile_size:
        if default_tile_size_set:
            sys.stderr.write(
                "Note: Device limits tile size to {} (down from {})\n".format(
                    max_tile_size, default_tile_size
                )
            )
        default_tile_size = max_tile_size

    for k, v in user_sizes.items():
        if k in all_sizes:
            all_sizes[k]["value"] = v
        else:
            raise Exception(
                "Unknown size: {}\nKnown sizes: {}".format(k, " ".join(all_sizes.keys()))
            )

    self.sizes = {}
    for k, v in all_sizes.items():
        if v["class"] == "group_size":
            max_value = max_group_size
            default_value = default_group_size
        elif v["class"] == "num_groups":
            max_value = max_group_size  # Intentional!
            default_value = default_num_groups
        elif v["class"] == "tile_size":
            max_value = max_tile_size
            default_value = default_tile_size
        elif v["class"] == "reg_tile_size":
            max_value = None
            default_value = default_reg_tile_size
        elif v["class"].startswith("threshold"):
            max_value = None
            default_value = default_threshold
        else:
            # Bespoke sizes have no limit or default.
            max_value = None
        if v["value"] == None:
            self.sizes[k] = default_value
        elif max_value != None and v["value"] > max_value:
            sys.stderr.write(
                "Note: Device limits {} to {} (down from {}\n".format(k, max_value, v["value"])
            )
            self.sizes[k] = max_value
        else:
            self.sizes[k] = v["value"]

    # XXX: we perform only a subset of z-encoding here.  Really, the
    # compiler should provide us with the variables to which
    # parameters are mapped.
    if len(program_src) >= 0:
        build_options += [f"-DLOCKSTEP_WIDTH={lockstep_width}"]

        build_options += [
            "-D{}={}".format(
                s.replace("z", "zz").replace(".", "zi").replace("#", "zh").replace("'", "zq"), v
            )
            for (s, v) in self.sizes.items()
        ]

        if self.platform.name == "Oclgrind":
            build_options += ["-DEMULATE_F16"]

        return cl.Program(self.ctx, program_src).build(build_options)


def opencl_alloc(self, min_size, tag):
    min_size = 1 if min_size == 0 else min_size
    assert min_size > 0
    return self.pool.allocate(min_size)


def opencl_free_all(self):
    self.pool.free_held()


def sync(self):
    failure = np.empty(1, dtype=np.int32)
    cl.enqueue_copy(self.queue, failure, self.global_failure, is_blocking=True)
    self.failure_is_an_option = np.int32(0)
    if failure[0] >= 0:
        # Reset failure information.
        cl.enqueue_fill_buffer(
            self.queue, self.global_failure, np.int32(-1), 0, np.int32().itemsize
        )

        # Read failure args.
        failure_args = np.empty(self.global_failure_args_max + 1, dtype=np.int64)
        cl.enqueue_copy(self.queue, failure_args, self.global_failure_args, is_blocking=True)

        raise Exception(self.failure_msgs[failure[0]].format(*failure_args))


import pyopencl.array
import time

sizes = {}
synchronous = False
preferred_platform = None
build_options = []
preferred_device = None
default_threshold = None
default_group_size = None
default_num_groups = None
default_tile_size = None
default_reg_tile_size = None
fut_opencl_src = """
// Clang-based OpenCL implementations need this for 'static' to work.
#ifdef cl_clang_storage_class_specifiers
#pragma OPENCL EXTENSION cl_clang_storage_class_specifiers : enable
#endif
#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable

// Some OpenCL programs dislike empty progams, or programs with no kernels.
// Declare a dummy kernel to ensure they remain our friends.
__kernel void dummy_kernel(__global unsigned char *dummy, int n)
{
    const int thread_gid = get_global_id(0);
    if (thread_gid >= n) return;
}

#pragma OPENCL EXTENSION cl_khr_int64_base_atomics : enable
#pragma OPENCL EXTENSION cl_khr_int64_extended_atomics : enable

typedef char int8_t;
typedef short int16_t;
typedef int int32_t;
typedef long int64_t;

typedef uchar uint8_t;
typedef ushort uint16_t;
typedef uint uint32_t;
typedef ulong uint64_t;

// NVIDIAs OpenCL does not create device-wide memory fences (see #734), so we
// use inline assembly if we detect we are on an NVIDIA GPU.
#ifdef cl_nv_pragma_unroll
static inline void mem_fence_global() {
  asm("membar.gl;");
}
#else
static inline void mem_fence_global() {
  mem_fence(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);
}
#endif
static inline void mem_fence_local() {
  mem_fence(CLK_LOCAL_MEM_FENCE);
}
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

static uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

static float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

static uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

static inline uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

static inline uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

static inline uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

static inline uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

static inline uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

static inline uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

static inline uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

static inline uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

static inline uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

static inline uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

static inline uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

static inline uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

static inline uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

static inline uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x / ys;
}

static inline uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x / ys;
}

static inline uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return (x + y - 1) / ys;
}

static inline uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x % ys;
}

static inline uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

static inline int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

static inline int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

static inline int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

static inline int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

static inline int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

static inline int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

static inline int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

static inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

static inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

static inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

static inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

static inline int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

static inline int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

static inline int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

static inline int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

static inline int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

#else

static inline uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

static inline uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

static inline uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

static inline uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

static inline uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

static inline uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

static inline uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

static inline uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

static inline uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

static inline uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

static inline uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

static inline uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

static inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

static inline int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

static inline int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

static inline int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

static inline int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

static inline int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

static inline int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

static inline int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

static inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

static inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

static inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

static inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

static inline int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

static inline int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

static inline int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

static inline int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

static inline int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

static inline int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

static inline int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

static inline int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

static inline int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

static inline int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

static inline int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

static inline int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

static inline int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

static inline int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

static inline int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

static inline int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

static inline int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

static inline uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

static inline uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

static inline uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

static inline uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

static inline int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

static inline int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

static inline int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

static inline int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

static inline uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

static inline uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

static inline uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

static inline uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

static inline uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

static inline uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

static inline uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

static inline uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

static inline uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

static inline uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

static inline uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

static inline uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

static inline int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

static inline int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

static inline int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

static inline int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

static inline uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

static inline uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

static inline uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

static inline uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

static inline uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

static inline uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

static inline uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

static inline uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

static inline uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

static inline uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

static inline uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

static inline uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

static inline bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

static inline bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

static inline bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

static inline bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

static inline bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

static inline bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

static inline bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

static inline bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

static inline bool slt8(int8_t x, int8_t y) {
  return x < y;
}

static inline bool slt16(int16_t x, int16_t y) {
  return x < y;
}

static inline bool slt32(int32_t x, int32_t y) {
  return x < y;
}

static inline bool slt64(int64_t x, int64_t y) {
  return x < y;
}

static inline bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

static inline bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

static inline bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

static inline bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

static inline uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline bool itob_i8_bool(int8_t x) {
  return x != 0;
}

static inline bool itob_i16_bool(int16_t x) {
  return x != 0;
}

static inline bool itob_i32_bool(int32_t x) {
  return x != 0;
}

static inline bool itob_i64_bool(int64_t x) {
  return x != 0;
}

static inline int8_t btoi_bool_i8(bool x) {
  return x;
}

static inline int16_t btoi_bool_i16(bool x) {
  return x;
}

static inline int32_t btoi_bool_i32(bool x) {
  return x;
}

static inline int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

static int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

static int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

static int32_t abs32(int32_t x) {
  return abs(x);
}

static int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
static int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

static int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

static int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

static int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

static int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

static int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

static int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

static int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  return mul_hi(a, b);
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  return mul_hi(a, b);
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  return mul_hi(a, b);
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  return mul_hi(a, b);
}

#elif defined(__CUDA_ARCH__)

static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  uint16_t aa = a;
  uint16_t bb = b;

  return aa * bb >> 8;
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  uint32_t aa = a;
  uint32_t bb = b;

  return aa * bb >> 16;
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  return mulhi(a, b);
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  return mul64hi(a, b);
}

#elif ISPC

static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  uint16_t aa = a;
  uint16_t bb = b;

  return aa * bb >> 8;
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  uint32_t aa = a;
  uint32_t bb = b;

  return aa * bb >> 16;
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  uint64_t aa = a;
  uint64_t bb = b;

  return aa * bb >> 32;
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l  + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.

static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  uint16_t aa = a;
  uint16_t bb = b;

  return aa * bb >> 8;
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  uint32_t aa = a;
  uint32_t bb = b;

  return aa * bb >> 16;
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  uint64_t aa = a;
  uint64_t bb = b;

  return aa * bb >> 32;
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  __uint128_t aa = a;
  __uint128_t bb = b;

  return aa * bb >> 64;
}
#endif

#if defined(__OPENCL_VERSION__)
static uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {
  return mad_hi(a, b, c);
}

static uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {
  return mad_hi(a, b, c);
}

static uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {
  return mad_hi(a, b, c);
}

static uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {
  return mad_hi(a, b, c);
}

#else // Not OpenCL

static uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {
  return futrts_mul_hi8(a, b) + c;
}

static uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {
  return futrts_mul_hi16(a, b) + c;
}

static uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {
  return futrts_mul_hi32(a, b) + c;
}

static uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {
  return futrts_mul_hi64(a, b) + c;
}
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

static int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

static int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

static int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

static int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

static int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

static int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

static int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

static int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

static int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

static int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

static int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

static int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

static int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

static int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

static inline float fdiv32(float x, float y) {
  return x / y;
}

static inline float fadd32(float x, float y) {
  return x + y;
}

static inline float fsub32(float x, float y) {
  return x - y;
}

static inline float fmul32(float x, float y) {
  return x * y;
}

static inline bool cmplt32(float x, float y) {
  return x < y;
}

static inline bool cmple32(float x, float y) {
  return x <= y;
}

static inline float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

static inline float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

static inline float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

static inline float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

static inline float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

static inline float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

static inline float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

static inline float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
static inline float fabs32(float x) {
  return fabs(x);
}

static inline float fmax32(float x, float y) {
  return fmax(x, y);
}

static inline float fmin32(float x, float y) {
  return fmin(x, y);
}

static inline float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

static inline float fabs32(float x) {
  return abs(x);
}

static inline float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

static inline float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

static inline float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

static inline float fabs32(float x) {
  return fabsf(x);
}

static inline float fmax32(float x, float y) {
  return fmaxf(x, y);
}

static inline float fmin32(float x, float y) {
  return fminf(x, y);
}

static inline float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

static inline bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

static inline bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

static inline bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

static inline bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

static inline int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

static inline uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f32_bool(float x) {
  return x != 0;
}

static inline float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
static inline float futrts_log32(float x) {
  return log(x);
}

static inline float futrts_log2_32(float x) {
  return log2(x);
}

static inline float futrts_log10_32(float x) {
  return log10(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrt(x);
}

static inline float futrts_cbrt32(float x) {
  return cbrt(x);
}

static inline float futrts_exp32(float x) {
  return exp(x);
}

static inline float futrts_cos32(float x) {
  return cos(x);
}

static inline float futrts_sin32(float x) {
  return sin(x);
}

static inline float futrts_tan32(float x) {
  return tan(x);
}

static inline float futrts_acos32(float x) {
  return acos(x);
}

static inline float futrts_asin32(float x) {
  return asin(x);
}

static inline float futrts_atan32(float x) {
  return atan(x);
}

static inline float futrts_cosh32(float x) {
  return cosh(x);
}

static inline float futrts_sinh32(float x) {
  return sinh(x);
}

static inline float futrts_tanh32(float x) {
  return tanh(x);
}

static inline float futrts_acosh32(float x) {
  return acosh(x);
}

static inline float futrts_asinh32(float x) {
  return asinh(x);
}

static inline float futrts_atanh32(float x) {
  return atanh(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgamma(x);
}

static inline float futrts_lgamma32(float x) {
  return lgamma(x);
}

static inline float futrts_erf32(float x) {
  return erf(x);
}

static inline float futrts_erfc32(float x) {
  return erfc(x);
}

static inline float fmod32(float x, float y) {
  return fmod(x, y);
}

static inline float futrts_round32(float x) {
  return rint(x);
}

static inline float futrts_floor32(float x) {
  return floor(x);
}

static inline float futrts_ceil32(float x) {
  return ceil(x);
}

static inline float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

static inline float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

static inline float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

static inline float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

static inline float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

static inline float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

static inline float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
static inline float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float futrts_exp32(float x) {
  return exp(x);
}

static inline float futrts_cos32(float x) {
  return cos(x);
}

static inline float futrts_sin32(float x) {
  return sin(x);
}

static inline float futrts_tan32(float x) {
  return tan(x);
}

static inline float futrts_acos32(float x) {
  return acos(x);
}

static inline float futrts_asin32(float x) {
  return asin(x);
}

static inline float futrts_atan32(float x) {
  return atan(x);
}

static inline float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

static inline float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

static inline float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

static inline float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

static inline float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

static inline float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

static inline float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
static inline float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
static inline float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
static inline float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
static inline float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

static inline float futrts_round32(float x) {
  return round(x);
}

static inline float futrts_floor32(float x) {
  return floor(x);
}

static inline float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
static inline float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

static inline float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

static inline float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

static inline float futrts_log32(float x) {
  return logf(x);
}

static inline float futrts_log2_32(float x) {
  return log2f(x);
}

static inline float futrts_log10_32(float x) {
  return log10f(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrtf(x);
}

static inline float futrts_cbrt32(float x) {
  return cbrtf(x);
}

static inline float futrts_exp32(float x) {
  return expf(x);
}

static inline float futrts_cos32(float x) {
  return cosf(x);
}

static inline float futrts_sin32(float x) {
  return sinf(x);
}

static inline float futrts_tan32(float x) {
  return tanf(x);
}

static inline float futrts_acos32(float x) {
  return acosf(x);
}

static inline float futrts_asin32(float x) {
  return asinf(x);
}

static inline float futrts_atan32(float x) {
  return atanf(x);
}

static inline float futrts_cosh32(float x) {
  return coshf(x);
}

static inline float futrts_sinh32(float x) {
  return sinhf(x);
}

static inline float futrts_tanh32(float x) {
  return tanhf(x);
}

static inline float futrts_acosh32(float x) {
  return acoshf(x);
}

static inline float futrts_asinh32(float x) {
  return asinhf(x);
}

static inline float futrts_atanh32(float x) {
  return atanhf(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgammaf(x);
}

static inline float futrts_lgamma32(float x) {
  return lgammaf(x);
}

static inline float futrts_erf32(float x) {
  return erff(x);
}

static inline float futrts_erfc32(float x) {
  return erfcf(x);
}

static inline float fmod32(float x, float y) {
  return fmodf(x, y);
}

static inline float futrts_round32(float x) {
  return rintf(x);
}

static inline float futrts_floor32(float x) {
  return floorf(x);
}

static inline float futrts_ceil32(float x) {
  return ceilf(x);
}

static inline float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

static inline float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

static inline float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
static inline int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

static inline float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
static inline int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

static inline float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

#if ISPC
static inline bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

static inline bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

static inline double fdiv64(double x, double y) {
  return x / y;
}

static inline double fadd64(double x, double y) {
  return x + y;
}

static inline double fsub64(double x, double y) {
  return x - y;
}

static inline double fmul64(double x, double y) {
  return x * y;
}

static inline bool cmplt64(double x, double y) {
  return x < y;
}

static inline bool cmple64(double x, double y) {
  return x <= y;
}

static inline double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

static inline double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

static inline double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

static inline double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

static inline double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

static inline double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

static inline double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

static inline double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

static inline double fabs64(double x) {
  return abs(x);
}

static inline double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

static inline double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

static inline double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

static inline double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

static inline double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

static inline double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

static inline double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
static inline double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_exp64(double x) {
  return exp(x);
}

static inline double futrts_cos64(double x) {
  return cos(x);
}

static inline double futrts_sin64(double x) {
  return sin(x);
}

static inline double futrts_tan64(double x) {
  return tan(x);
}

static inline double futrts_acos64(double x) {
  return acos(x);
}

static inline double futrts_asin64(double x) {
  return asin(x);
}

static inline double futrts_atan64(double x) {
  return atan(x);
}

static inline double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

static inline double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

static inline double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

static inline double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

static inline double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

static inline double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

static inline double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
static inline double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
static inline double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
static inline double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
static inline double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
static inline double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

static inline double futrts_round64(double x) {
  return round(x);
}

static inline double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
static inline float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_floor64(double x) {
  return floor(x);
}

static inline bool futrts_isnan64(double x) {
  return isnan(x);
}

static inline int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

static inline uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f64_bool(double x) {
  return x != 0.0;
}

static inline double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

static inline int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

static inline double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

static inline double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

static inline double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

static inline double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

static inline float fpconv_f32_f32(float x) {
  return (float) x;
}

static inline double fpconv_f32_f64(float x) {
  return (double) x;
}

static inline float fpconv_f64_f32(double x) {
  return (float) x;
}

static inline double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

static inline double fdiv64(double x, double y) {
  return x / y;
}

static inline double fadd64(double x, double y) {
  return x + y;
}

static inline double fsub64(double x, double y) {
  return x - y;
}

static inline double fmul64(double x, double y) {
  return x * y;
}

static inline bool cmplt64(double x, double y) {
  return x < y;
}

static inline bool cmple64(double x, double y) {
  return x <= y;
}

static inline double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

static inline double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

static inline double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

static inline double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

static inline double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

static inline double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

static inline double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

static inline double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

static inline double fabs64(double x) {
  return fabs(x);
}

static inline double fmax64(double x, double y) {
  return fmax(x, y);
}

static inline double fmin64(double x, double y) {
  return fmin(x, y);
}

static inline double fpow64(double x, double y) {
  return pow(x, y);
}

static inline double futrts_log64(double x) {
  return log(x);
}

static inline double futrts_log2_64(double x) {
  return log2(x);
}

static inline double futrts_log10_64(double x) {
  return log10(x);
}

static inline double futrts_sqrt64(double x) {
  return sqrt(x);
}

static inline double futrts_cbrt64(double x) {
  return cbrt(x);
}

static inline double futrts_exp64(double x) {
  return exp(x);
}

static inline double futrts_cos64(double x) {
  return cos(x);
}

static inline double futrts_sin64(double x) {
  return sin(x);
}

static inline double futrts_tan64(double x) {
  return tan(x);
}

static inline double futrts_acos64(double x) {
  return acos(x);
}

static inline double futrts_asin64(double x) {
  return asin(x);
}

static inline double futrts_atan64(double x) {
  return atan(x);
}

static inline double futrts_cosh64(double x) {
  return cosh(x);
}

static inline double futrts_sinh64(double x) {
  return sinh(x);
}

static inline double futrts_tanh64(double x) {
  return tanh(x);
}

static inline double futrts_acosh64(double x) {
  return acosh(x);
}

static inline double futrts_asinh64(double x) {
  return asinh(x);
}

static inline double futrts_atanh64(double x) {
  return atanh(x);
}

static inline double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

static inline double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

static inline double futrts_gamma64(double x) {
  return tgamma(x);
}

static inline double futrts_lgamma64(double x) {
  return lgamma(x);
}

static inline double futrts_erf64(double x) {
  return erf(x);
}

static inline double futrts_erfc64(double x) {
  return erfc(x);
}

static inline double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

static inline double futrts_round64(double x) {
  return rint(x);
}

static inline double futrts_ceil64(double x) {
  return ceil(x);
}

static inline float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

static inline double futrts_floor64(double x) {
  return floor(x);
}

static inline bool futrts_isnan64(double x) {
  return isnan(x);
}

static inline bool futrts_isinf64(double x) {
  return isinf(x);
}

static inline int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

static inline uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f64_bool(double x) {
  return x != 0;
}

static inline double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

static inline int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

static inline double fmod64(double x, double y) {
  return fmod(x, y);
}

static inline double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

static inline double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

static inline double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

static inline float fpconv_f32_f32(float x) {
  return (float) x;
}

static inline double fpconv_f32_f64(float x) {
  return (double) x;
}

static inline float fpconv_f64_f32(double x) {
  return (float) x;
}

static inline double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

static inline f16 fadd16(f16 x, f16 y) {
  return x + y;
}

static inline f16 fsub16(f16 x, f16 y) {
  return x - y;
}

static inline f16 fmul16(f16 x, f16 y) {
  return x * y;
}

static inline bool cmplt16(f16 x, f16 y) {
  return x < y;
}

static inline bool cmple16(f16 x, f16 y) {
  return x <= y;
}

static inline f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

static inline f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

static inline f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

static inline f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

static inline f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

static inline f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

static inline f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

static inline f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

static inline int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

static inline int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

static inline int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

static inline int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

static inline uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

static inline uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

static inline uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

static inline uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

static inline bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

static inline f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
static inline bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

static inline f16 fabs16(f16 x) {
  return fabs(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
static inline f16 fabs16(f16 x) {
  return abs(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}
#else // Assuming CUDA.

static inline f16 fabs16(f16 x) {
  return fabsf(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
static inline bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
static inline bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

static inline bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
static inline f16 futrts_log16(f16 x) {
  return log(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return log2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return log10(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

static inline f16 futrts_exp16(f16 x) {
  return exp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return cos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return sin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tan(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acos(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asin(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atan(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

static inline f16 futrts_erf16(f16 x) {
  return erf(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rint(x);
}

static inline f16 futrts_floor16(f16 x) {
  return floor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

static inline f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

static inline f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

static inline f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

static inline f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

static inline f16 futrts_exp16(f16 x) {
  return exp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

static inline f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

static inline f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

static inline f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

static inline f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

static inline f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

static inline f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

static inline f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

static inline f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

static inline f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

static inline f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

static inline f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
static inline f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
static inline f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

static inline f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

static inline f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

static inline f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

static inline f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

static inline f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

static inline f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

static inline f16 futrts_log16(f16 x) {
  return hlog(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

static inline f16 futrts_exp16(f16 x) {
  return hexp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return hcos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return hsin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tanf(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acosf(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asinf(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atanf(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

static inline f16 futrts_erf16(f16 x) {
  return erff(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rintf(x);
}

static inline f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
static inline int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
static inline f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

static inline int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

static inline f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
static inline int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

static inline f16 fabs16(f16 x) {
  return fabs32(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

static inline bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

static inline bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

static inline f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

static inline f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

static inline f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

static inline f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

static inline f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

static inline f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

static inline f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

static inline f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

static inline f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

static inline f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

static inline int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

static inline f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

static inline int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

static inline f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

static inline f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

static inline float fpconv_f16_f16(f16 x) {
  return x;
}

static inline float fpconv_f16_f32(f16 x) {
  return x;
}

static inline f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

static inline double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
static inline f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
static inline f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.
// Start of atomics.h

inline int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicExch((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

inline int32_t atomic_xchg_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicExch((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

inline int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,
                                         int32_t cmp, int32_t val) {
#ifdef FUTHARK_CUDA
  return atomicCAS((int32_t*)p, cmp, val);
#else
  return atomic_cmpxchg(p, cmp, val);
#endif
}

inline int32_t atomic_cmpxchg_i32_local(volatile __local int32_t *p,
                                        int32_t cmp, int32_t val) {
#ifdef FUTHARK_CUDA
  return atomicCAS((int32_t*)p, cmp, val);
#else
  return atomic_cmpxchg(p, cmp, val);
#endif
}

inline int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((int32_t*)p, x);
#else
  return atomic_add(p, x);
#endif
}

inline int32_t atomic_add_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((int32_t*)p, x);
#else
  return atomic_add(p, x);
#endif
}

inline float atomic_fadd_f32_global(volatile __global float *p, float x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((float*)p, x);
#else
  union { int32_t i; float f; } old;
  union { int32_t i; float f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

inline float atomic_fadd_f32_local(volatile __local float *p, float x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((float*)p, x);
#else
  union { int32_t i; float f; } old;
  union { int32_t i; float f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i32_local((volatile __local int32_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

inline int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((int32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

inline int32_t atomic_smax_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((int32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

inline int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((int32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

inline int32_t atomic_smin_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((int32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

inline uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((uint32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

inline uint32_t atomic_umax_i32_local(volatile __local uint32_t *p, uint32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((uint32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

inline uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((uint32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

inline uint32_t atomic_umin_i32_local(volatile __local uint32_t *p, uint32_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((uint32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

inline int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicAnd((int32_t*)p, x);
#else
  return atomic_and(p, x);
#endif
}

inline int32_t atomic_and_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicAnd((int32_t*)p, x);
#else
  return atomic_and(p, x);
#endif
}

inline int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicOr((int32_t*)p, x);
#else
  return atomic_or(p, x);
#endif
}

inline int32_t atomic_or_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicOr((int32_t*)p, x);
#else
  return atomic_or(p, x);
#endif
}

inline int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicXor((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

inline int32_t atomic_xor_i32_local(volatile __local int32_t *p, int32_t x) {
#ifdef FUTHARK_CUDA
  return atomicXor((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

// Start of 64 bit atomics

inline int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicExch((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

inline int64_t atomic_xchg_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicExch((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

inline int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,
                                         int64_t cmp, int64_t val) {
#ifdef FUTHARK_CUDA
  return atomicCAS((uint64_t*)p, cmp, val);
#else
  return atom_cmpxchg(p, cmp, val);
#endif
}

inline int64_t atomic_cmpxchg_i64_local(volatile __local int64_t *p,
                                        int64_t cmp, int64_t val) {
#ifdef FUTHARK_CUDA
  return atomicCAS((uint64_t*)p, cmp, val);
#else
  return atom_cmpxchg(p, cmp, val);
#endif
}

inline int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((uint64_t*)p, x);
#else
  return atom_add(p, x);
#endif
}

inline int64_t atomic_add_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicAdd((uint64_t*)p, x);
#else
  return atom_add(p, x);
#endif
}

#ifdef FUTHARK_F64_ENABLED

inline double atomic_fadd_f64_global(volatile __global double *p, double x) {
#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600
  return atomicAdd((double*)p, x);
#else
  union { int64_t i; double f; } old;
  union { int64_t i; double f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

inline double atomic_fadd_f64_local(volatile __local double *p, double x) {
#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600
  return atomicAdd((double*)p, x);
#else
  union { int64_t i; double f; } old;
  union { int64_t i; double f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

#endif

inline int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((int64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

inline int64_t atomic_smax_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((int64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

inline int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((int64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

inline int64_t atomic_smin_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((int64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

inline uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((uint64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

inline uint64_t atomic_umax_i64_local(volatile __local uint64_t *p, uint64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMax((uint64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

inline uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((uint64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

inline uint64_t atomic_umin_i64_local(volatile __local uint64_t *p, uint64_t x) {
#ifdef FUTHARK_CUDA
  return atomicMin((uint64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

inline int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicAnd((int64_t*)p, x);
#else
  return atom_and(p, x);
#endif
}

inline int64_t atomic_and_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicAnd((int64_t*)p, x);
#else
  return atom_and(p, x);
#endif
}

inline int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicOr((int64_t*)p, x);
#else
  return atom_or(p, x);
#endif
}

inline int64_t atomic_or_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicOr((int64_t*)p, x);
#else
  return atom_or(p, x);
#endif
}

inline int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicXor((int64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

inline int64_t atomic_xor_i64_local(volatile __local int64_t *p, int64_t x) {
#ifdef FUTHARK_CUDA
  return atomicXor((int64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

// End of atomics.h



__kernel void builtinzhreplicate_i64zireplicate_7579(int64_t num_elems_7575, int64_t val_7576, int64_t replicate_n_7578, int64_t virt_num_groups_7584, int64_t num_groups_7585, __global unsigned char *mem_7574)
{
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    int32_t replicate_ltid_7580;
    int64_t group_sizze_7582;
    int32_t replicate_gid_7581;
    
    replicate_ltid_7580 = get_local_id(0);
    group_sizze_7582 = get_local_size(0);
    replicate_gid_7581 = get_group_id(0);
    
    int32_t replicate_gtid_7579 = replicate_gid_7581 * group_sizze_7582 + replicate_ltid_7580;
    int32_t phys_group_id_7586;
    
    phys_group_id_7586 = get_group_id(0);
    
    int32_t iterations_7587 = sdiv_up32(sext_i64_i32(virt_num_groups_7584) - phys_group_id_7586, sext_i64_i32(num_groups_7585));
    
    for (int32_t i_7588 = 0; i_7588 < iterations_7587; i_7588++) {
        int32_t virt_group_id_7589 = phys_group_id_7586 + i_7588 * sext_i64_i32(num_groups_7585);
        int64_t global_tid_7590 = sext_i32_i64(virt_group_id_7589) * sext_i32_i64(group_sizze_7582) + sext_i32_i64(replicate_ltid_7580);
        int64_t slice_7592 = num_elems_7575;
        int64_t rep_i_7591 = global_tid_7590;
        int64_t remnant_7593 = global_tid_7590 - rep_i_7591;
        
        if (slt64(global_tid_7590, replicate_n_7578)) {
            ((__global int64_t *) mem_7574)[rep_i_7591] = val_7576;
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_0:
    return;
}
__kernel void byte_histogramziseghist_global_7178(__global int *global_failure, int64_t n_6636, int64_t num_groups_7173, int32_t num_subhistos_7595, int32_t chk_i_7665, int64_t hist_H_chk_7666, __global unsigned char *xs_mem_7539, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    #define seghist_group_sizze_7171 (byte_histogramziseghist_group_sizze_7170)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7668;
    int64_t group_sizze_7671;
    int32_t wave_sizze_7670;
    int32_t group_tid_7669;
    
    local_tid_7668 = get_local_id(0);
    group_sizze_7671 = get_local_size(0);
    wave_sizze_7670 = LOCKSTEP_WIDTH;
    group_tid_7669 = get_group_id(0);
    
    int32_t global_tid_7667 = group_tid_7669 * group_sizze_7671 + local_tid_7668;
    int32_t phys_tid_7178 = global_tid_7667;
    int32_t subhisto_ind_7672 = squot32(global_tid_7667, sdiv_up32(sext_i64_i32(seghist_group_sizze_7171 * num_groups_7173), num_subhistos_7595));
    int64_t num_chunks_7673 = sdiv_up64(n_6636, sext_i32_i64(sext_i64_i32(seghist_group_sizze_7171 * num_groups_7173)));
    
    for (int64_t chunk_i_7674 = 0; chunk_i_7674 < num_chunks_7673; chunk_i_7674++) {
        int64_t i_7675 = chunk_i_7674 * sext_i32_i64(sext_i64_i32(seghist_group_sizze_7171 * num_groups_7173)) + sext_i32_i64(global_tid_7667);
        
        if (slt64(i_7675, n_6636)) {
            int64_t slice_7676 = n_6636;
            int64_t gtid_7177 = i_7675;
            int64_t remnant_7677 = i_7675 - gtid_7177;
            
            if (slt64(i_7675, n_6636)) {
                int8_t x_7182 = ((__global int8_t *) xs_mem_7539)[gtid_7177];
                int64_t defunc_0_f_res_7184 = zext_i8_i64(x_7182);
                
                // save map-out results
                { }
                // perform atomic updates
                {
                    if (sle64(sext_i32_i64(chk_i_7665) * hist_H_chk_7666, defunc_0_f_res_7184) && (slt64(defunc_0_f_res_7184, sext_i32_i64(chk_i_7665) * hist_H_chk_7666 + hist_H_chk_7666) && (sle64((int64_t) 0, defunc_0_f_res_7184) && slt64(defunc_0_f_res_7184, (int64_t) 256)))) {
                        int64_t x_7179;
                        int64_t x_7180 = (int64_t) 1;
                        int64_t old_7678;
                        
                        old_7678 = atomic_add_i64_global(&((volatile __global int64_t *) defunc_1_map_res_subhistos_mem_7596)[sext_i32_i64(subhisto_ind_7672) * (int64_t) 256 + defunc_0_f_res_7184], (int64_t) x_7180);
                    }
                }
            }
        }
    }
    
  error_0:
    return;
    #undef seghist_group_sizze_7171
}
__kernel void byte_histogramziseghist_local_7178(__global int *global_failure, __local volatile int64_t *subhistogram_local_mem_7634_backing_aligned_0, int64_t n_6636, int32_t max_group_sizze_7605, int64_t num_groups_7606, int32_t hist_M_7612, int32_t chk_i_7616, int64_t num_segments_7617, int64_t hist_H_chk_7618, int64_t histo_sizze_7619, int32_t init_per_thread_7620, __global unsigned char *xs_mem_7539, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict subhistogram_local_mem_7634_backing_0 = (__local volatile unsigned char *) subhistogram_local_mem_7634_backing_aligned_0;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7622;
    int64_t group_sizze_7625;
    int32_t wave_sizze_7624;
    int32_t group_tid_7623;
    
    local_tid_7622 = get_local_id(0);
    group_sizze_7625 = get_local_size(0);
    wave_sizze_7624 = LOCKSTEP_WIDTH;
    group_tid_7623 = get_group_id(0);
    
    int32_t global_tid_7621 = group_tid_7623 * group_sizze_7625 + local_tid_7622;
    int32_t phys_tid_7178 = global_tid_7621;
    int32_t phys_group_id_7626;
    
    phys_group_id_7626 = get_group_id(0);
    
    int32_t iterations_7627 = sdiv_up32(sext_i64_i32(num_groups_7606 * num_segments_7617) - phys_group_id_7626, sext_i64_i32(num_groups_7606));
    
    for (int32_t i_7628 = 0; i_7628 < iterations_7627; i_7628++) {
        int32_t virt_group_id_7629 = phys_group_id_7626 + i_7628 * sext_i64_i32(num_groups_7606);
        int32_t flat_segment_id_7630 = squot32(virt_group_id_7629, sext_i64_i32(num_groups_7606));
        int32_t gid_in_segment_7631 = srem32(virt_group_id_7629, sext_i64_i32(num_groups_7606));
        int32_t pgtid_in_segment_7632 = gid_in_segment_7631 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
        int32_t threads_per_segment_7633 = sext_i64_i32(num_groups_7606 * max_group_sizze_7605);
        __local unsigned char *subhistogram_local_mem_7634;
        
        subhistogram_local_mem_7634 = (__local unsigned char *) subhistogram_local_mem_7634_backing_0;
        
        int32_t thread_local_subhisto_i_7636 = srem32(local_tid_7622, hist_M_7612);
        
        // initialize histograms in local memory
        {
            for (int32_t local_i_7637 = 0; local_i_7637 < init_per_thread_7620; local_i_7637++) {
                int32_t j_7638 = local_i_7637 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
                int32_t j_offset_7639 = hist_M_7612 * sext_i64_i32(histo_sizze_7619) * gid_in_segment_7631 + j_7638;
                int32_t local_subhisto_i_7640 = squot32(j_7638, sext_i64_i32(histo_sizze_7619));
                int32_t global_subhisto_i_7641 = squot32(j_offset_7639, sext_i64_i32(histo_sizze_7619));
                
                if (slt32(j_7638, hist_M_7612 * sext_i64_i32(histo_sizze_7619))) {
                    // First subhistogram is initialised from global memory; others with neutral element.
                    {
                        if (global_subhisto_i_7641 == 0) {
                            int64_t tmp_7642 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619))) + sext_i32_i64(chk_i_7616) * hist_H_chk_7618];
                            
                            ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(local_subhisto_i_7640) * hist_H_chk_7618 + sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619)))] = tmp_7642;
                        } else {
                            ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(local_subhisto_i_7640) * hist_H_chk_7618 + sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619)))] = (int64_t) 0;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        
        int32_t num_chunks_7643 = sdiv_up32(sext_i64_i32(n_6636), threads_per_segment_7633);
        
        for (int32_t chunk_i_7644 = 0; chunk_i_7644 < num_chunks_7643; chunk_i_7644++) {
            int32_t i_7645 = chunk_i_7644 * threads_per_segment_7633 + pgtid_in_segment_7632;
            
            if (slt32(i_7645, sext_i64_i32(n_6636))) {
                int64_t gtid_7177 = sext_i32_i64(i_7645);
                int8_t x_7182 = ((__global int8_t *) xs_mem_7539)[gtid_7177];
                int64_t defunc_0_f_res_7184 = zext_i8_i64(x_7182);
                
                if (chk_i_7616 == 0) {
                    // save map-out results
                    { }
                }
                // perform atomic updates
                {
                    if ((sle64((int64_t) 0, defunc_0_f_res_7184) && slt64(defunc_0_f_res_7184, (int64_t) 256)) && (sle64(sext_i32_i64(chk_i_7616) * hist_H_chk_7618, defunc_0_f_res_7184) && slt64(defunc_0_f_res_7184, sext_i32_i64(chk_i_7616) * hist_H_chk_7618 + hist_H_chk_7618))) {
                        int64_t x_7179;
                        int64_t x_7180 = (int64_t) 1;
                        int64_t old_7646;
                        
                        old_7646 = atomic_add_i64_local(&((volatile __local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(thread_local_subhisto_i_7636) * hist_H_chk_7618 + (defunc_0_f_res_7184 - sext_i32_i64(chk_i_7616) * hist_H_chk_7618)], (int64_t) x_7180);
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
        // Compact the multiple local memory subhistograms to result in global memory
        {
            int64_t trunc_H_7647 = smin64(hist_H_chk_7618, (int64_t) 256 - sext_i32_i64(chk_i_7616) * hist_H_chk_7618);
            int32_t histo_sizze_7648 = sext_i64_i32(trunc_H_7647);
            
            for (int32_t local_i_7649 = 0; local_i_7649 < init_per_thread_7620; local_i_7649++) {
                int32_t j_7650 = local_i_7649 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
                
                if (slt32(j_7650, histo_sizze_7648)) {
                    int64_t x_7179;
                    int64_t x_7180;
                    
                    // Read values from subhistogram 0.
                    {
                        x_7179 = ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(j_7650)];
                    }
                    // Accumulate based on values in other subhistograms.
                    {
                        for (int32_t subhisto_id_7651 = 0; subhisto_id_7651 < hist_M_7612 - 1; subhisto_id_7651++) {
                            x_7180 = ((__local int64_t *) subhistogram_local_mem_7634)[(sext_i32_i64(subhisto_id_7651) + (int64_t) 1) * hist_H_chk_7618 + sext_i32_i64(j_7650)];
                            
                            int64_t defunc_1_op_res_7181 = add64(x_7179, x_7180);
                            
                            x_7179 = defunc_1_op_res_7181;
                        }
                    }
                    // Put final bucket value in global memory.
                    {
                        ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[srem64(sext_i32_i64(virt_group_id_7629), num_groups_7606) * (int64_t) 256 + (sext_i32_i64(j_7650) + sext_i32_i64(chk_i_7616) * hist_H_chk_7618)] = x_7179;
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
}
__kernel void byte_histogramzisegred_large_7681(__global int *global_failure, __local volatile int64_t *sync_arr_mem_7727_backing_aligned_0, __local volatile int64_t *red_arr_mem_7725_backing_aligned_1, int64_t num_groups_7173, int32_t num_subhistos_7595, int64_t groups_per_segment_7711, int64_t elements_per_thread_7712, int64_t virt_num_groups_7713, int64_t threads_per_segment_7715, __global unsigned char *mem_7541, __global unsigned char *defunc_1_map_res_subhistos_mem_7596, __global unsigned char *segred_tmp_mem_7716, __global unsigned char *byte_histogramzicounter_mem_7718)
{
    #define seghist_group_sizze_7171 (byte_histogramziseghist_group_sizze_7170)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict sync_arr_mem_7727_backing_1 = (__local volatile unsigned char *) sync_arr_mem_7727_backing_aligned_0;
    __local volatile unsigned char *restrict red_arr_mem_7725_backing_0 = (__local volatile unsigned char *) red_arr_mem_7725_backing_aligned_1;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7721;
    int64_t group_sizze_7724;
    int32_t wave_sizze_7723;
    int32_t group_tid_7722;
    
    local_tid_7721 = get_local_id(0);
    group_sizze_7724 = get_local_size(0);
    wave_sizze_7723 = LOCKSTEP_WIDTH;
    group_tid_7722 = get_group_id(0);
    
    int32_t global_tid_7720 = group_tid_7722 * group_sizze_7724 + local_tid_7721;
    int32_t flat_gtid_7681 = global_tid_7720;
    __local unsigned char *red_arr_mem_7725;
    
    red_arr_mem_7725 = (__local unsigned char *) red_arr_mem_7725_backing_0;
    
    __local unsigned char *sync_arr_mem_7727;
    
    sync_arr_mem_7727 = (__local unsigned char *) sync_arr_mem_7727_backing_1;
    
    int32_t phys_group_id_7729;
    
    phys_group_id_7729 = get_group_id(0);
    
    int32_t iterations_7730 = sdiv_up32(sext_i64_i32(virt_num_groups_7713) - phys_group_id_7729, sext_i64_i32(num_groups_7173));
    
    for (int32_t i_7731 = 0; i_7731 < iterations_7730; i_7731++) {
        int32_t virt_group_id_7732 = phys_group_id_7729 + i_7731 * sext_i64_i32(num_groups_7173);
        int32_t flat_segment_id_7733 = squot32(virt_group_id_7732, sext_i64_i32(groups_per_segment_7711));
        int64_t global_tid_7734 = srem64(sext_i32_i64(virt_group_id_7732) * seghist_group_sizze_7171 + sext_i32_i64(local_tid_7721), seghist_group_sizze_7171 * groups_per_segment_7711);
        int64_t slice_7735 = (int64_t) 256;
        int64_t bucket_id_7679 = sext_i32_i64(flat_segment_id_7733);
        int64_t remnant_7736 = sext_i32_i64(flat_segment_id_7733) - bucket_id_7679;
        int64_t subhistogram_id_7680;
        int64_t x_acc_7737;
        int64_t chunk_sizze_7738 = smin64(elements_per_thread_7712, sdiv_up64(num_subhistos_7595 - global_tid_7734, threads_per_segment_7715));
        int64_t x_7179;
        int64_t x_7180;
        
        // neutral-initialise the accumulators
        {
            x_acc_7737 = (int64_t) 0;
        }
        for (int64_t i_7742 = 0; i_7742 < chunk_sizze_7738; i_7742++) {
            subhistogram_id_7680 = global_tid_7734 + threads_per_segment_7715 * i_7742;
            // apply map function
            {
                // load accumulator
                {
                    x_7179 = x_acc_7737;
                }
                // load new values
                {
                    x_7180 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[subhistogram_id_7680 * (int64_t) 256 + bucket_id_7679];
                }
                // apply reduction operator
                {
                    int64_t defunc_1_op_res_7181 = add64(x_7179, x_7180);
                    
                    // store in accumulator
                    {
                        x_acc_7737 = defunc_1_op_res_7181;
                    }
                }
            }
        }
        // to reduce current chunk, first store our result in memory
        {
            x_7179 = x_acc_7737;
            ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7179;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        
        int32_t offset_7743;
        int32_t skip_waves_7744 = 1;
        int64_t x_7739;
        int64_t x_7740;
        
        offset_7743 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_7721, sext_i64_i32(seghist_group_sizze_7171))) {
                x_7739 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
            }
        }
        offset_7743 = 1;
        while (slt32(offset_7743, wave_sizze_7723)) {
            if (slt32(local_tid_7721 + offset_7743, sext_i64_i32(seghist_group_sizze_7171)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) & (2 * offset_7743 - 1)) == 0) {
                // read array element
                {
                    x_7740 = ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
                }
                // apply reduction operation
                {
                    int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                    
                    x_7739 = defunc_1_op_res_7741;
                }
                // write result of operation
                {
                    ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                }
            }
            offset_7743 *= 2;
        }
        while (slt32(skip_waves_7744, squot32(sext_i64_i32(seghist_group_sizze_7171) + wave_sizze_7723 - 1, wave_sizze_7723))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_7743 = skip_waves_7744 * wave_sizze_7723;
            if (slt32(local_tid_7721 + offset_7743, sext_i64_i32(seghist_group_sizze_7171)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) == 0 && (squot32(local_tid_7721, wave_sizze_7723) & (2 * skip_waves_7744 - 1)) == 0)) {
                // read array element
                {
                    x_7740 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
                }
                // apply reduction operation
                {
                    int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                    
                    x_7739 = defunc_1_op_res_7741;
                }
                // write result of operation
                {
                    ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                }
            }
            skip_waves_7744 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // first thread saves the result in accumulator
        {
            if (sext_i32_i64(local_tid_7721) == (int64_t) 0) {
                x_acc_7737 = x_7739;
            }
        }
        if (groups_per_segment_7711 == (int64_t) 1) {
            // first thread in group saves final result to memory
            {
                if (local_tid_7721 == 0) {
                    ((__global int64_t *) mem_7541)[bucket_id_7679] = x_acc_7737;
                }
            }
        } else {
            int32_t old_counter_7745;
            
            // first thread in group saves group result to global memory
            {
                if (local_tid_7721 == 0) {
                    ((__global int64_t *) segred_tmp_mem_7716)[sext_i32_i64(virt_group_id_7732)] = x_acc_7737;
                    mem_fence_global();
                    old_counter_7745 = atomic_add_i32_global(&((volatile __global int *) byte_histogramzicounter_mem_7718)[sext_i32_i64(srem32(flat_segment_id_7733, 10240))], (int) 1);
                    ((__local bool *) sync_arr_mem_7727)[(int64_t) 0] = old_counter_7745 == groups_per_segment_7711 - (int64_t) 1;
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            
            bool is_last_group_7746 = ((__local bool *) sync_arr_mem_7727)[(int64_t) 0];
            
            if (is_last_group_7746) {
                if (local_tid_7721 == 0) {
                    old_counter_7745 = atomic_add_i32_global(&((volatile __global int *) byte_histogramzicounter_mem_7718)[sext_i32_i64(srem32(flat_segment_id_7733, 10240))], (int) ((int64_t) 0 - groups_per_segment_7711));
                }
                // read in the per-group-results
                {
                    int64_t read_per_thread_7747 = sdiv_up64(groups_per_segment_7711, seghist_group_sizze_7171);
                    
                    x_7179 = (int64_t) 0;
                    for (int64_t i_7748 = 0; i_7748 < read_per_thread_7747; i_7748++) {
                        int64_t group_res_id_7749 = sext_i32_i64(local_tid_7721) * read_per_thread_7747 + i_7748;
                        int64_t index_of_group_res_7750 = sext_i32_i64(flat_segment_id_7733) * groups_per_segment_7711 + group_res_id_7749;
                        
                        if (slt64(group_res_id_7749, groups_per_segment_7711)) {
                            x_7180 = ((__global int64_t *) segred_tmp_mem_7716)[index_of_group_res_7750];
                            
                            int64_t defunc_1_op_res_7181 = add64(x_7179, x_7180);
                            
                            x_7179 = defunc_1_op_res_7181;
                        }
                    }
                }
                ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7179;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-group results
                {
                    int32_t offset_7751;
                    int32_t skip_waves_7752 = 1;
                    int64_t x_7739;
                    int64_t x_7740;
                    
                    offset_7751 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_7721, sext_i64_i32(seghist_group_sizze_7171))) {
                            x_7739 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                        }
                    }
                    offset_7751 = 1;
                    while (slt32(offset_7751, wave_sizze_7723)) {
                        if (slt32(local_tid_7721 + offset_7751, sext_i64_i32(seghist_group_sizze_7171)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) & (2 * offset_7751 - 1)) == 0) {
                            // read array element
                            {
                                x_7740 = ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                                
                                x_7739 = defunc_1_op_res_7741;
                            }
                            // write result of operation
                            {
                                ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                            }
                        }
                        offset_7751 *= 2;
                    }
                    while (slt32(skip_waves_7752, squot32(sext_i64_i32(seghist_group_sizze_7171) + wave_sizze_7723 - 1, wave_sizze_7723))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_7751 = skip_waves_7752 * wave_sizze_7723;
                        if (slt32(local_tid_7721 + offset_7751, sext_i64_i32(seghist_group_sizze_7171)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) == 0 && (squot32(local_tid_7721, wave_sizze_7723) & (2 * skip_waves_7752 - 1)) == 0)) {
                            // read array element
                            {
                                x_7740 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                                
                                x_7739 = defunc_1_op_res_7741;
                            }
                            // write result of operation
                            {
                                ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                            }
                        }
                        skip_waves_7752 *= 2;
                    }
                    // and back to memory with the final result
                    {
                        if (local_tid_7721 == 0) {
                            ((__global int64_t *) mem_7541)[bucket_id_7679] = x_7739;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef seghist_group_sizze_7171
}
__kernel void byte_histogramzisegred_small_7681(__global int *global_failure, __local volatile int64_t *red_arr_mem_7689_backing_aligned_0, int64_t num_groups_7173, int32_t num_subhistos_7595, int64_t segment_sizze_nonzzero_7682, __global unsigned char *mem_7541, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    #define seghist_group_sizze_7171 (byte_histogramziseghist_group_sizze_7170)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict red_arr_mem_7689_backing_0 = (__local volatile unsigned char *) red_arr_mem_7689_backing_aligned_0;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7685;
    int64_t group_sizze_7688;
    int32_t wave_sizze_7687;
    int32_t group_tid_7686;
    
    local_tid_7685 = get_local_id(0);
    group_sizze_7688 = get_local_size(0);
    wave_sizze_7687 = LOCKSTEP_WIDTH;
    group_tid_7686 = get_group_id(0);
    
    int32_t global_tid_7684 = group_tid_7686 * group_sizze_7688 + local_tid_7685;
    int32_t flat_gtid_7681 = global_tid_7684;
    __local unsigned char *red_arr_mem_7689;
    
    red_arr_mem_7689 = (__local unsigned char *) red_arr_mem_7689_backing_0;
    
    int32_t phys_group_id_7691;
    
    phys_group_id_7691 = get_group_id(0);
    
    int32_t iterations_7692 = sdiv_up32(sext_i64_i32(sdiv_up64((int64_t) 256, squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682))) - phys_group_id_7691, sext_i64_i32(num_groups_7173));
    
    for (int32_t i_7693 = 0; i_7693 < iterations_7692; i_7693++) {
        int32_t virt_group_id_7694 = phys_group_id_7691 + i_7693 * sext_i64_i32(num_groups_7173);
        int64_t slice_7695 = (int64_t) 256;
        int64_t bucket_id_7679 = squot64(sext_i32_i64(local_tid_7685), segment_sizze_nonzzero_7682) + sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682);
        int64_t remnant_7696 = squot64(sext_i32_i64(local_tid_7685), segment_sizze_nonzzero_7682) + sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682) - bucket_id_7679;
        int64_t subhistogram_id_7680 = srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595);
        
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, num_subhistos_7595) && (slt64(bucket_id_7679, (int64_t) 256) && slt64(sext_i32_i64(local_tid_7685), num_subhistos_7595 * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682)))) {
                // save results to be reduced
                {
                    int64_t tmp_7697 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[subhistogram_id_7680 * (int64_t) 256 + bucket_id_7679];
                    
                    ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = tmp_7697;
                }
            } else {
                ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = (int64_t) 0;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, num_subhistos_7595)) {
            // perform segmented scan to imitate reduction
            {
                int64_t x_7179;
                int64_t x_7180;
                int64_t x_7698;
                int64_t x_7699;
                bool ltid_in_bounds_7701 = slt64(sext_i32_i64(local_tid_7685), num_subhistos_7595 * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682));
                int32_t skip_threads_7702;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_7701) {
                        x_7180 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)];
                        if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 0) {
                            x_7179 = x_7180;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_7702 = 1;
                    while (slt32(skip_threads_7702, 32)) {
                        bool thread_active_7703 = sle32(skip_threads_7702, local_tid_7685 - squot32(local_tid_7685, 32) * 32) && ltid_in_bounds_7701;
                        
                        if (thread_active_7703) {
                            // read operands
                            {
                                x_7179 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685) - sext_i32_i64(skip_threads_7702)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_7704 = slt64(srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595), sext_i32_i64(local_tid_7685) - sext_i32_i64(local_tid_7685 - skip_threads_7702));
                            
                            if (thread_active_7703 && inactive_7704) {
                                x_7179 = x_7180;
                            }
                            if (thread_active_7703) {
                                if (!inactive_7704) {
                                    int64_t defunc_1_op_res_7181 = add64(x_7179, x_7180);
                                    
                                    x_7179 = defunc_1_op_res_7181;
                                }
                            }
                        }
                        if (sle32(wave_sizze_7687, skip_threads_7702)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_7703) {
                            // write result
                            {
                                ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7179;
                                x_7180 = x_7179;
                            }
                        }
                        if (sle32(wave_sizze_7687, skip_threads_7702)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_7702 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 31 && ltid_in_bounds_7701) {
                        ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(squot32(local_tid_7685, 32))] = x_7179;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_7705;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701) {
                            x_7699 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)];
                            if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 0) {
                                x_7698 = x_7699;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_7705 = 1;
                        while (slt32(skip_threads_7705, 32)) {
                            bool thread_active_7706 = sle32(skip_threads_7705, local_tid_7685 - squot32(local_tid_7685, 32) * 32) && (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701);
                            
                            if (thread_active_7706) {
                                // read operands
                                {
                                    x_7698 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685) - sext_i32_i64(skip_threads_7705)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_7707 = slt64(srem64(sext_i32_i64(local_tid_7685 * 32 + 32 - 1), num_subhistos_7595), sext_i32_i64(local_tid_7685 * 32 + 32 - 1) - sext_i32_i64((local_tid_7685 - skip_threads_7705) * 32 + 32 - 1));
                                
                                if (thread_active_7706 && inactive_7707) {
                                    x_7698 = x_7699;
                                }
                                if (thread_active_7706) {
                                    if (!inactive_7707) {
                                        int64_t defunc_1_op_res_7700 = add64(x_7698, x_7699);
                                        
                                        x_7698 = defunc_1_op_res_7700;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_7687, skip_threads_7705)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_7706) {
                                // write result
                                {
                                    ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7698;
                                    x_7699 = x_7698;
                                }
                            }
                            if (sle32(wave_sizze_7687, skip_threads_7705)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_7705 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_7708 = squot32(local_tid_7685, 32) == 0 || !ltid_in_bounds_7701;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_7708) {
                            x_7180 = x_7179;
                            x_7179 = ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(squot32(local_tid_7685, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_7709 = slt64(srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595), sext_i32_i64(local_tid_7685) - sext_i32_i64(squot32(local_tid_7685, 32) * 32 - 1));
                        
                        if (!no_carry_in_7708) {
                            if (inactive_7709) {
                                x_7179 = x_7180;
                            }
                        }
                        if (!no_carry_in_7708) {
                            if (!inactive_7709) {
                                int64_t defunc_1_op_res_7181 = add64(x_7179, x_7180);
                                
                                x_7179 = defunc_1_op_res_7181;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_7708) {
                            ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7179;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701) {
                        ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7180;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682) + sext_i32_i64(local_tid_7685), (int64_t) 256) && slt64(sext_i32_i64(local_tid_7685), squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682))) {
                int64_t tmp_7710 = ((__local int64_t *) red_arr_mem_7689)[(sext_i32_i64(local_tid_7685) + (int64_t) 1) * segment_sizze_nonzzero_7682 - (int64_t) 1];
                
                ((__global int64_t *) mem_7541)[sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7171, segment_sizze_nonzzero_7682) + sext_i32_i64(local_tid_7685)] = tmp_7710;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef seghist_group_sizze_7171
}
__kernel void chunked_entropyzisegmap_7269(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_6950, int64_t chunk_sizze_6951, int64_t range_end_7044, __global unsigned char *xs_mem_7539, __global unsigned char *mem_7564)
{
    #define segmap_group_sizze_7265 (chunked_entropyzisegmap_group_sizze_7216)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7579;
    int64_t group_sizze_7582;
    int32_t wave_sizze_7581;
    int32_t group_tid_7580;
    
    local_tid_7579 = get_local_id(0);
    group_sizze_7582 = get_local_size(0);
    wave_sizze_7581 = LOCKSTEP_WIDTH;
    group_tid_7580 = get_group_id(0);
    
    int32_t global_tid_7578 = group_tid_7580 * group_sizze_7582 + local_tid_7579;
    int32_t phys_tid_7269 = global_tid_7578;
    int64_t global_tid_7583 = sext_i32_i64(group_tid_7580) * segmap_group_sizze_7265 + sext_i32_i64(local_tid_7579);
    int64_t slice_7584 = range_end_7044;
    int64_t gtid_7268 = global_tid_7583;
    int64_t remnant_7585 = global_tid_7583 - gtid_7268;
    
    if (slt64(gtid_7268, range_end_7044)) {
        int64_t index_primexp_7491 = add64((int64_t) 1, gtid_7268);
        int64_t i_7271 = mul64(chunk_sizze_6951, index_primexp_7491);
        int64_t x_7272 = add64((int64_t) 2, gtid_7268);
        int64_t j_7273 = mul64(chunk_sizze_6951, x_7272);
        int64_t j_m_i_7274 = sub64(j_7273, i_7271);
        bool empty_slice_7275 = j_m_i_7274 == (int64_t) 0;
        int64_t m_7276 = sub64(j_m_i_7274, (int64_t) 1);
        int64_t i_p_m_t_s_7277 = add64(i_7271, m_7276);
        bool zzero_leq_i_p_m_t_s_7278 = sle64((int64_t) 0, i_p_m_t_s_7277);
        bool i_p_m_t_s_leq_w_7279 = slt64(i_p_m_t_s_7277, n_6950);
        bool zzero_lte_i_7280 = sle64((int64_t) 0, i_7271);
        bool i_lte_j_7281 = sle64(i_7271, j_7273);
        bool y_7282 = i_p_m_t_s_leq_w_7279 && zzero_lte_i_7280;
        bool y_7283 = zzero_leq_i_p_m_t_s_7278 && y_7282;
        bool y_7284 = i_lte_j_7281 && y_7283;
        bool forwards_ok_7285 = zzero_lte_i_7280 && y_7284;
        bool ok_or_empty_7286 = empty_slice_7275 || forwards_ok_7285;
        bool index_certs_7287;
        
        if (!ok_or_empty_7286) {
            {
                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {
                    global_failure_args[0] = (int64_t) i_7271;
                    global_failure_args[1] = (int64_t) j_7273;
                    global_failure_args[2] = (int64_t) n_6950;
                    ;
                }
                return;
            }
        }
        
        int64_t mem_7559[(int64_t) 256];
        
        for (int64_t i_7586 = 0; i_7586 < (int64_t) 256; i_7586++) {
            mem_7559[i_7586] = (int64_t) 0;
        }
        for (int64_t iter_7512 = 0; iter_7512 < j_m_i_7274; iter_7512++) {
            int64_t slice_7537 = i_7271 + iter_7512;
            int8_t pixel_7514 = ((__global int8_t *) xs_mem_7539)[slice_7537];
            int64_t defunc_0_f_res_7297 = zext_i8_i64(pixel_7514);
            bool less_than_zzero_7516 = slt64(defunc_0_f_res_7297, (int64_t) 0);
            bool greater_than_sizze_7517 = sle64((int64_t) 256, defunc_0_f_res_7297);
            bool outside_bounds_dim_7518 = less_than_zzero_7516 || greater_than_sizze_7517;
            
            if (!(outside_bounds_dim_7518 == 1)) {
                int64_t read_hist_7520 = mem_7559[defunc_0_f_res_7297];
                int64_t defunc_1_op_res_7294 = add64((int64_t) 1, read_hist_7520);
                
                mem_7559[defunc_0_f_res_7297] = defunc_1_op_res_7294;
            }
        }
        
        float i64_res_7298 = sitofp_i64_f32(j_m_i_7274);
        float defunc_0_f_res_7299;
        float redout_7523 = 0.0F;
        
        for (int32_t i_7536 = 0; i_7536 < 256; i_7536++) {
            int64_t i_7524 = sext_i32_i64(i_7536);
            int64_t x_7303 = mem_7559[i_7524];
            float defunc_0_f_res_7304 = sitofp_i64_f32(x_7303);
            float defunc_0_f_res_7305 = defunc_0_f_res_7304 / i64_res_7298;
            bool cond_7306 = defunc_0_f_res_7305 == 0.0F;
            float defunc_0_f_res_7307;
            
            if (cond_7306 == 1) {
                defunc_0_f_res_7307 = 0.0F;
            } else {
                float log2_res_7308 = futrts_log2_32(defunc_0_f_res_7305);
                float defunc_0_f_res_f_res_7309 = defunc_0_f_res_7305 * log2_res_7308;
                
                defunc_0_f_res_7307 = defunc_0_f_res_f_res_7309;
            }
            
            float defunc_1_op_res_7302 = defunc_0_f_res_7307 + redout_7523;
            float redout_tmp_7588 = defunc_1_op_res_7302;
            
            redout_7523 = redout_tmp_7588;
        }
        defunc_0_f_res_7299 = redout_7523;
        
        float x_7310 = -1.0F * defunc_0_f_res_7299;
        float log2_res_7311 = futrts_log2_32(i64_res_7298);
        float defunc_0_f_res_7312 = x_7310 / log2_res_7311;
        
        ((__global float *) mem_7564)[gtid_7268] = defunc_0_f_res_7312;
    }
    
  error_0:
    return;
    #undef segmap_group_sizze_7265
}
__kernel void chunked_entropyzisegmap_7425(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_6950, int64_t chunk_sizze_6951, int64_t range_end_7044, int64_t num_groups_7420, int32_t virt_num_groups_7589, __global unsigned char *xs_mem_7539, __global unsigned char *mem_7546, __global unsigned char *mem_7549)
{
    #define segmap_group_sizze_7419 (chunked_entropyzisegmap_group_sizze_7380)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    volatile __local bool local_failure;
    
    if (failure_is_an_option) {
        int failed = *global_failure >= 0;
        
        if (failed)
            return;
    }
    local_failure = false;
    barrier(CLK_LOCAL_MEM_FENCE);
    
    int32_t local_tid_7591;
    int64_t group_sizze_7594;
    int32_t wave_sizze_7593;
    int32_t group_tid_7592;
    
    local_tid_7591 = get_local_id(0);
    group_sizze_7594 = get_local_size(0);
    wave_sizze_7593 = LOCKSTEP_WIDTH;
    group_tid_7592 = get_group_id(0);
    
    int32_t global_tid_7590 = group_tid_7592 * group_sizze_7594 + local_tid_7591;
    int32_t phys_tid_7425 = global_tid_7590;
    int32_t phys_group_id_7595;
    
    phys_group_id_7595 = get_group_id(0);
    
    int32_t iterations_7596 = sdiv_up32(virt_num_groups_7589 - phys_group_id_7595, sext_i64_i32(num_groups_7420));
    
    for (int32_t i_7597 = 0; i_7597 < iterations_7596; i_7597++) {
        int32_t virt_group_id_7598 = phys_group_id_7595 + i_7597 * sext_i64_i32(num_groups_7420);
        int64_t global_tid_7599 = sext_i32_i64(virt_group_id_7598) * segmap_group_sizze_7419 + sext_i32_i64(local_tid_7591);
        int64_t slice_7600 = range_end_7044;
        int64_t gtid_7424 = global_tid_7599;
        int64_t remnant_7601 = global_tid_7599 - gtid_7424;
        
        if (slt64(gtid_7424, range_end_7044)) {
            int64_t index_primexp_7493 = add64((int64_t) 1, gtid_7424);
            int64_t i_7427 = mul64(chunk_sizze_6951, index_primexp_7493);
            int64_t x_7428 = add64((int64_t) 2, gtid_7424);
            int64_t j_7429 = mul64(chunk_sizze_6951, x_7428);
            int64_t j_m_i_7430 = sub64(j_7429, i_7427);
            bool empty_slice_7431 = j_m_i_7430 == (int64_t) 0;
            int64_t m_7432 = sub64(j_m_i_7430, (int64_t) 1);
            int64_t i_p_m_t_s_7433 = add64(i_7427, m_7432);
            bool zzero_leq_i_p_m_t_s_7434 = sle64((int64_t) 0, i_p_m_t_s_7433);
            bool i_p_m_t_s_leq_w_7435 = slt64(i_p_m_t_s_7433, n_6950);
            bool zzero_lte_i_7436 = sle64((int64_t) 0, i_7427);
            bool i_lte_j_7437 = sle64(i_7427, j_7429);
            bool y_7438 = i_p_m_t_s_leq_w_7435 && zzero_lte_i_7436;
            bool y_7439 = zzero_leq_i_p_m_t_s_7434 && y_7438;
            bool y_7440 = i_lte_j_7437 && y_7439;
            bool forwards_ok_7441 = zzero_lte_i_7436 && y_7440;
            bool ok_or_empty_7442 = empty_slice_7431 || forwards_ok_7441;
            bool index_certs_7443;
            
            if (!ok_or_empty_7442) {
                {
                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {
                        global_failure_args[0] = (int64_t) i_7427;
                        global_failure_args[1] = (int64_t) j_7429;
                        global_failure_args[2] = (int64_t) n_6950;
                        ;
                    }
                    local_failure = true;
                    goto error_0;
                }
            }
            
            int64_t mem_7541[(int64_t) 256];
            
            for (int64_t i_7602 = 0; i_7602 < (int64_t) 256; i_7602++) {
                mem_7541[i_7602] = (int64_t) 0;
            }
            for (int64_t iter_7525 = 0; iter_7525 < j_m_i_7430; iter_7525++) {
                int64_t slice_7538 = i_7427 + iter_7525;
                int8_t pixel_7527 = ((__global int8_t *) xs_mem_7539)[slice_7538];
                int64_t defunc_0_f_res_7455 = zext_i8_i64(pixel_7527);
                bool less_than_zzero_7529 = slt64(defunc_0_f_res_7455, (int64_t) 0);
                bool greater_than_sizze_7530 = sle64((int64_t) 256, defunc_0_f_res_7455);
                bool outside_bounds_dim_7531 = less_than_zzero_7529 || greater_than_sizze_7530;
                
                if (!(outside_bounds_dim_7531 == 1)) {
                    int64_t read_hist_7533 = mem_7541[defunc_0_f_res_7455];
                    int64_t defunc_1_op_res_7452 = add64((int64_t) 1, read_hist_7533);
                    
                    mem_7541[defunc_0_f_res_7455] = defunc_1_op_res_7452;
                }
            }
            
            float i64_res_7456 = sitofp_i64_f32(j_m_i_7430);
            
            for (int64_t i_7604 = 0; i_7604 < (int64_t) 256; i_7604++) {
                int64_t tmp_7605 = mem_7541[i_7604];
                
                ((__global int64_t *) mem_7546)[gtid_7424 + i_7604 * range_end_7044] = tmp_7605;
            }
            ((__global float *) mem_7549)[gtid_7424] = i64_res_7456;
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_0:
    return;
    #undef segmap_group_sizze_7419
}
__kernel void chunked_entropyzisegmap_7483(__global int *global_failure, int64_t chunk_sizze_6951, int64_t range_end_7044, __global unsigned char *mem_7553, __global unsigned char *mem_7557)
{
    #define segmap_group_sizze_7479 (chunked_entropyzisegmap_group_sizze_7318)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7678;
    int64_t group_sizze_7681;
    int32_t wave_sizze_7680;
    int32_t group_tid_7679;
    
    local_tid_7678 = get_local_id(0);
    group_sizze_7681 = get_local_size(0);
    wave_sizze_7680 = LOCKSTEP_WIDTH;
    group_tid_7679 = get_group_id(0);
    
    int32_t global_tid_7677 = group_tid_7679 * group_sizze_7681 + local_tid_7678;
    int32_t phys_tid_7483 = global_tid_7677;
    int64_t global_tid_7682 = sext_i32_i64(group_tid_7679) * segmap_group_sizze_7479 + sext_i32_i64(local_tid_7678);
    int64_t slice_7683 = range_end_7044;
    int64_t gtid_7482 = global_tid_7682;
    int64_t remnant_7684 = global_tid_7682 - gtid_7482;
    
    if (slt64(gtid_7482, range_end_7044)) {
        int64_t binop_y_7496 = add64((int64_t) 2, gtid_7482);
        int64_t binop_x_7497 = mul64(chunk_sizze_6951, binop_y_7496);
        int64_t binop_y_7499 = add64((int64_t) 1, gtid_7482);
        int64_t binop_y_7500 = mul64(chunk_sizze_6951, binop_y_7499);
        int64_t convop_x_7501 = sub64(binop_x_7497, binop_y_7500);
        float index_primexp_7502 = sitofp_i64_f32(convop_x_7501);
        float defunc_0_f_res_7485 = ((__global float *) mem_7553)[gtid_7482];
        float x_7486 = -1.0F * defunc_0_f_res_7485;
        float log2_res_7487 = futrts_log2_32(index_primexp_7502);
        float defunc_0_f_res_7488 = x_7486 / log2_res_7487;
        
        ((__global float *) mem_7557)[gtid_7482] = defunc_0_f_res_7488;
    }
    
  error_0:
    return;
    #undef segmap_group_sizze_7479
}
__kernel void chunked_entropyzisegred_large_7465(__global int *global_failure, __local volatile int64_t *sync_arr_mem_7650_backing_aligned_0, __local volatile int64_t *red_arr_mem_7648_backing_aligned_1, int64_t chunk_sizze_6951, int64_t range_end_7044, int64_t num_groups_7460, int64_t groups_per_segment_7634, int64_t elements_per_thread_7635, int64_t virt_num_groups_7636, int64_t threads_per_segment_7638, __global unsigned char *mem_7546, __global unsigned char *mem_7553, __global unsigned char *segred_tmp_mem_7639, __global unsigned char *chunked_entropyzicounter_mem_7641)
{
    #define segred_group_sizze_7459 (chunked_entropyzisegred_group_sizze_7332)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict sync_arr_mem_7650_backing_1 = (__local volatile unsigned char *) sync_arr_mem_7650_backing_aligned_0;
    __local volatile unsigned char *restrict red_arr_mem_7648_backing_0 = (__local volatile unsigned char *) red_arr_mem_7648_backing_aligned_1;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7644;
    int64_t group_sizze_7647;
    int32_t wave_sizze_7646;
    int32_t group_tid_7645;
    
    local_tid_7644 = get_local_id(0);
    group_sizze_7647 = get_local_size(0);
    wave_sizze_7646 = LOCKSTEP_WIDTH;
    group_tid_7645 = get_group_id(0);
    
    int32_t global_tid_7643 = group_tid_7645 * group_sizze_7647 + local_tid_7644;
    int32_t phys_tid_7465 = global_tid_7643;
    __local unsigned char *red_arr_mem_7648;
    
    red_arr_mem_7648 = (__local unsigned char *) red_arr_mem_7648_backing_0;
    
    __local unsigned char *sync_arr_mem_7650;
    
    sync_arr_mem_7650 = (__local unsigned char *) sync_arr_mem_7650_backing_1;
    
    int32_t phys_group_id_7652;
    
    phys_group_id_7652 = get_group_id(0);
    
    int32_t iterations_7653 = sdiv_up32(sext_i64_i32(virt_num_groups_7636) - phys_group_id_7652, sext_i64_i32(num_groups_7460));
    
    for (int32_t i_7654 = 0; i_7654 < iterations_7653; i_7654++) {
        int32_t virt_group_id_7655 = phys_group_id_7652 + i_7654 * sext_i64_i32(num_groups_7460);
        int32_t flat_segment_id_7656 = squot32(virt_group_id_7655, sext_i64_i32(groups_per_segment_7634));
        int64_t global_tid_7657 = srem64(sext_i32_i64(virt_group_id_7655) * segred_group_sizze_7459 + sext_i32_i64(local_tid_7644), segred_group_sizze_7459 * groups_per_segment_7634);
        int64_t slice_7658 = range_end_7044;
        int64_t gtid_7463 = sext_i32_i64(flat_segment_id_7656);
        int64_t remnant_7659 = sext_i32_i64(flat_segment_id_7656) - gtid_7463;
        int64_t gtid_7464;
        float x_acc_7660;
        int64_t chunk_sizze_7661 = smin64(elements_per_thread_7635, sdiv_up64((int64_t) 256 - global_tid_7657, threads_per_segment_7638));
        float x_7466;
        float x_7467;
        
        // neutral-initialise the accumulators
        {
            x_acc_7660 = 0.0F;
        }
        for (int64_t i_7665 = 0; i_7665 < chunk_sizze_7661; i_7665++) {
            gtid_7464 = global_tid_7657 + threads_per_segment_7638 * i_7665;
            // apply map function
            {
                int64_t binop_y_7505 = add64((int64_t) 2, gtid_7463);
                int64_t binop_x_7506 = mul64(chunk_sizze_6951, binop_y_7505);
                int64_t binop_y_7508 = add64((int64_t) 1, gtid_7463);
                int64_t binop_y_7509 = mul64(chunk_sizze_6951, binop_y_7508);
                int64_t convop_x_7510 = sub64(binop_x_7506, binop_y_7509);
                float index_primexp_7511 = sitofp_i64_f32(convop_x_7510);
                int64_t x_7471 = ((__global int64_t *) mem_7546)[gtid_7464 * range_end_7044 + gtid_7463];
                float defunc_0_f_res_7472 = sitofp_i64_f32(x_7471);
                float defunc_0_f_res_7473 = defunc_0_f_res_7472 / index_primexp_7511;
                bool cond_7474 = defunc_0_f_res_7473 == 0.0F;
                float defunc_0_f_res_7475;
                
                if (cond_7474 == 1) {
                    defunc_0_f_res_7475 = 0.0F;
                } else {
                    float log2_res_7476 = futrts_log2_32(defunc_0_f_res_7473);
                    float defunc_0_f_res_f_res_7477 = defunc_0_f_res_7473 * log2_res_7476;
                    
                    defunc_0_f_res_7475 = defunc_0_f_res_f_res_7477;
                }
                // save map-out results
                { }
                // load accumulator
                {
                    x_7466 = x_acc_7660;
                }
                // load new values
                {
                    x_7467 = defunc_0_f_res_7475;
                }
                // apply reduction operator
                {
                    float defunc_1_op_res_7468 = x_7466 + x_7467;
                    
                    // store in accumulator
                    {
                        x_acc_7660 = defunc_1_op_res_7468;
                    }
                }
            }
        }
        // to reduce current chunk, first store our result in memory
        {
            x_7466 = x_acc_7660;
            ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7466;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        
        int32_t offset_7666;
        int32_t skip_waves_7667 = 1;
        float x_7662;
        float x_7663;
        
        offset_7666 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_7644, sext_i64_i32(segred_group_sizze_7459))) {
                x_7662 = ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7666)];
            }
        }
        offset_7666 = 1;
        while (slt32(offset_7666, wave_sizze_7646)) {
            if (slt32(local_tid_7644 + offset_7666, sext_i64_i32(segred_group_sizze_7459)) && ((local_tid_7644 - squot32(local_tid_7644, wave_sizze_7646) * wave_sizze_7646) & (2 * offset_7666 - 1)) == 0) {
                // read array element
                {
                    x_7663 = ((volatile __local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7666)];
                }
                // apply reduction operation
                {
                    float defunc_1_op_res_7664 = x_7662 + x_7663;
                    
                    x_7662 = defunc_1_op_res_7664;
                }
                // write result of operation
                {
                    ((volatile __local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7662;
                }
            }
            offset_7666 *= 2;
        }
        while (slt32(skip_waves_7667, squot32(sext_i64_i32(segred_group_sizze_7459) + wave_sizze_7646 - 1, wave_sizze_7646))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_7666 = skip_waves_7667 * wave_sizze_7646;
            if (slt32(local_tid_7644 + offset_7666, sext_i64_i32(segred_group_sizze_7459)) && ((local_tid_7644 - squot32(local_tid_7644, wave_sizze_7646) * wave_sizze_7646) == 0 && (squot32(local_tid_7644, wave_sizze_7646) & (2 * skip_waves_7667 - 1)) == 0)) {
                // read array element
                {
                    x_7663 = ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7666)];
                }
                // apply reduction operation
                {
                    float defunc_1_op_res_7664 = x_7662 + x_7663;
                    
                    x_7662 = defunc_1_op_res_7664;
                }
                // write result of operation
                {
                    ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7662;
                }
            }
            skip_waves_7667 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // first thread saves the result in accumulator
        {
            if (sext_i32_i64(local_tid_7644) == (int64_t) 0) {
                x_acc_7660 = x_7662;
            }
        }
        if (groups_per_segment_7634 == (int64_t) 1) {
            // first thread in group saves final result to memory
            {
                if (local_tid_7644 == 0) {
                    ((__global float *) mem_7553)[gtid_7463] = x_acc_7660;
                }
            }
        } else {
            int32_t old_counter_7668;
            
            // first thread in group saves group result to global memory
            {
                if (local_tid_7644 == 0) {
                    ((__global float *) segred_tmp_mem_7639)[sext_i32_i64(virt_group_id_7655)] = x_acc_7660;
                    mem_fence_global();
                    old_counter_7668 = atomic_add_i32_global(&((volatile __global int *) chunked_entropyzicounter_mem_7641)[sext_i32_i64(srem32(flat_segment_id_7656, 10240))], (int) 1);
                    ((__local bool *) sync_arr_mem_7650)[(int64_t) 0] = old_counter_7668 == groups_per_segment_7634 - (int64_t) 1;
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            
            bool is_last_group_7669 = ((__local bool *) sync_arr_mem_7650)[(int64_t) 0];
            
            if (is_last_group_7669) {
                if (local_tid_7644 == 0) {
                    old_counter_7668 = atomic_add_i32_global(&((volatile __global int *) chunked_entropyzicounter_mem_7641)[sext_i32_i64(srem32(flat_segment_id_7656, 10240))], (int) ((int64_t) 0 - groups_per_segment_7634));
                }
                // read in the per-group-results
                {
                    int64_t read_per_thread_7670 = sdiv_up64(groups_per_segment_7634, segred_group_sizze_7459);
                    
                    x_7466 = 0.0F;
                    for (int64_t i_7671 = 0; i_7671 < read_per_thread_7670; i_7671++) {
                        int64_t group_res_id_7672 = sext_i32_i64(local_tid_7644) * read_per_thread_7670 + i_7671;
                        int64_t index_of_group_res_7673 = sext_i32_i64(flat_segment_id_7656) * groups_per_segment_7634 + group_res_id_7672;
                        
                        if (slt64(group_res_id_7672, groups_per_segment_7634)) {
                            x_7467 = ((__global float *) segred_tmp_mem_7639)[index_of_group_res_7673];
                            
                            float defunc_1_op_res_7468 = x_7466 + x_7467;
                            
                            x_7466 = defunc_1_op_res_7468;
                        }
                    }
                }
                ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7466;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-group results
                {
                    int32_t offset_7674;
                    int32_t skip_waves_7675 = 1;
                    float x_7662;
                    float x_7663;
                    
                    offset_7674 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_7644, sext_i64_i32(segred_group_sizze_7459))) {
                            x_7662 = ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7674)];
                        }
                    }
                    offset_7674 = 1;
                    while (slt32(offset_7674, wave_sizze_7646)) {
                        if (slt32(local_tid_7644 + offset_7674, sext_i64_i32(segred_group_sizze_7459)) && ((local_tid_7644 - squot32(local_tid_7644, wave_sizze_7646) * wave_sizze_7646) & (2 * offset_7674 - 1)) == 0) {
                            // read array element
                            {
                                x_7663 = ((volatile __local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7674)];
                            }
                            // apply reduction operation
                            {
                                float defunc_1_op_res_7664 = x_7662 + x_7663;
                                
                                x_7662 = defunc_1_op_res_7664;
                            }
                            // write result of operation
                            {
                                ((volatile __local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7662;
                            }
                        }
                        offset_7674 *= 2;
                    }
                    while (slt32(skip_waves_7675, squot32(sext_i64_i32(segred_group_sizze_7459) + wave_sizze_7646 - 1, wave_sizze_7646))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_7674 = skip_waves_7675 * wave_sizze_7646;
                        if (slt32(local_tid_7644 + offset_7674, sext_i64_i32(segred_group_sizze_7459)) && ((local_tid_7644 - squot32(local_tid_7644, wave_sizze_7646) * wave_sizze_7646) == 0 && (squot32(local_tid_7644, wave_sizze_7646) & (2 * skip_waves_7675 - 1)) == 0)) {
                            // read array element
                            {
                                x_7663 = ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644 + offset_7674)];
                            }
                            // apply reduction operation
                            {
                                float defunc_1_op_res_7664 = x_7662 + x_7663;
                                
                                x_7662 = defunc_1_op_res_7664;
                            }
                            // write result of operation
                            {
                                ((__local float *) red_arr_mem_7648)[sext_i32_i64(local_tid_7644)] = x_7662;
                            }
                        }
                        skip_waves_7675 *= 2;
                    }
                    // and back to memory with the final result
                    {
                        if (local_tid_7644 == 0) {
                            ((__global float *) mem_7553)[gtid_7463] = x_7662;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef segred_group_sizze_7459
}
__kernel void chunked_entropyzisegred_small_7465(__global int *global_failure, __local volatile int64_t *red_arr_mem_7613_backing_aligned_0, int64_t chunk_sizze_6951, int64_t range_end_7044, int64_t num_groups_7460, int64_t segment_sizze_nonzzero_7606, __global unsigned char *mem_7546, __global unsigned char *mem_7553)
{
    #define segred_group_sizze_7459 (chunked_entropyzisegred_group_sizze_7332)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict red_arr_mem_7613_backing_0 = (__local volatile unsigned char *) red_arr_mem_7613_backing_aligned_0;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7609;
    int64_t group_sizze_7612;
    int32_t wave_sizze_7611;
    int32_t group_tid_7610;
    
    local_tid_7609 = get_local_id(0);
    group_sizze_7612 = get_local_size(0);
    wave_sizze_7611 = LOCKSTEP_WIDTH;
    group_tid_7610 = get_group_id(0);
    
    int32_t global_tid_7608 = group_tid_7610 * group_sizze_7612 + local_tid_7609;
    int32_t phys_tid_7465 = global_tid_7608;
    __local unsigned char *red_arr_mem_7613;
    
    red_arr_mem_7613 = (__local unsigned char *) red_arr_mem_7613_backing_0;
    
    int32_t phys_group_id_7615;
    
    phys_group_id_7615 = get_group_id(0);
    
    int32_t iterations_7616 = sdiv_up32(sext_i64_i32(sdiv_up64(range_end_7044, squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606))) - phys_group_id_7615, sext_i64_i32(num_groups_7460));
    
    for (int32_t i_7617 = 0; i_7617 < iterations_7616; i_7617++) {
        int32_t virt_group_id_7618 = phys_group_id_7615 + i_7617 * sext_i64_i32(num_groups_7460);
        int64_t slice_7619 = range_end_7044;
        int64_t gtid_7463 = squot64(sext_i32_i64(local_tid_7609), segment_sizze_nonzzero_7606) + sext_i32_i64(virt_group_id_7618) * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606);
        int64_t remnant_7620 = squot64(sext_i32_i64(local_tid_7609), segment_sizze_nonzzero_7606) + sext_i32_i64(virt_group_id_7618) * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606) - gtid_7463;
        int64_t gtid_7464 = srem64(sext_i32_i64(local_tid_7609), (int64_t) 256);
        
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, (int64_t) 256) && (slt64(gtid_7463, range_end_7044) && slt64(sext_i32_i64(local_tid_7609), (int64_t) 256 * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606)))) {
                int64_t binop_y_7505 = add64((int64_t) 2, gtid_7463);
                int64_t binop_x_7506 = mul64(chunk_sizze_6951, binop_y_7505);
                int64_t binop_y_7508 = add64((int64_t) 1, gtid_7463);
                int64_t binop_y_7509 = mul64(chunk_sizze_6951, binop_y_7508);
                int64_t convop_x_7510 = sub64(binop_x_7506, binop_y_7509);
                float index_primexp_7511 = sitofp_i64_f32(convop_x_7510);
                int64_t x_7471 = ((__global int64_t *) mem_7546)[gtid_7464 * range_end_7044 + gtid_7463];
                float defunc_0_f_res_7472 = sitofp_i64_f32(x_7471);
                float defunc_0_f_res_7473 = defunc_0_f_res_7472 / index_primexp_7511;
                bool cond_7474 = defunc_0_f_res_7473 == 0.0F;
                float defunc_0_f_res_7475;
                
                if (cond_7474 == 1) {
                    defunc_0_f_res_7475 = 0.0F;
                } else {
                    float log2_res_7476 = futrts_log2_32(defunc_0_f_res_7473);
                    float defunc_0_f_res_f_res_7477 = defunc_0_f_res_7473 * log2_res_7476;
                    
                    defunc_0_f_res_7475 = defunc_0_f_res_f_res_7477;
                }
                // save map-out results
                { }
                // save results to be reduced
                {
                    ((__local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = defunc_0_f_res_7475;
                }
            } else {
                ((__local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = 0.0F;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, (int64_t) 256)) {
            // perform segmented scan to imitate reduction
            {
                float x_7466;
                float x_7467;
                float x_7621;
                float x_7622;
                bool ltid_in_bounds_7624 = slt64(sext_i32_i64(local_tid_7609), (int64_t) 256 * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606));
                int32_t skip_threads_7625;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_7624) {
                        x_7467 = ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)];
                        if ((local_tid_7609 - squot32(local_tid_7609, 32) * 32) == 0) {
                            x_7466 = x_7467;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_7625 = 1;
                    while (slt32(skip_threads_7625, 32)) {
                        bool thread_active_7626 = sle32(skip_threads_7625, local_tid_7609 - squot32(local_tid_7609, 32) * 32) && ltid_in_bounds_7624;
                        
                        if (thread_active_7626) {
                            // read operands
                            {
                                x_7466 = ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609) - sext_i32_i64(skip_threads_7625)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_7627 = slt64(srem64(sext_i32_i64(local_tid_7609), (int64_t) 256), sext_i32_i64(local_tid_7609) - sext_i32_i64(local_tid_7609 - skip_threads_7625));
                            
                            if (thread_active_7626 && inactive_7627) {
                                x_7466 = x_7467;
                            }
                            if (thread_active_7626) {
                                if (!inactive_7627) {
                                    float defunc_1_op_res_7468 = x_7466 + x_7467;
                                    
                                    x_7466 = defunc_1_op_res_7468;
                                }
                            }
                        }
                        if (sle32(wave_sizze_7611, skip_threads_7625)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_7626) {
                            // write result
                            {
                                ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = x_7466;
                                x_7467 = x_7466;
                            }
                        }
                        if (sle32(wave_sizze_7611, skip_threads_7625)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_7625 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_7609 - squot32(local_tid_7609, 32) * 32) == 31 && ltid_in_bounds_7624) {
                        ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(squot32(local_tid_7609, 32))] = x_7466;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_7628;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_7609, 32) == 0 && ltid_in_bounds_7624) {
                            x_7622 = ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)];
                            if ((local_tid_7609 - squot32(local_tid_7609, 32) * 32) == 0) {
                                x_7621 = x_7622;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_7628 = 1;
                        while (slt32(skip_threads_7628, 32)) {
                            bool thread_active_7629 = sle32(skip_threads_7628, local_tid_7609 - squot32(local_tid_7609, 32) * 32) && (squot32(local_tid_7609, 32) == 0 && ltid_in_bounds_7624);
                            
                            if (thread_active_7629) {
                                // read operands
                                {
                                    x_7621 = ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609) - sext_i32_i64(skip_threads_7628)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_7630 = slt64(srem64(sext_i32_i64(local_tid_7609 * 32 + 32 - 1), (int64_t) 256), sext_i32_i64(local_tid_7609 * 32 + 32 - 1) - sext_i32_i64((local_tid_7609 - skip_threads_7628) * 32 + 32 - 1));
                                
                                if (thread_active_7629 && inactive_7630) {
                                    x_7621 = x_7622;
                                }
                                if (thread_active_7629) {
                                    if (!inactive_7630) {
                                        float defunc_1_op_res_7623 = x_7621 + x_7622;
                                        
                                        x_7621 = defunc_1_op_res_7623;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_7611, skip_threads_7628)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_7629) {
                                // write result
                                {
                                    ((volatile __local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = x_7621;
                                    x_7622 = x_7621;
                                }
                            }
                            if (sle32(wave_sizze_7611, skip_threads_7628)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_7628 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_7631 = squot32(local_tid_7609, 32) == 0 || !ltid_in_bounds_7624;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_7631) {
                            x_7467 = x_7466;
                            x_7466 = ((__local float *) red_arr_mem_7613)[sext_i32_i64(squot32(local_tid_7609, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_7632 = slt64(srem64(sext_i32_i64(local_tid_7609), (int64_t) 256), sext_i32_i64(local_tid_7609) - sext_i32_i64(squot32(local_tid_7609, 32) * 32 - 1));
                        
                        if (!no_carry_in_7631) {
                            if (inactive_7632) {
                                x_7466 = x_7467;
                            }
                        }
                        if (!no_carry_in_7631) {
                            if (!inactive_7632) {
                                float defunc_1_op_res_7468 = x_7466 + x_7467;
                                
                                x_7466 = defunc_1_op_res_7468;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_7631) {
                            ((__local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = x_7466;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_7609, 32) == 0 && ltid_in_bounds_7624) {
                        ((__local float *) red_arr_mem_7613)[sext_i32_i64(local_tid_7609)] = x_7467;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_group_id_7618) * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606) + sext_i32_i64(local_tid_7609), range_end_7044) && slt64(sext_i32_i64(local_tid_7609), squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606))) {
                float tmp_7633 = ((__local float *) red_arr_mem_7613)[(sext_i32_i64(local_tid_7609) + (int64_t) 1) * segment_sizze_nonzzero_7606 - (int64_t) 1];
                
                ((__global float *) mem_7553)[sext_i32_i64(virt_group_id_7618) * squot64(segred_group_sizze_7459, segment_sizze_nonzzero_7606) + sext_i32_i64(local_tid_7609)] = tmp_7633;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef segred_group_sizze_7459
}
__kernel void entropyziseghist_global_7194(__global int *global_failure, int64_t n_6801, int64_t num_groups_7189, int32_t num_subhistos_7595, int32_t chk_i_7665, int64_t hist_H_chk_7666, __global unsigned char *xs_mem_7539, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    #define seghist_group_sizze_7187 (entropyziseghist_group_sizze_7186)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7668;
    int64_t group_sizze_7671;
    int32_t wave_sizze_7670;
    int32_t group_tid_7669;
    
    local_tid_7668 = get_local_id(0);
    group_sizze_7671 = get_local_size(0);
    wave_sizze_7670 = LOCKSTEP_WIDTH;
    group_tid_7669 = get_group_id(0);
    
    int32_t global_tid_7667 = group_tid_7669 * group_sizze_7671 + local_tid_7668;
    int32_t phys_tid_7194 = global_tid_7667;
    int32_t subhisto_ind_7672 = squot32(global_tid_7667, sdiv_up32(sext_i64_i32(seghist_group_sizze_7187 * num_groups_7189), num_subhistos_7595));
    int64_t num_chunks_7673 = sdiv_up64(n_6801, sext_i32_i64(sext_i64_i32(seghist_group_sizze_7187 * num_groups_7189)));
    
    for (int64_t chunk_i_7674 = 0; chunk_i_7674 < num_chunks_7673; chunk_i_7674++) {
        int64_t i_7675 = chunk_i_7674 * sext_i32_i64(sext_i64_i32(seghist_group_sizze_7187 * num_groups_7189)) + sext_i32_i64(global_tid_7667);
        
        if (slt64(i_7675, n_6801)) {
            int64_t slice_7676 = n_6801;
            int64_t gtid_7193 = i_7675;
            int64_t remnant_7677 = i_7675 - gtid_7193;
            
            if (slt64(i_7675, n_6801)) {
                int8_t x_7198 = ((__global int8_t *) xs_mem_7539)[gtid_7193];
                int64_t defunc_0_f_res_7200 = zext_i8_i64(x_7198);
                
                // save map-out results
                { }
                // perform atomic updates
                {
                    if (sle64(sext_i32_i64(chk_i_7665) * hist_H_chk_7666, defunc_0_f_res_7200) && (slt64(defunc_0_f_res_7200, sext_i32_i64(chk_i_7665) * hist_H_chk_7666 + hist_H_chk_7666) && (sle64((int64_t) 0, defunc_0_f_res_7200) && slt64(defunc_0_f_res_7200, (int64_t) 256)))) {
                        int64_t x_7195;
                        int64_t x_7196 = (int64_t) 1;
                        int64_t old_7678;
                        
                        old_7678 = atomic_add_i64_global(&((volatile __global int64_t *) defunc_1_map_res_subhistos_mem_7596)[sext_i32_i64(subhisto_ind_7672) * (int64_t) 256 + defunc_0_f_res_7200], (int64_t) x_7196);
                    }
                }
            }
        }
    }
    
  error_0:
    return;
    #undef seghist_group_sizze_7187
}
__kernel void entropyziseghist_local_7194(__global int *global_failure, __local volatile int64_t *subhistogram_local_mem_7634_backing_aligned_0, int64_t n_6801, int32_t max_group_sizze_7605, int64_t num_groups_7606, int32_t hist_M_7612, int32_t chk_i_7616, int64_t num_segments_7617, int64_t hist_H_chk_7618, int64_t histo_sizze_7619, int32_t init_per_thread_7620, __global unsigned char *xs_mem_7539, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict subhistogram_local_mem_7634_backing_0 = (__local volatile unsigned char *) subhistogram_local_mem_7634_backing_aligned_0;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7622;
    int64_t group_sizze_7625;
    int32_t wave_sizze_7624;
    int32_t group_tid_7623;
    
    local_tid_7622 = get_local_id(0);
    group_sizze_7625 = get_local_size(0);
    wave_sizze_7624 = LOCKSTEP_WIDTH;
    group_tid_7623 = get_group_id(0);
    
    int32_t global_tid_7621 = group_tid_7623 * group_sizze_7625 + local_tid_7622;
    int32_t phys_tid_7194 = global_tid_7621;
    int32_t phys_group_id_7626;
    
    phys_group_id_7626 = get_group_id(0);
    
    int32_t iterations_7627 = sdiv_up32(sext_i64_i32(num_groups_7606 * num_segments_7617) - phys_group_id_7626, sext_i64_i32(num_groups_7606));
    
    for (int32_t i_7628 = 0; i_7628 < iterations_7627; i_7628++) {
        int32_t virt_group_id_7629 = phys_group_id_7626 + i_7628 * sext_i64_i32(num_groups_7606);
        int32_t flat_segment_id_7630 = squot32(virt_group_id_7629, sext_i64_i32(num_groups_7606));
        int32_t gid_in_segment_7631 = srem32(virt_group_id_7629, sext_i64_i32(num_groups_7606));
        int32_t pgtid_in_segment_7632 = gid_in_segment_7631 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
        int32_t threads_per_segment_7633 = sext_i64_i32(num_groups_7606 * max_group_sizze_7605);
        __local unsigned char *subhistogram_local_mem_7634;
        
        subhistogram_local_mem_7634 = (__local unsigned char *) subhistogram_local_mem_7634_backing_0;
        
        int32_t thread_local_subhisto_i_7636 = srem32(local_tid_7622, hist_M_7612);
        
        // initialize histograms in local memory
        {
            for (int32_t local_i_7637 = 0; local_i_7637 < init_per_thread_7620; local_i_7637++) {
                int32_t j_7638 = local_i_7637 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
                int32_t j_offset_7639 = hist_M_7612 * sext_i64_i32(histo_sizze_7619) * gid_in_segment_7631 + j_7638;
                int32_t local_subhisto_i_7640 = squot32(j_7638, sext_i64_i32(histo_sizze_7619));
                int32_t global_subhisto_i_7641 = squot32(j_offset_7639, sext_i64_i32(histo_sizze_7619));
                
                if (slt32(j_7638, hist_M_7612 * sext_i64_i32(histo_sizze_7619))) {
                    // First subhistogram is initialised from global memory; others with neutral element.
                    {
                        if (global_subhisto_i_7641 == 0) {
                            int64_t tmp_7642 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619))) + sext_i32_i64(chk_i_7616) * hist_H_chk_7618];
                            
                            ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(local_subhisto_i_7640) * hist_H_chk_7618 + sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619)))] = tmp_7642;
                        } else {
                            ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(local_subhisto_i_7640) * hist_H_chk_7618 + sext_i32_i64(srem32(j_7638, sext_i64_i32(histo_sizze_7619)))] = (int64_t) 0;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        
        int32_t num_chunks_7643 = sdiv_up32(sext_i64_i32(n_6801), threads_per_segment_7633);
        
        for (int32_t chunk_i_7644 = 0; chunk_i_7644 < num_chunks_7643; chunk_i_7644++) {
            int32_t i_7645 = chunk_i_7644 * threads_per_segment_7633 + pgtid_in_segment_7632;
            
            if (slt32(i_7645, sext_i64_i32(n_6801))) {
                int64_t gtid_7193 = sext_i32_i64(i_7645);
                int8_t x_7198 = ((__global int8_t *) xs_mem_7539)[gtid_7193];
                int64_t defunc_0_f_res_7200 = zext_i8_i64(x_7198);
                
                if (chk_i_7616 == 0) {
                    // save map-out results
                    { }
                }
                // perform atomic updates
                {
                    if ((sle64((int64_t) 0, defunc_0_f_res_7200) && slt64(defunc_0_f_res_7200, (int64_t) 256)) && (sle64(sext_i32_i64(chk_i_7616) * hist_H_chk_7618, defunc_0_f_res_7200) && slt64(defunc_0_f_res_7200, sext_i32_i64(chk_i_7616) * hist_H_chk_7618 + hist_H_chk_7618))) {
                        int64_t x_7195;
                        int64_t x_7196 = (int64_t) 1;
                        int64_t old_7646;
                        
                        old_7646 = atomic_add_i64_local(&((volatile __local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(thread_local_subhisto_i_7636) * hist_H_chk_7618 + (defunc_0_f_res_7200 - sext_i32_i64(chk_i_7616) * hist_H_chk_7618)], (int64_t) x_7196);
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
        // Compact the multiple local memory subhistograms to result in global memory
        {
            int64_t trunc_H_7647 = smin64(hist_H_chk_7618, (int64_t) 256 - sext_i32_i64(chk_i_7616) * hist_H_chk_7618);
            int32_t histo_sizze_7648 = sext_i64_i32(trunc_H_7647);
            
            for (int32_t local_i_7649 = 0; local_i_7649 < init_per_thread_7620; local_i_7649++) {
                int32_t j_7650 = local_i_7649 * sext_i64_i32(max_group_sizze_7605) + local_tid_7622;
                
                if (slt32(j_7650, histo_sizze_7648)) {
                    int64_t x_7195;
                    int64_t x_7196;
                    
                    // Read values from subhistogram 0.
                    {
                        x_7195 = ((__local int64_t *) subhistogram_local_mem_7634)[sext_i32_i64(j_7650)];
                    }
                    // Accumulate based on values in other subhistograms.
                    {
                        for (int32_t subhisto_id_7651 = 0; subhisto_id_7651 < hist_M_7612 - 1; subhisto_id_7651++) {
                            x_7196 = ((__local int64_t *) subhistogram_local_mem_7634)[(sext_i32_i64(subhisto_id_7651) + (int64_t) 1) * hist_H_chk_7618 + sext_i32_i64(j_7650)];
                            
                            int64_t defunc_1_op_res_7197 = add64(x_7195, x_7196);
                            
                            x_7195 = defunc_1_op_res_7197;
                        }
                    }
                    // Put final bucket value in global memory.
                    {
                        ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[srem64(sext_i32_i64(virt_group_id_7629), num_groups_7606) * (int64_t) 256 + (sext_i32_i64(j_7650) + sext_i32_i64(chk_i_7616) * hist_H_chk_7618)] = x_7195;
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
}
__kernel void entropyzisegred_large_7681(__global int *global_failure, __local volatile int64_t *sync_arr_mem_7727_backing_aligned_0, __local volatile int64_t *red_arr_mem_7725_backing_aligned_1, int64_t num_groups_7189, int32_t num_subhistos_7595, int64_t groups_per_segment_7711, int64_t elements_per_thread_7712, int64_t virt_num_groups_7713, int64_t threads_per_segment_7715, __global unsigned char *mem_7541, __global unsigned char *defunc_1_map_res_subhistos_mem_7596, __global unsigned char *segred_tmp_mem_7716, __global unsigned char *entropyzicounter_mem_7718)
{
    #define seghist_group_sizze_7187 (entropyziseghist_group_sizze_7186)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict sync_arr_mem_7727_backing_1 = (__local volatile unsigned char *) sync_arr_mem_7727_backing_aligned_0;
    __local volatile unsigned char *restrict red_arr_mem_7725_backing_0 = (__local volatile unsigned char *) red_arr_mem_7725_backing_aligned_1;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7721;
    int64_t group_sizze_7724;
    int32_t wave_sizze_7723;
    int32_t group_tid_7722;
    
    local_tid_7721 = get_local_id(0);
    group_sizze_7724 = get_local_size(0);
    wave_sizze_7723 = LOCKSTEP_WIDTH;
    group_tid_7722 = get_group_id(0);
    
    int32_t global_tid_7720 = group_tid_7722 * group_sizze_7724 + local_tid_7721;
    int32_t flat_gtid_7681 = global_tid_7720;
    __local unsigned char *red_arr_mem_7725;
    
    red_arr_mem_7725 = (__local unsigned char *) red_arr_mem_7725_backing_0;
    
    __local unsigned char *sync_arr_mem_7727;
    
    sync_arr_mem_7727 = (__local unsigned char *) sync_arr_mem_7727_backing_1;
    
    int32_t phys_group_id_7729;
    
    phys_group_id_7729 = get_group_id(0);
    
    int32_t iterations_7730 = sdiv_up32(sext_i64_i32(virt_num_groups_7713) - phys_group_id_7729, sext_i64_i32(num_groups_7189));
    
    for (int32_t i_7731 = 0; i_7731 < iterations_7730; i_7731++) {
        int32_t virt_group_id_7732 = phys_group_id_7729 + i_7731 * sext_i64_i32(num_groups_7189);
        int32_t flat_segment_id_7733 = squot32(virt_group_id_7732, sext_i64_i32(groups_per_segment_7711));
        int64_t global_tid_7734 = srem64(sext_i32_i64(virt_group_id_7732) * seghist_group_sizze_7187 + sext_i32_i64(local_tid_7721), seghist_group_sizze_7187 * groups_per_segment_7711);
        int64_t slice_7735 = (int64_t) 256;
        int64_t bucket_id_7679 = sext_i32_i64(flat_segment_id_7733);
        int64_t remnant_7736 = sext_i32_i64(flat_segment_id_7733) - bucket_id_7679;
        int64_t subhistogram_id_7680;
        int64_t x_acc_7737;
        int64_t chunk_sizze_7738 = smin64(elements_per_thread_7712, sdiv_up64(num_subhistos_7595 - global_tid_7734, threads_per_segment_7715));
        int64_t x_7195;
        int64_t x_7196;
        
        // neutral-initialise the accumulators
        {
            x_acc_7737 = (int64_t) 0;
        }
        for (int64_t i_7742 = 0; i_7742 < chunk_sizze_7738; i_7742++) {
            subhistogram_id_7680 = global_tid_7734 + threads_per_segment_7715 * i_7742;
            // apply map function
            {
                // load accumulator
                {
                    x_7195 = x_acc_7737;
                }
                // load new values
                {
                    x_7196 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[subhistogram_id_7680 * (int64_t) 256 + bucket_id_7679];
                }
                // apply reduction operator
                {
                    int64_t defunc_1_op_res_7197 = add64(x_7195, x_7196);
                    
                    // store in accumulator
                    {
                        x_acc_7737 = defunc_1_op_res_7197;
                    }
                }
            }
        }
        // to reduce current chunk, first store our result in memory
        {
            x_7195 = x_acc_7737;
            ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7195;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        
        int32_t offset_7743;
        int32_t skip_waves_7744 = 1;
        int64_t x_7739;
        int64_t x_7740;
        
        offset_7743 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_7721, sext_i64_i32(seghist_group_sizze_7187))) {
                x_7739 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
            }
        }
        offset_7743 = 1;
        while (slt32(offset_7743, wave_sizze_7723)) {
            if (slt32(local_tid_7721 + offset_7743, sext_i64_i32(seghist_group_sizze_7187)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) & (2 * offset_7743 - 1)) == 0) {
                // read array element
                {
                    x_7740 = ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
                }
                // apply reduction operation
                {
                    int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                    
                    x_7739 = defunc_1_op_res_7741;
                }
                // write result of operation
                {
                    ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                }
            }
            offset_7743 *= 2;
        }
        while (slt32(skip_waves_7744, squot32(sext_i64_i32(seghist_group_sizze_7187) + wave_sizze_7723 - 1, wave_sizze_7723))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_7743 = skip_waves_7744 * wave_sizze_7723;
            if (slt32(local_tid_7721 + offset_7743, sext_i64_i32(seghist_group_sizze_7187)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) == 0 && (squot32(local_tid_7721, wave_sizze_7723) & (2 * skip_waves_7744 - 1)) == 0)) {
                // read array element
                {
                    x_7740 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7743)];
                }
                // apply reduction operation
                {
                    int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                    
                    x_7739 = defunc_1_op_res_7741;
                }
                // write result of operation
                {
                    ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                }
            }
            skip_waves_7744 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // first thread saves the result in accumulator
        {
            if (sext_i32_i64(local_tid_7721) == (int64_t) 0) {
                x_acc_7737 = x_7739;
            }
        }
        if (groups_per_segment_7711 == (int64_t) 1) {
            // first thread in group saves final result to memory
            {
                if (local_tid_7721 == 0) {
                    ((__global int64_t *) mem_7541)[bucket_id_7679] = x_acc_7737;
                }
            }
        } else {
            int32_t old_counter_7745;
            
            // first thread in group saves group result to global memory
            {
                if (local_tid_7721 == 0) {
                    ((__global int64_t *) segred_tmp_mem_7716)[sext_i32_i64(virt_group_id_7732)] = x_acc_7737;
                    mem_fence_global();
                    old_counter_7745 = atomic_add_i32_global(&((volatile __global int *) entropyzicounter_mem_7718)[sext_i32_i64(srem32(flat_segment_id_7733, 10240))], (int) 1);
                    ((__local bool *) sync_arr_mem_7727)[(int64_t) 0] = old_counter_7745 == groups_per_segment_7711 - (int64_t) 1;
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            
            bool is_last_group_7746 = ((__local bool *) sync_arr_mem_7727)[(int64_t) 0];
            
            if (is_last_group_7746) {
                if (local_tid_7721 == 0) {
                    old_counter_7745 = atomic_add_i32_global(&((volatile __global int *) entropyzicounter_mem_7718)[sext_i32_i64(srem32(flat_segment_id_7733, 10240))], (int) ((int64_t) 0 - groups_per_segment_7711));
                }
                // read in the per-group-results
                {
                    int64_t read_per_thread_7747 = sdiv_up64(groups_per_segment_7711, seghist_group_sizze_7187);
                    
                    x_7195 = (int64_t) 0;
                    for (int64_t i_7748 = 0; i_7748 < read_per_thread_7747; i_7748++) {
                        int64_t group_res_id_7749 = sext_i32_i64(local_tid_7721) * read_per_thread_7747 + i_7748;
                        int64_t index_of_group_res_7750 = sext_i32_i64(flat_segment_id_7733) * groups_per_segment_7711 + group_res_id_7749;
                        
                        if (slt64(group_res_id_7749, groups_per_segment_7711)) {
                            x_7196 = ((__global int64_t *) segred_tmp_mem_7716)[index_of_group_res_7750];
                            
                            int64_t defunc_1_op_res_7197 = add64(x_7195, x_7196);
                            
                            x_7195 = defunc_1_op_res_7197;
                        }
                    }
                }
                ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7195;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-group results
                {
                    int32_t offset_7751;
                    int32_t skip_waves_7752 = 1;
                    int64_t x_7739;
                    int64_t x_7740;
                    
                    offset_7751 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_7721, sext_i64_i32(seghist_group_sizze_7187))) {
                            x_7739 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                        }
                    }
                    offset_7751 = 1;
                    while (slt32(offset_7751, wave_sizze_7723)) {
                        if (slt32(local_tid_7721 + offset_7751, sext_i64_i32(seghist_group_sizze_7187)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) & (2 * offset_7751 - 1)) == 0) {
                            // read array element
                            {
                                x_7740 = ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                                
                                x_7739 = defunc_1_op_res_7741;
                            }
                            // write result of operation
                            {
                                ((volatile __local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                            }
                        }
                        offset_7751 *= 2;
                    }
                    while (slt32(skip_waves_7752, squot32(sext_i64_i32(seghist_group_sizze_7187) + wave_sizze_7723 - 1, wave_sizze_7723))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_7751 = skip_waves_7752 * wave_sizze_7723;
                        if (slt32(local_tid_7721 + offset_7751, sext_i64_i32(seghist_group_sizze_7187)) && ((local_tid_7721 - squot32(local_tid_7721, wave_sizze_7723) * wave_sizze_7723) == 0 && (squot32(local_tid_7721, wave_sizze_7723) & (2 * skip_waves_7752 - 1)) == 0)) {
                            // read array element
                            {
                                x_7740 = ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721 + offset_7751)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_1_op_res_7741 = add64(x_7739, x_7740);
                                
                                x_7739 = defunc_1_op_res_7741;
                            }
                            // write result of operation
                            {
                                ((__local int64_t *) red_arr_mem_7725)[sext_i32_i64(local_tid_7721)] = x_7739;
                            }
                        }
                        skip_waves_7752 *= 2;
                    }
                    // and back to memory with the final result
                    {
                        if (local_tid_7721 == 0) {
                            ((__global int64_t *) mem_7541)[bucket_id_7679] = x_7739;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef seghist_group_sizze_7187
}
__kernel void entropyzisegred_nonseg_7210(__global int *global_failure, __local volatile int64_t *red_arr_mem_7766_backing_aligned_0, __local volatile int64_t *sync_arr_mem_7764_backing_aligned_1, float i64_res_7114, int64_t num_groups_7205, int64_t num_threads_7758, __global unsigned char *mem_7541, __global unsigned char *mem_7545, __global unsigned char *entropyzicounter_mem_7754, __global unsigned char *segred_tmp_mem_7756)
{
    #define segred_group_sizze_7203 (entropyzisegred_group_sizze_7202)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict red_arr_mem_7766_backing_1 = (__local volatile unsigned char *) red_arr_mem_7766_backing_aligned_0;
    __local volatile unsigned char *restrict sync_arr_mem_7764_backing_0 = (__local volatile unsigned char *) sync_arr_mem_7764_backing_aligned_1;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7760;
    int64_t group_sizze_7763;
    int32_t wave_sizze_7762;
    int32_t group_tid_7761;
    
    local_tid_7760 = get_local_id(0);
    group_sizze_7763 = get_local_size(0);
    wave_sizze_7762 = LOCKSTEP_WIDTH;
    group_tid_7761 = get_group_id(0);
    
    int32_t global_tid_7759 = group_tid_7761 * group_sizze_7763 + local_tid_7760;
    int32_t phys_tid_7210 = global_tid_7759;
    __local unsigned char *sync_arr_mem_7764;
    
    sync_arr_mem_7764 = (__local unsigned char *) sync_arr_mem_7764_backing_0;
    
    __local unsigned char *red_arr_mem_7766;
    
    red_arr_mem_7766 = (__local unsigned char *) red_arr_mem_7766_backing_1;
    
    int64_t dummy_7208 = (int64_t) 0;
    int64_t gtid_7209 = (int64_t) 0;
    float x_acc_7768;
    int64_t chunk_sizze_7769 = smin64(sdiv_up64((int64_t) 256, sext_i32_i64(sext_i64_i32(segred_group_sizze_7203 * num_groups_7205))), sdiv_up64((int64_t) 256 - phys_tid_7210, num_threads_7758));
    float x_7125;
    float x_7126;
    
    // neutral-initialise the accumulators
    {
        x_acc_7768 = 0.0F;
    }
    for (int64_t i_7773 = 0; i_7773 < chunk_sizze_7769; i_7773++) {
        gtid_7209 = phys_tid_7210 + num_threads_7758 * i_7773;
        // apply map function
        {
            int64_t x_7149 = ((__global int64_t *) mem_7541)[gtid_7209];
            float defunc_0_f_res_7150 = sitofp_i64_f32(x_7149);
            float defunc_0_f_res_7152 = defunc_0_f_res_7150 / i64_res_7114;
            bool cond_7154 = defunc_0_f_res_7152 == 0.0F;
            float defunc_0_f_res_7155;
            
            if (cond_7154 == 1) {
                defunc_0_f_res_7155 = 0.0F;
            } else {
                float log2_res_7156 = futrts_log2_32(defunc_0_f_res_7152);
                float defunc_0_f_res_f_res_7157 = defunc_0_f_res_7152 * log2_res_7156;
                
                defunc_0_f_res_7155 = defunc_0_f_res_f_res_7157;
            }
            // save map-out results
            { }
            // load accumulator
            {
                x_7125 = x_acc_7768;
            }
            // load new values
            {
                x_7126 = defunc_0_f_res_7155;
            }
            // apply reduction operator
            {
                float defunc_1_op_res_7127 = x_7125 + x_7126;
                
                // store in accumulator
                {
                    x_acc_7768 = defunc_1_op_res_7127;
                }
            }
        }
    }
    // to reduce current chunk, first store our result in memory
    {
        x_7125 = x_acc_7768;
        ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7125;
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    
    int32_t offset_7774;
    int32_t skip_waves_7775 = 1;
    float x_7770;
    float x_7771;
    
    offset_7774 = 0;
    // participating threads read initial accumulator
    {
        if (slt32(local_tid_7760, sext_i64_i32(segred_group_sizze_7203))) {
            x_7770 = ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7774)];
        }
    }
    offset_7774 = 1;
    while (slt32(offset_7774, wave_sizze_7762)) {
        if (slt32(local_tid_7760 + offset_7774, sext_i64_i32(segred_group_sizze_7203)) && ((local_tid_7760 - squot32(local_tid_7760, wave_sizze_7762) * wave_sizze_7762) & (2 * offset_7774 - 1)) == 0) {
            // read array element
            {
                x_7771 = ((volatile __local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7774)];
            }
            // apply reduction operation
            {
                float defunc_1_op_res_7772 = x_7770 + x_7771;
                
                x_7770 = defunc_1_op_res_7772;
            }
            // write result of operation
            {
                ((volatile __local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7770;
            }
        }
        offset_7774 *= 2;
    }
    while (slt32(skip_waves_7775, squot32(sext_i64_i32(segred_group_sizze_7203) + wave_sizze_7762 - 1, wave_sizze_7762))) {
        barrier(CLK_LOCAL_MEM_FENCE);
        offset_7774 = skip_waves_7775 * wave_sizze_7762;
        if (slt32(local_tid_7760 + offset_7774, sext_i64_i32(segred_group_sizze_7203)) && ((local_tid_7760 - squot32(local_tid_7760, wave_sizze_7762) * wave_sizze_7762) == 0 && (squot32(local_tid_7760, wave_sizze_7762) & (2 * skip_waves_7775 - 1)) == 0)) {
            // read array element
            {
                x_7771 = ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7774)];
            }
            // apply reduction operation
            {
                float defunc_1_op_res_7772 = x_7770 + x_7771;
                
                x_7770 = defunc_1_op_res_7772;
            }
            // write result of operation
            {
                ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7770;
            }
        }
        skip_waves_7775 *= 2;
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    // first thread saves the result in accumulator
    {
        if (sext_i32_i64(local_tid_7760) == (int64_t) 0) {
            x_acc_7768 = x_7770;
        }
    }
    
    int32_t old_counter_7776;
    
    // first thread in group saves group result to global memory
    {
        if (local_tid_7760 == 0) {
            ((__global float *) segred_tmp_mem_7756)[sext_i32_i64(group_tid_7761)] = x_acc_7768;
            mem_fence_global();
            old_counter_7776 = atomic_add_i32_global(&((volatile __global int *) entropyzicounter_mem_7754)[(int64_t) 0], (int) 1);
            ((__local bool *) sync_arr_mem_7764)[(int64_t) 0] = old_counter_7776 == num_groups_7205 - (int64_t) 1;
        }
    }
    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    
    bool is_last_group_7777 = ((__local bool *) sync_arr_mem_7764)[(int64_t) 0];
    
    if (is_last_group_7777) {
        if (local_tid_7760 == 0) {
            old_counter_7776 = atomic_add_i32_global(&((volatile __global int *) entropyzicounter_mem_7754)[(int64_t) 0], (int) ((int64_t) 0 - num_groups_7205));
        }
        // read in the per-group-results
        {
            int64_t read_per_thread_7778 = sdiv_up64(num_groups_7205, segred_group_sizze_7203);
            
            x_7125 = 0.0F;
            for (int64_t i_7779 = 0; i_7779 < read_per_thread_7778; i_7779++) {
                int64_t group_res_id_7780 = sext_i32_i64(local_tid_7760) * read_per_thread_7778 + i_7779;
                int64_t index_of_group_res_7781 = group_res_id_7780;
                
                if (slt64(group_res_id_7780, num_groups_7205)) {
                    x_7126 = ((__global float *) segred_tmp_mem_7756)[index_of_group_res_7781];
                    
                    float defunc_1_op_res_7127 = x_7125 + x_7126;
                    
                    x_7125 = defunc_1_op_res_7127;
                }
            }
        }
        ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7125;
        barrier(CLK_LOCAL_MEM_FENCE);
        // reduce the per-group results
        {
            int32_t offset_7782;
            int32_t skip_waves_7783 = 1;
            float x_7770;
            float x_7771;
            
            offset_7782 = 0;
            // participating threads read initial accumulator
            {
                if (slt32(local_tid_7760, sext_i64_i32(segred_group_sizze_7203))) {
                    x_7770 = ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7782)];
                }
            }
            offset_7782 = 1;
            while (slt32(offset_7782, wave_sizze_7762)) {
                if (slt32(local_tid_7760 + offset_7782, sext_i64_i32(segred_group_sizze_7203)) && ((local_tid_7760 - squot32(local_tid_7760, wave_sizze_7762) * wave_sizze_7762) & (2 * offset_7782 - 1)) == 0) {
                    // read array element
                    {
                        x_7771 = ((volatile __local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7782)];
                    }
                    // apply reduction operation
                    {
                        float defunc_1_op_res_7772 = x_7770 + x_7771;
                        
                        x_7770 = defunc_1_op_res_7772;
                    }
                    // write result of operation
                    {
                        ((volatile __local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7770;
                    }
                }
                offset_7782 *= 2;
            }
            while (slt32(skip_waves_7783, squot32(sext_i64_i32(segred_group_sizze_7203) + wave_sizze_7762 - 1, wave_sizze_7762))) {
                barrier(CLK_LOCAL_MEM_FENCE);
                offset_7782 = skip_waves_7783 * wave_sizze_7762;
                if (slt32(local_tid_7760 + offset_7782, sext_i64_i32(segred_group_sizze_7203)) && ((local_tid_7760 - squot32(local_tid_7760, wave_sizze_7762) * wave_sizze_7762) == 0 && (squot32(local_tid_7760, wave_sizze_7762) & (2 * skip_waves_7783 - 1)) == 0)) {
                    // read array element
                    {
                        x_7771 = ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760 + offset_7782)];
                    }
                    // apply reduction operation
                    {
                        float defunc_1_op_res_7772 = x_7770 + x_7771;
                        
                        x_7770 = defunc_1_op_res_7772;
                    }
                    // write result of operation
                    {
                        ((__local float *) red_arr_mem_7766)[sext_i32_i64(local_tid_7760)] = x_7770;
                    }
                }
                skip_waves_7783 *= 2;
            }
            // and back to memory with the final result
            {
                if (local_tid_7760 == 0) {
                    ((__global float *) mem_7545)[(int64_t) 0] = x_7770;
                }
            }
        }
    }
    
  error_1:
    return;
    #undef segred_group_sizze_7203
}
__kernel void entropyzisegred_small_7681(__global int *global_failure, __local volatile int64_t *red_arr_mem_7689_backing_aligned_0, int64_t num_groups_7189, int32_t num_subhistos_7595, int64_t segment_sizze_nonzzero_7682, __global unsigned char *mem_7541, __global unsigned char *defunc_1_map_res_subhistos_mem_7596)
{
    #define seghist_group_sizze_7187 (entropyziseghist_group_sizze_7186)
    
    const int block_dim0 = 0;
    const int block_dim1 = 1;
    const int block_dim2 = 2;
    __local volatile unsigned char *restrict red_arr_mem_7689_backing_0 = (__local volatile unsigned char *) red_arr_mem_7689_backing_aligned_0;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_7685;
    int64_t group_sizze_7688;
    int32_t wave_sizze_7687;
    int32_t group_tid_7686;
    
    local_tid_7685 = get_local_id(0);
    group_sizze_7688 = get_local_size(0);
    wave_sizze_7687 = LOCKSTEP_WIDTH;
    group_tid_7686 = get_group_id(0);
    
    int32_t global_tid_7684 = group_tid_7686 * group_sizze_7688 + local_tid_7685;
    int32_t flat_gtid_7681 = global_tid_7684;
    __local unsigned char *red_arr_mem_7689;
    
    red_arr_mem_7689 = (__local unsigned char *) red_arr_mem_7689_backing_0;
    
    int32_t phys_group_id_7691;
    
    phys_group_id_7691 = get_group_id(0);
    
    int32_t iterations_7692 = sdiv_up32(sext_i64_i32(sdiv_up64((int64_t) 256, squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682))) - phys_group_id_7691, sext_i64_i32(num_groups_7189));
    
    for (int32_t i_7693 = 0; i_7693 < iterations_7692; i_7693++) {
        int32_t virt_group_id_7694 = phys_group_id_7691 + i_7693 * sext_i64_i32(num_groups_7189);
        int64_t slice_7695 = (int64_t) 256;
        int64_t bucket_id_7679 = squot64(sext_i32_i64(local_tid_7685), segment_sizze_nonzzero_7682) + sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682);
        int64_t remnant_7696 = squot64(sext_i32_i64(local_tid_7685), segment_sizze_nonzzero_7682) + sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682) - bucket_id_7679;
        int64_t subhistogram_id_7680 = srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595);
        
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, num_subhistos_7595) && (slt64(bucket_id_7679, (int64_t) 256) && slt64(sext_i32_i64(local_tid_7685), num_subhistos_7595 * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682)))) {
                // save results to be reduced
                {
                    int64_t tmp_7697 = ((__global int64_t *) defunc_1_map_res_subhistos_mem_7596)[subhistogram_id_7680 * (int64_t) 256 + bucket_id_7679];
                    
                    ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = tmp_7697;
                }
            } else {
                ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = (int64_t) 0;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, num_subhistos_7595)) {
            // perform segmented scan to imitate reduction
            {
                int64_t x_7195;
                int64_t x_7196;
                int64_t x_7698;
                int64_t x_7699;
                bool ltid_in_bounds_7701 = slt64(sext_i32_i64(local_tid_7685), num_subhistos_7595 * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682));
                int32_t skip_threads_7702;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_7701) {
                        x_7196 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)];
                        if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 0) {
                            x_7195 = x_7196;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_7702 = 1;
                    while (slt32(skip_threads_7702, 32)) {
                        bool thread_active_7703 = sle32(skip_threads_7702, local_tid_7685 - squot32(local_tid_7685, 32) * 32) && ltid_in_bounds_7701;
                        
                        if (thread_active_7703) {
                            // read operands
                            {
                                x_7195 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685) - sext_i32_i64(skip_threads_7702)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_7704 = slt64(srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595), sext_i32_i64(local_tid_7685) - sext_i32_i64(local_tid_7685 - skip_threads_7702));
                            
                            if (thread_active_7703 && inactive_7704) {
                                x_7195 = x_7196;
                            }
                            if (thread_active_7703) {
                                if (!inactive_7704) {
                                    int64_t defunc_1_op_res_7197 = add64(x_7195, x_7196);
                                    
                                    x_7195 = defunc_1_op_res_7197;
                                }
                            }
                        }
                        if (sle32(wave_sizze_7687, skip_threads_7702)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_7703) {
                            // write result
                            {
                                ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7195;
                                x_7196 = x_7195;
                            }
                        }
                        if (sle32(wave_sizze_7687, skip_threads_7702)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_7702 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 31 && ltid_in_bounds_7701) {
                        ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(squot32(local_tid_7685, 32))] = x_7195;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_7705;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701) {
                            x_7699 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)];
                            if ((local_tid_7685 - squot32(local_tid_7685, 32) * 32) == 0) {
                                x_7698 = x_7699;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_7705 = 1;
                        while (slt32(skip_threads_7705, 32)) {
                            bool thread_active_7706 = sle32(skip_threads_7705, local_tid_7685 - squot32(local_tid_7685, 32) * 32) && (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701);
                            
                            if (thread_active_7706) {
                                // read operands
                                {
                                    x_7698 = ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685) - sext_i32_i64(skip_threads_7705)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_7707 = slt64(srem64(sext_i32_i64(local_tid_7685 * 32 + 32 - 1), num_subhistos_7595), sext_i32_i64(local_tid_7685 * 32 + 32 - 1) - sext_i32_i64((local_tid_7685 - skip_threads_7705) * 32 + 32 - 1));
                                
                                if (thread_active_7706 && inactive_7707) {
                                    x_7698 = x_7699;
                                }
                                if (thread_active_7706) {
                                    if (!inactive_7707) {
                                        int64_t defunc_1_op_res_7700 = add64(x_7698, x_7699);
                                        
                                        x_7698 = defunc_1_op_res_7700;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_7687, skip_threads_7705)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_7706) {
                                // write result
                                {
                                    ((volatile __local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7698;
                                    x_7699 = x_7698;
                                }
                            }
                            if (sle32(wave_sizze_7687, skip_threads_7705)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_7705 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_7708 = squot32(local_tid_7685, 32) == 0 || !ltid_in_bounds_7701;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_7708) {
                            x_7196 = x_7195;
                            x_7195 = ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(squot32(local_tid_7685, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_7709 = slt64(srem64(sext_i32_i64(local_tid_7685), num_subhistos_7595), sext_i32_i64(local_tid_7685) - sext_i32_i64(squot32(local_tid_7685, 32) * 32 - 1));
                        
                        if (!no_carry_in_7708) {
                            if (inactive_7709) {
                                x_7195 = x_7196;
                            }
                        }
                        if (!no_carry_in_7708) {
                            if (!inactive_7709) {
                                int64_t defunc_1_op_res_7197 = add64(x_7195, x_7196);
                                
                                x_7195 = defunc_1_op_res_7197;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_7708) {
                            ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7195;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_7685, 32) == 0 && ltid_in_bounds_7701) {
                        ((__local int64_t *) red_arr_mem_7689)[sext_i32_i64(local_tid_7685)] = x_7196;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682) + sext_i32_i64(local_tid_7685), (int64_t) 256) && slt64(sext_i32_i64(local_tid_7685), squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682))) {
                int64_t tmp_7710 = ((__local int64_t *) red_arr_mem_7689)[(sext_i32_i64(local_tid_7685) + (int64_t) 1) * segment_sizze_nonzzero_7682 - (int64_t) 1];
                
                ((__global int64_t *) mem_7541)[sext_i32_i64(virt_group_id_7694) * squot64(seghist_group_sizze_7187, segment_sizze_nonzzero_7682) + sext_i32_i64(local_tid_7685)] = tmp_7710;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef seghist_group_sizze_7187
}
"""
# Start of values.py.

# Hacky parser/reader/writer for values written in Futhark syntax.
# Used for reading stdin when compiling standalone programs with the
# Python code generator.

import numpy as np
import struct
import sys


class ReaderInput:
    def __init__(self, f):
        self.f = f
        self.lookahead_buffer = []

    def get_char(self):
        if len(self.lookahead_buffer) == 0:
            return self.f.read(1)
        else:
            c = self.lookahead_buffer[0]
            self.lookahead_buffer = self.lookahead_buffer[1:]
            return c

    def unget_char(self, c):
        self.lookahead_buffer = [c] + self.lookahead_buffer

    def get_chars(self, n):
        n1 = min(n, len(self.lookahead_buffer))
        s = b"".join(self.lookahead_buffer[:n1])
        self.lookahead_buffer = self.lookahead_buffer[n1:]
        n2 = n - n1
        if n2 > 0:
            s += self.f.read(n2)
        return s

    def peek_char(self):
        c = self.get_char()
        if c:
            self.unget_char(c)
        return c


def skip_spaces(f):
    c = f.get_char()
    while c != None:
        if c.isspace():
            c = f.get_char()
        elif c == b"-":
            # May be line comment.
            if f.peek_char() == b"-":
                # Yes, line comment. Skip to end of line.
                while c != b"\n" and c != None:
                    c = f.get_char()
            else:
                break
        else:
            break
    if c:
        f.unget_char(c)


def parse_specific_char(f, expected):
    got = f.get_char()
    if got != expected:
        f.unget_char(got)
        raise ValueError
    return True


def parse_specific_string(f, s):
    # This funky mess is intended, and is caused by the fact that if `type(b) ==
    # bytes` then `type(b[0]) == int`, but we need to match each element with a
    # `bytes`, so therefore we make each character an array element
    b = s.encode("utf8")
    bs = [b[i : i + 1] for i in range(len(b))]
    read = []
    try:
        for c in bs:
            parse_specific_char(f, c)
            read.append(c)
        return True
    except ValueError:
        for c in read[::-1]:
            f.unget_char(c)
        raise


def optional(p, *args):
    try:
        return p(*args)
    except ValueError:
        return None


def optional_specific_string(f, s):
    c = f.peek_char()
    # This funky mess is intended, and is caused by the fact that if `type(b) ==
    # bytes` then `type(b[0]) == int`, but we need to match each element with a
    # `bytes`, so therefore we make each character an array element
    b = s.encode("utf8")
    bs = [b[i : i + 1] for i in range(len(b))]
    if c == bs[0]:
        return parse_specific_string(f, s)
    else:
        return False


def sepBy(p, sep, *args):
    elems = []
    x = optional(p, *args)
    if x != None:
        elems += [x]
        while optional(sep, *args) != None:
            x = p(*args)
            elems += [x]
    return elems


# Assumes '0x' has already been read
def parse_hex_int(f):
    s = b""
    c = f.get_char()
    while c != None:
        if c in b"01234556789ABCDEFabcdef":
            s += c
            c = f.get_char()
        elif c == b"_":
            c = f.get_char()  # skip _
        else:
            f.unget_char(c)
            break
    return str(int(s, 16)).encode("utf8")  # ugh


def parse_int(f):
    s = b""
    c = f.get_char()
    if c == b"0" and f.peek_char() in b"xX":
        c = f.get_char()  # skip X
        return parse_hex_int(f)
    else:
        while c != None:
            if c.isdigit():
                s += c
                c = f.get_char()
            elif c == b"_":
                c = f.get_char()  # skip _
            else:
                f.unget_char(c)
                break
        if len(s) == 0:
            raise ValueError
        return s


def parse_int_signed(f):
    s = b""
    c = f.get_char()

    if c == b"-" and f.peek_char().isdigit():
        return c + parse_int(f)
    else:
        if c != b"+":
            f.unget_char(c)
        return parse_int(f)


def read_str_comma(f):
    skip_spaces(f)
    parse_specific_char(f, b",")
    return b","


def read_str_int(f, s):
    skip_spaces(f)
    x = int(parse_int_signed(f))
    optional_specific_string(f, s)
    return x


def read_str_uint(f, s):
    skip_spaces(f)
    x = int(parse_int(f))
    optional_specific_string(f, s)
    return x


def read_str_i8(f):
    return np.int8(read_str_int(f, "i8"))


def read_str_i16(f):
    return np.int16(read_str_int(f, "i16"))


def read_str_i32(f):
    return np.int32(read_str_int(f, "i32"))


def read_str_i64(f):
    return np.int64(read_str_int(f, "i64"))


def read_str_u8(f):
    return np.uint8(read_str_int(f, "u8"))


def read_str_u16(f):
    return np.uint16(read_str_int(f, "u16"))


def read_str_u32(f):
    return np.uint32(read_str_int(f, "u32"))


def read_str_u64(f):
    return np.uint64(read_str_int(f, "u64"))


def read_char(f):
    skip_spaces(f)
    parse_specific_char(f, b"'")
    c = f.get_char()
    parse_specific_char(f, b"'")
    return c


def read_str_hex_float(f, sign):
    int_part = parse_hex_int(f)
    parse_specific_char(f, b".")
    frac_part = parse_hex_int(f)
    parse_specific_char(f, b"p")
    exponent = parse_int(f)

    int_val = int(int_part, 16)
    frac_val = float(int(frac_part, 16)) / (16 ** len(frac_part))
    exp_val = int(exponent)

    total_val = (int_val + frac_val) * (2.0**exp_val)
    if sign == b"-":
        total_val = -1 * total_val

    return float(total_val)


def read_str_decimal(f):
    skip_spaces(f)
    c = f.get_char()
    if c == b"-":
        sign = b"-"
    else:
        f.unget_char(c)
        sign = b""

    # Check for hexadecimal float
    c = f.get_char()
    if c == "0" and (f.peek_char() in ["x", "X"]):
        f.get_char()
        return read_str_hex_float(f, sign)
    else:
        f.unget_char(c)

    bef = optional(parse_int, f)
    if bef == None:
        bef = b"0"
        parse_specific_char(f, b".")
        aft = parse_int(f)
    elif optional(parse_specific_char, f, b"."):
        aft = parse_int(f)
    else:
        aft = b"0"
    if optional(parse_specific_char, f, b"E") or optional(parse_specific_char, f, b"e"):
        expt = parse_int_signed(f)
    else:
        expt = b"0"
    return float(sign + bef + b"." + aft + b"E" + expt)


def read_str_f16(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f16.nan")
        return np.float32(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f16.inf")
            return np.float32(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f16.inf")
                return np.float32(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f16")
                return x


def read_str_f32(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f32.nan")
        return np.float32(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f32.inf")
            return np.float32(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f32.inf")
                return np.float32(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f32")
                return x


def read_str_f64(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f64.nan")
        return np.float64(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f64.inf")
            return np.float64(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f64.inf")
                return np.float64(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f64")
                return x


def read_str_bool(f):
    skip_spaces(f)
    if f.peek_char() == b"t":
        parse_specific_string(f, "true")
        return True
    elif f.peek_char() == b"f":
        parse_specific_string(f, "false")
        return False
    else:
        raise ValueError


def read_str_empty_array(f, type_name, rank):
    parse_specific_string(f, "empty")
    parse_specific_char(f, b"(")
    dims = []
    for i in range(rank):
        parse_specific_string(f, "[")
        dims += [int(parse_int(f))]
        parse_specific_string(f, "]")
    if np.product(dims) != 0:
        raise ValueError
    parse_specific_string(f, type_name)
    parse_specific_char(f, b")")

    return tuple(dims)


def read_str_array_elems(f, elem_reader, type_name, rank):
    skip_spaces(f)
    try:
        parse_specific_char(f, b"[")
    except ValueError:
        return read_str_empty_array(f, type_name, rank)
    else:
        xs = sepBy(elem_reader, read_str_comma, f)
        skip_spaces(f)
        parse_specific_char(f, b"]")
        return xs


def read_str_array_helper(f, elem_reader, type_name, rank):
    def nested_row_reader(_):
        return read_str_array_helper(f, elem_reader, type_name, rank - 1)

    if rank == 1:
        row_reader = elem_reader
    else:
        row_reader = nested_row_reader
    return read_str_array_elems(f, row_reader, type_name, rank)


def expected_array_dims(l, rank):
    if rank > 1:
        n = len(l)
        if n == 0:
            elem = []
        else:
            elem = l[0]
        return [n] + expected_array_dims(elem, rank - 1)
    else:
        return [len(l)]


def verify_array_dims(l, dims):
    if dims[0] != len(l):
        raise ValueError
    if len(dims) > 1:
        for x in l:
            verify_array_dims(x, dims[1:])


def read_str_array(f, elem_reader, type_name, rank, bt):
    elems = read_str_array_helper(f, elem_reader, type_name, rank)
    if type(elems) == tuple:
        # Empty array
        return np.empty(elems, dtype=bt)
    else:
        dims = expected_array_dims(elems, rank)
        verify_array_dims(elems, dims)
        return np.array(elems, dtype=bt)


################################################################################

READ_BINARY_VERSION = 2

# struct format specified at
# https://docs.python.org/2/library/struct.html#format-characters


def mk_bin_scalar_reader(t):
    def bin_reader(f):
        fmt = FUTHARK_PRIMTYPES[t]["bin_format"]
        size = FUTHARK_PRIMTYPES[t]["size"]
        tf = FUTHARK_PRIMTYPES[t]["numpy_type"]
        return tf(struct.unpack("<" + fmt, f.get_chars(size))[0])

    return bin_reader


read_bin_i8 = mk_bin_scalar_reader("i8")
read_bin_i16 = mk_bin_scalar_reader("i16")
read_bin_i32 = mk_bin_scalar_reader("i32")
read_bin_i64 = mk_bin_scalar_reader("i64")

read_bin_u8 = mk_bin_scalar_reader("u8")
read_bin_u16 = mk_bin_scalar_reader("u16")
read_bin_u32 = mk_bin_scalar_reader("u32")
read_bin_u64 = mk_bin_scalar_reader("u64")

read_bin_f16 = mk_bin_scalar_reader("f16")
read_bin_f32 = mk_bin_scalar_reader("f32")
read_bin_f64 = mk_bin_scalar_reader("f64")

read_bin_bool = mk_bin_scalar_reader("bool")


def read_is_binary(f):
    skip_spaces(f)
    c = f.get_char()
    if c == b"b":
        bin_version = read_bin_u8(f)
        if bin_version != READ_BINARY_VERSION:
            panic(
                1,
                "binary-input: File uses version %i, but I only understand version %i.\n",
                bin_version,
                READ_BINARY_VERSION,
            )
        return True
    else:
        f.unget_char(c)
        return False


FUTHARK_PRIMTYPES = {
    "i8": {
        "binname": b"  i8",
        "size": 1,
        "bin_reader": read_bin_i8,
        "str_reader": read_str_i8,
        "bin_format": "b",
        "numpy_type": np.int8,
    },
    "i16": {
        "binname": b" i16",
        "size": 2,
        "bin_reader": read_bin_i16,
        "str_reader": read_str_i16,
        "bin_format": "h",
        "numpy_type": np.int16,
    },
    "i32": {
        "binname": b" i32",
        "size": 4,
        "bin_reader": read_bin_i32,
        "str_reader": read_str_i32,
        "bin_format": "i",
        "numpy_type": np.int32,
    },
    "i64": {
        "binname": b" i64",
        "size": 8,
        "bin_reader": read_bin_i64,
        "str_reader": read_str_i64,
        "bin_format": "q",
        "numpy_type": np.int64,
    },
    "u8": {
        "binname": b"  u8",
        "size": 1,
        "bin_reader": read_bin_u8,
        "str_reader": read_str_u8,
        "bin_format": "B",
        "numpy_type": np.uint8,
    },
    "u16": {
        "binname": b" u16",
        "size": 2,
        "bin_reader": read_bin_u16,
        "str_reader": read_str_u16,
        "bin_format": "H",
        "numpy_type": np.uint16,
    },
    "u32": {
        "binname": b" u32",
        "size": 4,
        "bin_reader": read_bin_u32,
        "str_reader": read_str_u32,
        "bin_format": "I",
        "numpy_type": np.uint32,
    },
    "u64": {
        "binname": b" u64",
        "size": 8,
        "bin_reader": read_bin_u64,
        "str_reader": read_str_u64,
        "bin_format": "Q",
        "numpy_type": np.uint64,
    },
    "f16": {
        "binname": b" f16",
        "size": 2,
        "bin_reader": read_bin_f16,
        "str_reader": read_str_f16,
        "bin_format": "e",
        "numpy_type": np.float16,
    },
    "f32": {
        "binname": b" f32",
        "size": 4,
        "bin_reader": read_bin_f32,
        "str_reader": read_str_f32,
        "bin_format": "f",
        "numpy_type": np.float32,
    },
    "f64": {
        "binname": b" f64",
        "size": 8,
        "bin_reader": read_bin_f64,
        "str_reader": read_str_f64,
        "bin_format": "d",
        "numpy_type": np.float64,
    },
    "bool": {
        "binname": b"bool",
        "size": 1,
        "bin_reader": read_bin_bool,
        "str_reader": read_str_bool,
        "bin_format": "b",
        "numpy_type": bool,
    },
}


def read_bin_read_type(f):
    read_binname = f.get_chars(4)

    for k, v in FUTHARK_PRIMTYPES.items():
        if v["binname"] == read_binname:
            return k
    panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname)


def numpy_type_to_type_name(t):
    for k, v in FUTHARK_PRIMTYPES.items():
        if v["numpy_type"] == t:
            return k
    raise Exception(f"Unknown Numpy type: {t}")


def read_bin_ensure_scalar(f, expected_type):
    dims = read_bin_i8(f)

    if dims != 0:
        panic(
            1,
            "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
            dims,
        )

    bin_type = read_bin_read_type(f)
    if bin_type != expected_type:
        panic(
            1,
            "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
            expected_type,
            bin_type,
        )


# ------------------------------------------------------------------------------
# General interface for reading Primitive Futhark Values
# ------------------------------------------------------------------------------


def read_scalar(f, ty):
    if read_is_binary(f):
        read_bin_ensure_scalar(f, ty)
        return FUTHARK_PRIMTYPES[ty]["bin_reader"](f)
    return FUTHARK_PRIMTYPES[ty]["str_reader"](f)


def read_array(f, expected_type, rank):
    if not read_is_binary(f):
        str_reader = FUTHARK_PRIMTYPES[expected_type]["str_reader"]
        return read_str_array(
            f, str_reader, expected_type, rank, FUTHARK_PRIMTYPES[expected_type]["numpy_type"]
        )

    bin_rank = read_bin_u8(f)

    if bin_rank != rank:
        panic(
            1,
            "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
            rank,
            bin_rank,
        )

    bin_type_enum = read_bin_read_type(f)
    if expected_type != bin_type_enum:
        panic(
            1,
            "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
            rank,
            expected_type,
            bin_rank,
            bin_type_enum,
        )

    shape = []
    elem_count = 1
    for i in range(rank):
        bin_size = read_bin_i64(f)
        elem_count *= bin_size
        shape.append(bin_size)

    bin_fmt = FUTHARK_PRIMTYPES[bin_type_enum]["bin_format"]

    # We first read the expected number of types into a bytestring,
    # then use np.frombuffer.  This is because np.fromfile does not
    # work on things that are insufficiently file-like, like a network
    # stream.
    bytes = f.get_chars(elem_count * FUTHARK_PRIMTYPES[expected_type]["size"])
    arr = np.frombuffer(bytes, dtype=FUTHARK_PRIMTYPES[bin_type_enum]["numpy_type"])
    arr.shape = shape

    return arr


input_reader = ReaderInput(sys.stdin.buffer)

import re


def read_value(type_desc, reader=input_reader):
    """Read a value of the given type.  The type is a string
    representation of the Futhark type."""
    m = re.match(r"((?:\[\])*)([a-z0-9]+)$", type_desc)
    if m:
        dims = int(len(m.group(1)) / 2)
        basetype = m.group(2)
    assert m and basetype in FUTHARK_PRIMTYPES, f"Unknown type: {type_desc}"
    if dims > 0:
        return read_array(reader, basetype, dims)
    else:
        return read_scalar(reader, basetype)


def end_of_input(entry, f=input_reader):
    skip_spaces(f)
    if f.get_char() != b"":
        panic(1, 'Expected EOF on stdin after reading input for "%s".', entry)


def write_value_text(v, out=sys.stdout):
    if type(v) == np.uint8:
        out.write("%uu8" % v)
    elif type(v) == np.uint16:
        out.write("%uu16" % v)
    elif type(v) == np.uint32:
        out.write("%uu32" % v)
    elif type(v) == np.uint64:
        out.write("%uu64" % v)
    elif type(v) == np.int8:
        out.write("%di8" % v)
    elif type(v) == np.int16:
        out.write("%di16" % v)
    elif type(v) == np.int32:
        out.write("%di32" % v)
    elif type(v) == np.int64:
        out.write("%di64" % v)
    elif type(v) in [bool, np.bool_]:
        if v:
            out.write("true")
        else:
            out.write("false")
    elif type(v) == np.float16:
        if np.isnan(v):
            out.write("f16.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f16.inf")
            else:
                out.write("-f16.inf")
        else:
            out.write("%.6ff16" % v)
    elif type(v) == np.float32:
        if np.isnan(v):
            out.write("f32.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f32.inf")
            else:
                out.write("-f32.inf")
        else:
            out.write("%.6ff32" % v)
    elif type(v) == np.float64:
        if np.isnan(v):
            out.write("f64.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f64.inf")
            else:
                out.write("-f64.inf")
        else:
            out.write("%.6ff64" % v)
    elif type(v) == np.ndarray:
        if np.product(v.shape) == 0:
            tname = numpy_type_to_type_name(v.dtype)
            out.write("empty({}{})".format("".join([f"[{d}]" for d in v.shape]), tname))
        else:
            first = True
            out.write("[")
            for x in v:
                if not first:
                    out.write(", ")
                first = False
                write_value(x, out=out)
            out.write("]")
    else:
        raise Exception(f"Cannot print value of type {type(v)}: {v}")


type_strs = {
    np.dtype("int8"): b"  i8",
    np.dtype("int16"): b" i16",
    np.dtype("int32"): b" i32",
    np.dtype("int64"): b" i64",
    np.dtype("uint8"): b"  u8",
    np.dtype("uint16"): b" u16",
    np.dtype("uint32"): b" u32",
    np.dtype("uint64"): b" u64",
    np.dtype("float16"): b" f16",
    np.dtype("float32"): b" f32",
    np.dtype("float64"): b" f64",
    np.dtype("bool"): b"bool",
}


def construct_binary_value(v):
    t = v.dtype
    shape = v.shape

    elems = 1
    for d in shape:
        elems *= d

    num_bytes = 1 + 1 + 1 + 4 + len(shape) * 8 + elems * t.itemsize
    bytes = bytearray(num_bytes)
    bytes[0] = np.int8(ord("b"))
    bytes[1] = 2
    bytes[2] = np.int8(len(shape))
    bytes[3:7] = type_strs[t]

    for i in range(len(shape)):
        bytes[7 + i * 8 : 7 + (i + 1) * 8] = np.int64(shape[i]).tobytes()

    bytes[7 + len(shape) * 8 :] = np.ascontiguousarray(v).tobytes()

    return bytes


def write_value_binary(v, out=sys.stdout):
    out = out.buffer
    out.write(construct_binary_value(v))


def write_value(v, out=sys.stdout, binary=False):
    if binary:
        return write_value_binary(v, out=out)
    else:
        return write_value_text(v, out=out)


# End of values.py.
# Start of memory.py.

import ctypes as ct


def addressOffset(x, offset, bt):
    return ct.cast(ct.addressof(x.contents) + int(offset), ct.POINTER(bt))


def allocateMem(size):
    return ct.cast((ct.c_byte * max(0, size))(), ct.POINTER(ct.c_byte))


# Copy an array if its is not-None.  This is important for treating
# Numpy arrays as flat memory, but has some overhead.
def normaliseArray(x):
    if (x.base is x) or (x.base is None):
        return x
    else:
        return x.copy()


def unwrapArray(x):
    return normaliseArray(x).ctypes.data_as(ct.POINTER(ct.c_byte))


def createArray(x, shape, t):
    # HACK: np.ctypeslib.as_array may fail if the shape contains zeroes,
    # for some reason.
    if any(map(lambda x: x == 0, shape)):
        return np.ndarray(shape, dtype=t)
    else:
        return np.ctypeslib.as_array(x, shape=shape).view(t)


def indexArray(x, offset, bt):
    return addressOffset(x, offset * ct.sizeof(bt), bt)[0]


def writeScalarArray(x, offset, v):
    ct.memmove(ct.addressof(x.contents) + int(offset) * ct.sizeof(v), ct.addressof(v), ct.sizeof(v))


# An opaque Futhark value.
class opaque:
    def __init__(self, desc, *payload):
        self.data = payload
        self.desc = desc

    def __repr__(self):
        return f"<opaque Futhark value of type {self.desc}>"


# End of memory.py.
# Start of panic.py.


def panic(exitcode, fmt, *args):
    sys.stderr.write("%s: " % sys.argv[0])
    sys.stderr.write(fmt % args)
    sys.stderr.write("\n")
    sys.exit(exitcode)


# End of panic.py.
# Start of tuning.py


def read_tuning_file(kvs, f):
    for line in f.read().splitlines():
        size, value = line.split("=")
        kvs[size] = int(value)
    return kvs


# End of tuning.py.
# Start of scalar.py.

import numpy as np
import math
import struct


def intlit(t, x):
    if t == np.int8:
        return np.int8(x)
    elif t == np.int16:
        return np.int16(x)
    elif t == np.int32:
        return np.int32(x)
    else:
        return np.int64(x)


def signed(x):
    if type(x) == np.uint8:
        return np.int8(x)
    elif type(x) == np.uint16:
        return np.int16(x)
    elif type(x) == np.uint32:
        return np.int32(x)
    else:
        return np.int64(x)


def unsigned(x):
    if type(x) == np.int8:
        return np.uint8(x)
    elif type(x) == np.int16:
        return np.uint16(x)
    elif type(x) == np.int32:
        return np.uint32(x)
    else:
        return np.uint64(x)


def shlN(x, y):
    return x << y


def ashrN(x, y):
    return x >> y


# Python is so slow that we just make all the unsafe operations safe,
# always.


def sdivN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return x // y


def sdiv_upN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return (x + y - intlit(type(x), 1)) // y


def smodN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return x % y


def udivN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed(unsigned(x) // unsigned(y))


def udiv_upN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed((unsigned(x) + unsigned(y) - unsigned(intlit(type(x), 1))) // unsigned(y))


def umodN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed(unsigned(x) % unsigned(y))


def squotN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return np.floor_divide(np.abs(x), np.abs(y)) * np.sign(x) * np.sign(y)


def sremN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return np.remainder(np.abs(x), np.abs(y)) * np.sign(x)


def sminN(x, y):
    return min(x, y)


def smaxN(x, y):
    return max(x, y)


def uminN(x, y):
    return signed(min(unsigned(x), unsigned(y)))


def umaxN(x, y):
    return signed(max(unsigned(x), unsigned(y)))


def fminN(x, y):
    return np.fmin(x, y)


def fmaxN(x, y):
    return np.fmax(x, y)


def powN(x, y):
    return x**y


def fpowN(x, y):
    return x**y


def sleN(x, y):
    return x <= y


def sltN(x, y):
    return x < y


def uleN(x, y):
    return unsigned(x) <= unsigned(y)


def ultN(x, y):
    return unsigned(x) < unsigned(y)


def lshr8(x, y):
    return np.int8(np.uint8(x) >> np.uint8(y))


def lshr16(x, y):
    return np.int16(np.uint16(x) >> np.uint16(y))


def lshr32(x, y):
    return np.int32(np.uint32(x) >> np.uint32(y))


def lshr64(x, y):
    return np.int64(np.uint64(x) >> np.uint64(y))


def sext_T_i8(x):
    return np.int8(x)


def sext_T_i16(x):
    return np.int16(x)


def sext_T_i32(x):
    return np.int32(x)


def sext_T_i64(x):
    return np.int64(x)


def itob_T_bool(x):
    return bool(x)


def btoi_bool_i8(x):
    return np.int8(x)


def btoi_bool_i16(x):
    return np.int16(x)


def btoi_bool_i32(x):
    return np.int32(x)


def btoi_bool_i64(x):
    return np.int64(x)


def ftob_T_bool(x):
    return bool(x)


def btof_bool_f16(x):
    return np.float16(x)


def btof_bool_f32(x):
    return np.float32(x)


def btof_bool_f64(x):
    return np.float64(x)


def zext_i8_i8(x):
    return np.int8(np.uint8(x))


def zext_i8_i16(x):
    return np.int16(np.uint8(x))


def zext_i8_i32(x):
    return np.int32(np.uint8(x))


def zext_i8_i64(x):
    return np.int64(np.uint8(x))


def zext_i16_i8(x):
    return np.int8(np.uint16(x))


def zext_i16_i16(x):
    return np.int16(np.uint16(x))


def zext_i16_i32(x):
    return np.int32(np.uint16(x))


def zext_i16_i64(x):
    return np.int64(np.uint16(x))


def zext_i32_i8(x):
    return np.int8(np.uint32(x))


def zext_i32_i16(x):
    return np.int16(np.uint32(x))


def zext_i32_i32(x):
    return np.int32(np.uint32(x))


def zext_i32_i64(x):
    return np.int64(np.uint32(x))


def zext_i64_i8(x):
    return np.int8(np.uint64(x))


def zext_i64_i16(x):
    return np.int16(np.uint64(x))


def zext_i64_i32(x):
    return np.int32(np.uint64(x))


def zext_i64_i64(x):
    return np.int64(np.uint64(x))


sdiv8 = sdiv16 = sdiv32 = sdiv64 = sdivN
sdiv_up8 = sdiv1_up6 = sdiv_up32 = sdiv_up64 = sdiv_upN
sdiv_safe8 = sdiv1_safe6 = sdiv_safe32 = sdiv_safe64 = sdivN
sdiv_up_safe8 = sdiv_up1_safe6 = sdiv_up_safe32 = sdiv_up_safe64 = sdiv_upN
smod8 = smod16 = smod32 = smod64 = smodN
smod_safe8 = smod_safe16 = smod_safe32 = smod_safe64 = smodN
udiv8 = udiv16 = udiv32 = udiv64 = udivN
udiv_up8 = udiv_up16 = udiv_up32 = udiv_up64 = udivN
udiv_safe8 = udiv_safe16 = udiv_safe32 = udiv_safe64 = udiv_upN
udiv_up_safe8 = udiv_up_safe16 = udiv_up_safe32 = udiv_up_safe64 = udiv_upN
umod8 = umod16 = umod32 = umod64 = umodN
umod_safe8 = umod_safe16 = umod_safe32 = umod_safe64 = umodN
squot8 = squot16 = squot32 = squot64 = squotN
squot_safe8 = squot_safe16 = squot_safe32 = squot_safe64 = squotN
srem8 = srem16 = srem32 = srem64 = sremN
srem_safe8 = srem_safe16 = srem_safe32 = srem_safe64 = sremN

shl8 = shl16 = shl32 = shl64 = shlN
ashr8 = ashr16 = ashr32 = ashr64 = ashrN
smax8 = smax16 = smax32 = smax64 = smaxN
smin8 = smin16 = smin32 = smin64 = sminN
umax8 = umax16 = umax32 = umax64 = umaxN
umin8 = umin16 = umin32 = umin64 = uminN
pow8 = pow16 = pow32 = pow64 = powN
fpow16 = fpow32 = fpow64 = fpowN
fmax16 = fmax32 = fmax64 = fmaxN
fmin16 = fmin32 = fmin64 = fminN
sle8 = sle16 = sle32 = sle64 = sleN
slt8 = slt16 = slt32 = slt64 = sltN
ule8 = ule16 = ule32 = ule64 = uleN
ult8 = ult16 = ult32 = ult64 = ultN
sext_i8_i8 = sext_i16_i8 = sext_i32_i8 = sext_i64_i8 = sext_T_i8
sext_i8_i16 = sext_i16_i16 = sext_i32_i16 = sext_i64_i16 = sext_T_i16
sext_i8_i32 = sext_i16_i32 = sext_i32_i32 = sext_i64_i32 = sext_T_i32
sext_i8_i64 = sext_i16_i64 = sext_i32_i64 = sext_i64_i64 = sext_T_i64
itob_i8_bool = itob_i16_bool = itob_i32_bool = itob_i64_bool = itob_T_bool
ftob_f16_bool = ftob_f32_bool = ftob_f64_bool = ftob_T_bool


def clz_T(x):
    n = np.int32(0)
    bits = x.itemsize * 8
    for i in range(bits):
        if x < 0:
            break
        n += 1
        x <<= np.int8(1)
    return n


def ctz_T(x):
    n = np.int32(0)
    bits = x.itemsize * 8
    for i in range(bits):
        if (x & 1) == 1:
            break
        n += 1
        x >>= np.int8(1)
    return n


def popc_T(x):
    c = np.int32(0)
    while x != 0:
        x &= x - np.int8(1)
        c += np.int8(1)
    return c


futhark_popc8 = futhark_popc16 = futhark_popc32 = futhark_popc64 = popc_T
futhark_clzz8 = futhark_clzz16 = futhark_clzz32 = futhark_clzz64 = clz_T
futhark_ctzz8 = futhark_ctzz16 = futhark_ctzz32 = futhark_ctzz64 = ctz_T


def ssignum(x):
    return np.sign(x)


def usignum(x):
    if x < 0:
        return ssignum(-x)
    else:
        return ssignum(x)


def sitofp_T_f32(x):
    return np.float32(x)


sitofp_i8_f32 = sitofp_i16_f32 = sitofp_i32_f32 = sitofp_i64_f32 = sitofp_T_f32


def sitofp_T_f64(x):
    return np.float64(x)


sitofp_i8_f64 = sitofp_i16_f64 = sitofp_i32_f64 = sitofp_i64_f64 = sitofp_T_f64


def uitofp_T_f32(x):
    return np.float32(unsigned(x))


uitofp_i8_f32 = uitofp_i16_f32 = uitofp_i32_f32 = uitofp_i64_f32 = uitofp_T_f32


def uitofp_T_f64(x):
    return np.float64(unsigned(x))


uitofp_i8_f64 = uitofp_i16_f64 = uitofp_i32_f64 = uitofp_i64_f64 = uitofp_T_f64


def fptosi_T_i8(x):
    if np.isnan(x) or np.isinf(x):
        return np.int8(0)
    else:
        return np.int8(np.trunc(x))


fptosi_f16_i8 = fptosi_f32_i8 = fptosi_f64_i8 = fptosi_T_i8


def fptosi_T_i16(x):
    if np.isnan(x) or np.isinf(x):
        return np.int16(0)
    else:
        return np.int16(np.trunc(x))


fptosi_f16_i16 = fptosi_f32_i16 = fptosi_f64_i16 = fptosi_T_i16


def fptosi_T_i32(x):
    if np.isnan(x) or np.isinf(x):
        return np.int32(0)
    else:
        return np.int32(np.trunc(x))


fptosi_f16_i32 = fptosi_f32_i32 = fptosi_f64_i32 = fptosi_T_i32


def fptosi_T_i64(x):
    if np.isnan(x) or np.isinf(x):
        return np.int64(0)
    else:
        return np.int64(np.trunc(x))


fptosi_f16_i64 = fptosi_f32_i64 = fptosi_f64_i64 = fptosi_T_i64


def fptoui_T_i8(x):
    if np.isnan(x) or np.isinf(x):
        return np.int8(0)
    else:
        return np.int8(np.trunc(x))


fptoui_f16_i8 = fptoui_f32_i8 = fptoui_f64_i8 = fptoui_T_i8


def fptoui_T_i16(x):
    if np.isnan(x) or np.isinf(x):
        return np.int16(0)
    else:
        return np.int16(np.trunc(x))


fptoui_f16_i16 = fptoui_f32_i16 = fptoui_f64_i16 = fptoui_T_i16


def fptoui_T_i32(x):
    if np.isnan(x) or np.isinf(x):
        return np.int32(0)
    else:
        return np.int32(np.trunc(x))


fptoui_f16_i32 = fptoui_f32_i32 = fptoui_f64_i32 = fptoui_T_i32


def fptoui_T_i64(x):
    if np.isnan(x) or np.isinf(x):
        return np.int64(0)
    else:
        return np.int64(np.trunc(x))


fptoui_f16_i64 = fptoui_f32_i64 = fptoui_f64_i64 = fptoui_T_i64


def fpconv_f16_f32(x):
    return np.float32(x)


def fpconv_f16_f64(x):
    return np.float64(x)


def fpconv_f32_f16(x):
    return np.float16(x)


def fpconv_f32_f64(x):
    return np.float64(x)


def fpconv_f64_f16(x):
    return np.float16(x)


def fpconv_f64_f32(x):
    return np.float32(x)


def futhark_mul_hi8(a, b):
    a = np.uint64(np.uint8(a))
    b = np.uint64(np.uint8(b))
    return np.int8((a * b) >> np.uint64(8))


def futhark_mul_hi16(a, b):
    a = np.uint64(np.uint16(a))
    b = np.uint64(np.uint16(b))
    return np.int16((a * b) >> np.uint64(16))


def futhark_mul_hi32(a, b):
    a = np.uint64(np.uint32(a))
    b = np.uint64(np.uint32(b))
    return np.int32((a * b) >> np.uint64(32))


# This one is done with arbitrary-precision integers.
def futhark_mul_hi64(a, b):
    a = int(np.uint64(a))
    b = int(np.uint64(b))
    return np.int64(np.uint64(a * b >> 64))


def futhark_mad_hi8(a, b, c):
    return futhark_mul_hi8(a, b) + c


def futhark_mad_hi16(a, b, c):
    return futhark_mul_hi16(a, b) + c


def futhark_mad_hi32(a, b, c):
    return futhark_mul_hi32(a, b) + c


def futhark_mad_hi64(a, b, c):
    return futhark_mul_hi64(a, b) + c


def futhark_log64(x):
    return np.float64(np.log(x))


def futhark_log2_64(x):
    return np.float64(np.log2(x))


def futhark_log10_64(x):
    return np.float64(np.log10(x))


def futhark_sqrt64(x):
    return np.sqrt(x)


def futhark_cbrt64(x):
    return np.cbrt(x)


def futhark_exp64(x):
    return np.exp(x)


def futhark_cos64(x):
    return np.cos(x)


def futhark_sin64(x):
    return np.sin(x)


def futhark_tan64(x):
    return np.tan(x)


def futhark_acos64(x):
    return np.arccos(x)


def futhark_asin64(x):
    return np.arcsin(x)


def futhark_atan64(x):
    return np.arctan(x)


def futhark_cosh64(x):
    return np.cosh(x)


def futhark_sinh64(x):
    return np.sinh(x)


def futhark_tanh64(x):
    return np.tanh(x)


def futhark_acosh64(x):
    return np.arccosh(x)


def futhark_asinh64(x):
    return np.arcsinh(x)


def futhark_atanh64(x):
    return np.arctanh(x)


def futhark_atan2_64(x, y):
    return np.arctan2(x, y)


def futhark_hypot64(x, y):
    return np.hypot(x, y)


def futhark_gamma64(x):
    return np.float64(math.gamma(x))


def futhark_lgamma64(x):
    return np.float64(math.lgamma(x))


def futhark_erf64(x):
    return np.float64(math.erf(x))


def futhark_erfc64(x):
    return np.float64(math.erfc(x))


def futhark_round64(x):
    return np.round(x)


def futhark_ceil64(x):
    return np.ceil(x)


def futhark_floor64(x):
    return np.floor(x)


def futhark_nextafter64(x, y):
    return np.nextafter(x, y)


def futhark_isnan64(x):
    return np.isnan(x)


def futhark_isinf64(x):
    return np.isinf(x)


def futhark_to_bits64(x):
    s = struct.pack(">d", x)
    return np.int64(struct.unpack(">q", s)[0])


def futhark_from_bits64(x):
    s = struct.pack(">q", x)
    return np.float64(struct.unpack(">d", s)[0])


def futhark_log32(x):
    return np.float32(np.log(x))


def futhark_log2_32(x):
    return np.float32(np.log2(x))


def futhark_log10_32(x):
    return np.float32(np.log10(x))


def futhark_sqrt32(x):
    return np.float32(np.sqrt(x))


def futhark_cbrt32(x):
    return np.float32(np.cbrt(x))


def futhark_exp32(x):
    return np.exp(x)


def futhark_cos32(x):
    return np.cos(x)


def futhark_sin32(x):
    return np.sin(x)


def futhark_tan32(x):
    return np.tan(x)


def futhark_acos32(x):
    return np.arccos(x)


def futhark_asin32(x):
    return np.arcsin(x)


def futhark_atan32(x):
    return np.arctan(x)


def futhark_cosh32(x):
    return np.cosh(x)


def futhark_sinh32(x):
    return np.sinh(x)


def futhark_tanh32(x):
    return np.tanh(x)


def futhark_acosh32(x):
    return np.arccosh(x)


def futhark_asinh32(x):
    return np.arcsinh(x)


def futhark_atanh32(x):
    return np.arctanh(x)


def futhark_atan2_32(x, y):
    return np.arctan2(x, y)


def futhark_hypot32(x, y):
    return np.hypot(x, y)


def futhark_gamma32(x):
    return np.float32(math.gamma(x))


def futhark_lgamma32(x):
    return np.float32(math.lgamma(x))


def futhark_erf32(x):
    return np.float32(math.erf(x))


def futhark_erfc32(x):
    return np.float32(math.erfc(x))


def futhark_round32(x):
    return np.round(x)


def futhark_ceil32(x):
    return np.ceil(x)


def futhark_floor32(x):
    return np.floor(x)


def futhark_nextafter32(x, y):
    return np.nextafter(x, y)


def futhark_isnan32(x):
    return np.isnan(x)


def futhark_isinf32(x):
    return np.isinf(x)


def futhark_to_bits32(x):
    s = struct.pack(">f", x)
    return np.int32(struct.unpack(">l", s)[0])


def futhark_from_bits32(x):
    s = struct.pack(">l", x)
    return np.float32(struct.unpack(">f", s)[0])


def futhark_log16(x):
    return np.float16(np.log(x))


def futhark_log2_16(x):
    return np.float16(np.log2(x))


def futhark_log10_16(x):
    return np.float16(np.log10(x))


def futhark_sqrt16(x):
    return np.float16(np.sqrt(x))


def futhark_cbrt16(x):
    return np.float16(np.cbrt(x))


def futhark_exp16(x):
    return np.exp(x)


def futhark_cos16(x):
    return np.cos(x)


def futhark_sin16(x):
    return np.sin(x)


def futhark_tan16(x):
    return np.tan(x)


def futhark_acos16(x):
    return np.arccos(x)


def futhark_asin16(x):
    return np.arcsin(x)


def futhark_atan16(x):
    return np.arctan(x)


def futhark_cosh16(x):
    return np.cosh(x)


def futhark_sinh16(x):
    return np.sinh(x)


def futhark_tanh16(x):
    return np.tanh(x)


def futhark_acosh16(x):
    return np.arccosh(x)


def futhark_asinh16(x):
    return np.arcsinh(x)


def futhark_atanh16(x):
    return np.arctanh(x)


def futhark_atan2_16(x, y):
    return np.arctan2(x, y)


def futhark_hypot16(x, y):
    return np.hypot(x, y)


def futhark_gamma16(x):
    return np.float16(math.gamma(x))


def futhark_lgamma16(x):
    return np.float16(math.lgamma(x))


def futhark_erf16(x):
    return np.float16(math.erf(x))


def futhark_erfc16(x):
    return np.float16(math.erfc(x))


def futhark_round16(x):
    return np.round(x)


def futhark_ceil16(x):
    return np.ceil(x)


def futhark_floor16(x):
    return np.floor(x)


def futhark_nextafter16(x, y):
    return np.nextafter(x, y)


def futhark_isnan16(x):
    return np.isnan(x)


def futhark_isinf16(x):
    return np.isinf(x)


def futhark_to_bits16(x):
    s = struct.pack(">e", x)
    return np.int16(struct.unpack(">H", s)[0])


def futhark_from_bits16(x):
    s = struct.pack(">H", np.uint16(x))
    return np.float16(struct.unpack(">e", s)[0])


def futhark_lerp16(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_lerp32(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_lerp64(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_mad16(a, b, c):
    return a * b + c


def futhark_mad32(a, b, c):
    return a * b + c


def futhark_mad64(a, b, c):
    return a * b + c


def futhark_fma16(a, b, c):
    return a * b + c


def futhark_fma32(a, b, c):
    return a * b + c


def futhark_fma64(a, b, c):
    return a * b + c


# End of scalar.py.
# Start of server.py

import sys
import time
import shlex  # For string splitting


class Server:
    def __init__(self, ctx):
        self._ctx = ctx
        self._vars = {}

    class Failure(BaseException):
        def __init__(self, msg):
            self.msg = msg

    def _get_arg(self, args, i):
        if i < len(args):
            return args[i]
        else:
            raise self.Failure("Insufficient command args")

    def _get_entry_point(self, entry):
        if entry in self._ctx.entry_points:
            return self._ctx.entry_points[entry]
        else:
            raise self.Failure("Unknown entry point: %s" % entry)

    def _check_var(self, vname):
        if not vname in self._vars:
            raise self.Failure("Unknown variable: %s" % vname)

    def _check_new_var(self, vname):
        if vname in self._vars:
            raise self.Failure("Variable already exists: %s" % vname)

    def _get_var(self, vname):
        self._check_var(vname)
        return self._vars[vname]

    def _cmd_inputs(self, args):
        entry = self._get_arg(args, 0)
        for t in self._get_entry_point(entry)[0]:
            print(t)

    def _cmd_outputs(self, args):
        entry = self._get_arg(args, 0)
        for t in self._get_entry_point(entry)[1]:
            print(t)

    def _cmd_dummy(self, args):
        pass

    def _cmd_free(self, args):
        for vname in args:
            self._check_var(vname)
            del self._vars[vname]

    def _cmd_rename(self, args):
        oldname = self._get_arg(args, 0)
        newname = self._get_arg(args, 1)
        self._check_var(oldname)
        self._check_new_var(newname)
        self._vars[newname] = self._vars[oldname]
        del self._vars[oldname]

    def _cmd_call(self, args):
        entry = self._get_entry_point(self._get_arg(args, 0))
        num_ins = len(entry[0])
        num_outs = len(entry[1])
        exp_len = 1 + num_outs + num_ins

        if len(args) != exp_len:
            raise self.Failure("Invalid argument count, expected %d" % exp_len)

        out_vnames = args[1 : num_outs + 1]

        for out_vname in out_vnames:
            self._check_new_var(out_vname)

        in_vnames = args[1 + num_outs :]
        ins = [self._get_var(in_vname) for in_vname in in_vnames]

        try:
            (runtime, vals) = getattr(self._ctx, args[0])(*ins)
        except Exception as e:
            raise self.Failure(str(e))

        print("runtime: %d" % runtime)

        if num_outs == 1:
            self._vars[out_vnames[0]] = vals
        else:
            for out_vname, val in zip(out_vnames, vals):
                self._vars[out_vname] = val

    def _store_val(self, f, value):
        # In case we are using the PyOpenCL backend, we first
        # need to convert OpenCL arrays to ordinary NumPy
        # arrays.  We do this in a nasty way.
        if isinstance(value, opaque):
            for component in value.data:
                self._store_val(f, component)
        elif (
            isinstance(value, np.number)
            or isinstance(value, bool)
            or isinstance(value, np.bool_)
            or isinstance(value, np.ndarray)
        ):
            # Ordinary NumPy value.
            f.write(construct_binary_value(value))
        else:
            # Assuming PyOpenCL array.
            f.write(construct_binary_value(value.get()))

    def _cmd_store(self, args):
        fname = self._get_arg(args, 0)

        with open(fname, "wb") as f:
            for i in range(1, len(args)):
                self._store_val(f, self._get_var(args[i]))

    def _restore_val(self, reader, typename):
        if typename in self._ctx.opaques:
            vs = []
            for t in self._ctx.opaques[typename]:
                vs += [read_value(t, reader)]
            return opaque(typename, *vs)
        else:
            return read_value(typename, reader)

    def _cmd_restore(self, args):
        if len(args) % 2 == 0:
            raise self.Failure("Invalid argument count")

        fname = args[0]
        args = args[1:]

        with open(fname, "rb") as f:
            reader = ReaderInput(f)
            while args != []:
                vname = args[0]
                typename = args[1]
                args = args[2:]

                if vname in self._vars:
                    raise self.Failure("Variable already exists: %s" % vname)

                try:
                    self._vars[vname] = self._restore_val(reader, typename)
                except ValueError:
                    raise self.Failure(
                        "Failed to restore variable %s.\n"
                        "Possibly malformed data in %s.\n" % (vname, fname)
                    )

            skip_spaces(reader)
            if reader.get_char() != b"":
                raise self.Failure("Expected EOF after reading values")

    def _cmd_types(self, args):
        for k in self._ctx.opaques.keys():
            print(k)

    def _cmd_entry_points(self, args):
        for k in self._ctx.entry_points.keys():
            print(k)

    _commands = {
        "inputs": _cmd_inputs,
        "outputs": _cmd_outputs,
        "call": _cmd_call,
        "restore": _cmd_restore,
        "store": _cmd_store,
        "free": _cmd_free,
        "rename": _cmd_rename,
        "clear": _cmd_dummy,
        "pause_profiling": _cmd_dummy,
        "unpause_profiling": _cmd_dummy,
        "report": _cmd_dummy,
        "types": _cmd_types,
        "entry_points": _cmd_entry_points,
    }

    def _process_line(self, line):
        words = shlex.split(line)
        if words == []:
            raise self.Failure("Empty line")
        else:
            cmd = words[0]
            args = words[1:]
            if cmd in self._commands:
                self._commands[cmd](self, args)
            else:
                raise self.Failure("Unknown command: %s" % cmd)

    def run(self):
        while True:
            print("%%% OK", flush=True)
            line = sys.stdin.readline()
            if line == "":
                return
            try:
                self._process_line(line)
            except self.Failure as e:
                print("%%% FAILURE")
                print(e.msg)


# End of server.py
class entropy:
    entry_points = {
        "byte_histogram": (["[]u8"], ["[]i64"]),
        "chunked_entropy": (["i64", "[]u8"], ["[]f32"]),
        "entropy": (["[]u8"], ["f32"]),
    }
    opaques = {}

    def __init__(
        self,
        build_options=build_options,
        command_queue=None,
        interactive=False,
        platform_pref=preferred_platform,
        device_pref=preferred_device,
        default_group_size=default_group_size,
        default_num_groups=default_num_groups,
        default_tile_size=default_tile_size,
        default_reg_tile_size=default_reg_tile_size,
        default_threshold=default_threshold,
        sizes=sizes,
    ):
        size_heuristics = [
            ("NVIDIA CUDA", cl.device_type.GPU, "lockstep_width", lambda device: np.int32(32)),
            (
                "AMD Accelerated Parallel Processing",
                cl.device_type.GPU,
                "lockstep_width",
                lambda device: np.int32(32),
            ),
            ("", cl.device_type.GPU, "lockstep_width", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.GPU,
                "num_groups",
                lambda device: (
                    np.int32(4) * device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS"))
                ),
            ),
            ("", cl.device_type.GPU, "group_size", lambda device: np.int32(256)),
            ("", cl.device_type.GPU, "tile_size", lambda device: np.int32(16)),
            ("", cl.device_type.GPU, "reg_tile_size", lambda device: np.int32(4)),
            ("", cl.device_type.GPU, "threshold", lambda device: np.int32(32768)),
            ("", cl.device_type.CPU, "lockstep_width", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.CPU,
                "num_groups",
                lambda device: device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS")),
            ),
            ("", cl.device_type.CPU, "group_size", lambda device: np.int32(32)),
            ("", cl.device_type.CPU, "tile_size", lambda device: np.int32(4)),
            ("", cl.device_type.CPU, "reg_tile_size", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.CPU,
                "threshold",
                lambda device: device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS")),
            ),
        ]
        self.global_failure_args_max = 3
        self.failure_msgs = [
            "Index [{}:{}] out of bounds for array of shape [{}].\n-> #0  entropy.fut:14:27-65\n   #1  /prelude/functional.fut:9:42-44\n   #2  entropy.fut:13:3-14:67\n   #3  entropy.fut:12:1-14:67\n",
            "Index [{}:{}] out of bounds for array of shape [{}].\n-> #0  entropy.fut:14:27-65\n   #1  /prelude/functional.fut:9:42-44\n   #2  entropy.fut:13:3-14:67\n   #3  entropy.fut:12:1-14:67\n",
        ]
        program = initialise_opencl_object(
            self,
            program_src=fut_opencl_src,
            build_options=build_options,
            command_queue=command_queue,
            interactive=interactive,
            platform_pref=platform_pref,
            device_pref=device_pref,
            default_group_size=default_group_size,
            default_num_groups=default_num_groups,
            default_tile_size=default_tile_size,
            default_reg_tile_size=default_reg_tile_size,
            default_threshold=default_threshold,
            size_heuristics=size_heuristics,
            required_types=["i8", "i32", "i64", "f32", "bool", "unit"],
            user_sizes=sizes,
            all_sizes={
                "builtin#replicate_i64.group_size_7583": {"class": "group_size", "value": None},
                "byte_histogram.L2_size_7657": {
                    "class": "bespoke(L2_for_histogram, 4194304)",
                    "value": 4194304,
                },
                "byte_histogram.seghist_group_size_7170": {"class": "group_size", "value": None},
                "byte_histogram.seghist_num_groups_7172": {"class": "num_groups", "value": None},
                "chunked_entropy.segmap_group_size_7216": {"class": "group_size", "value": None},
                "chunked_entropy.segmap_group_size_7318": {"class": "group_size", "value": None},
                "chunked_entropy.segmap_group_size_7380": {"class": "group_size", "value": None},
                "chunked_entropy.segmap_num_groups_7382": {"class": "num_groups", "value": None},
                "chunked_entropy.segred_group_size_7332": {"class": "group_size", "value": None},
                "chunked_entropy.segred_num_groups_7334": {"class": "num_groups", "value": None},
                "chunked_entropy.suff_outer_par_0": {"class": "threshold(def, )", "value": None},
                "entropy.L2_size_7657": {
                    "class": "bespoke(L2_for_histogram, 4194304)",
                    "value": 4194304,
                },
                "entropy.seghist_group_size_7186": {"class": "group_size", "value": None},
                "entropy.seghist_num_groups_7188": {"class": "num_groups", "value": None},
                "entropy.segred_group_size_7202": {"class": "group_size", "value": None},
                "entropy.segred_num_groups_7204": {"class": "num_groups", "value": None},
            },
        )
        self.builtinzhreplicate_i64zireplicate_7579_var = (
            program.builtinzhreplicate_i64zireplicate_7579
        )
        self.byte_histogramziseghist_global_7178_var = program.byte_histogramziseghist_global_7178
        self.byte_histogramziseghist_local_7178_var = program.byte_histogramziseghist_local_7178
        self.byte_histogramzisegred_large_7681_var = program.byte_histogramzisegred_large_7681
        self.byte_histogramzisegred_small_7681_var = program.byte_histogramzisegred_small_7681
        self.chunked_entropyzisegmap_7269_var = program.chunked_entropyzisegmap_7269
        self.chunked_entropyzisegmap_7425_var = program.chunked_entropyzisegmap_7425
        self.chunked_entropyzisegmap_7483_var = program.chunked_entropyzisegmap_7483
        self.chunked_entropyzisegred_large_7465_var = program.chunked_entropyzisegred_large_7465
        self.chunked_entropyzisegred_small_7465_var = program.chunked_entropyzisegred_small_7465
        self.entropyziseghist_global_7194_var = program.entropyziseghist_global_7194
        self.entropyziseghist_local_7194_var = program.entropyziseghist_local_7194
        self.entropyzisegred_large_7681_var = program.entropyzisegred_large_7681
        self.entropyzisegred_nonseg_7210_var = program.entropyzisegred_nonseg_7210
        self.entropyzisegred_small_7681_var = program.entropyzisegred_small_7681
        self.constants = {}
        byte_histogramzicounter_mem_7718 = np.zeros(10240, dtype=np.int32)
        static_mem_7788 = opencl_alloc(self, 40960, "static_mem_7788")
        if 40960 != 0:
            cl.enqueue_copy(
                self.queue,
                static_mem_7788,
                normaliseArray(byte_histogramzicounter_mem_7718),
                is_blocking=synchronous,
            )
        self.byte_histogramzicounter_mem_7718 = static_mem_7788
        chunked_entropyzicounter_mem_7641 = np.zeros(10240, dtype=np.int32)
        static_mem_7789 = opencl_alloc(self, 40960, "static_mem_7789")
        if 40960 != 0:
            cl.enqueue_copy(
                self.queue,
                static_mem_7789,
                normaliseArray(chunked_entropyzicounter_mem_7641),
                is_blocking=synchronous,
            )
        self.chunked_entropyzicounter_mem_7641 = static_mem_7789
        entropyzicounter_mem_7718 = np.zeros(10240, dtype=np.int32)
        static_mem_7794 = opencl_alloc(self, 40960, "static_mem_7794")
        if 40960 != 0:
            cl.enqueue_copy(
                self.queue,
                static_mem_7794,
                normaliseArray(entropyzicounter_mem_7718),
                is_blocking=synchronous,
            )
        self.entropyzicounter_mem_7718 = static_mem_7794
        entropyzicounter_mem_7754 = np.zeros(10, dtype=np.int32)
        static_mem_7795 = opencl_alloc(self, 40, "static_mem_7795")
        if 40 != 0:
            cl.enqueue_copy(
                self.queue,
                static_mem_7795,
                normaliseArray(entropyzicounter_mem_7754),
                is_blocking=synchronous,
            )
        self.entropyzicounter_mem_7754 = static_mem_7795

    def futhark_builtinzhreplicate_i64(self, mem_7574, num_elems_7575, val_7576):
        replicate_n_7578 = num_elems_7575
        group_sizze_7583 = self.sizes["builtin#replicate_i64.group_size_7583"]
        virt_num_groups_7584 = sdiv_up64(replicate_n_7578, group_sizze_7583)
        num_groups_7585 = smin64(virt_num_groups_7584, np.int64(1048576))
        if (1 * (np.int64(num_groups_7585) * np.int64(group_sizze_7583))) != 0:
            self.builtinzhreplicate_i64zireplicate_7579_var.set_args(
                ct.c_int64(num_elems_7575),
                ct.c_int64(val_7576),
                ct.c_int64(replicate_n_7578),
                ct.c_int64(virt_num_groups_7584),
                ct.c_int64(num_groups_7585),
                mem_7574,
            )
            cl.enqueue_nd_range_kernel(
                self.queue,
                self.builtinzhreplicate_i64zireplicate_7579_var,
                ((np.int64(num_groups_7585) * np.int64(group_sizze_7583)),),
                (np.int64(group_sizze_7583),),
            )
            if synchronous:
                sync(self)
        return ()

    def futhark_entry_byte_histogram(self, xs_mem_7539, n_6636):
        mem_7541 = opencl_alloc(self, np.int64(2048), "mem_7541")
        self.futhark_builtinzhreplicate_i64(mem_7541, np.int64(256), np.int64(0))
        seghist_group_sizze_7171 = self.sizes["byte_histogram.seghist_group_size_7170"]
        max_num_groups_7594 = self.sizes["byte_histogram.seghist_num_groups_7172"]
        num_groups_7173 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(n_6636, seghist_group_sizze_7171), sext_i32_i64(max_num_groups_7594)
                ),
            )
        )
        h_7598 = np.int64(2048)
        seg_h_7599 = np.int64(2048)
        if seg_h_7599 == np.int64(0):
            pass
        else:
            hist_H_7600 = np.int64(256)
            hist_el_sizze_7601 = sdiv_up64(h_7598, hist_H_7600)
            hist_N_7602 = n_6636
            hist_RF_7603 = np.int32(1)
            hist_L_7604 = self.max_local_memory
            max_group_sizze_7605 = self.max_group_size
            num_groups_7606 = sdiv_up64(
                sext_i32_i64(sext_i64_i32(num_groups_7173 * seghist_group_sizze_7171)),
                max_group_sizze_7605,
            )
            hist_m_prime_7607 = sitofp_i64_f64(
                smin64(
                    sext_i32_i64(squot32(hist_L_7604, hist_el_sizze_7601)),
                    sdiv_up64(hist_N_7602, num_groups_7606),
                )
            ) / sitofp_i64_f64(hist_H_7600)
            hist_M0_7608 = smax64(
                np.int64(1), smin64(fptosi_f64_i64(hist_m_prime_7607), max_group_sizze_7605)
            )
            hist_Nout_7609 = np.int64(1)
            hist_Nin_7610 = n_6636
            work_asymp_M_max_7611 = squot64(
                (hist_Nout_7609 * hist_N_7602), ((np.int64(2) * num_groups_7606) * hist_H_7600)
            )
            hist_M_7612 = sext_i64_i32(smin64(hist_M0_7608, work_asymp_M_max_7611))
            hist_C_7613 = sdiv_up64(
                max_group_sizze_7605, sext_i32_i64(smax32(np.int32(1), hist_M_7612))
            )
            local_mem_needed_7614 = hist_el_sizze_7601 * sext_i32_i64(hist_M_7612)
            hist_S_7615 = sext_i64_i32(
                sdiv_up64((hist_H_7600 * local_mem_needed_7614), hist_L_7604)
            )
            if sle64(hist_H_7600, hist_Nin_7610) and (
                sle64(local_mem_needed_7614, hist_L_7604)
                and (
                    sle32(hist_S_7615, np.int32(3))
                    and (
                        sle64(hist_C_7613, max_group_sizze_7605) and slt32(np.int32(0), hist_M_7612)
                    )
                )
            ):
                num_subhistos_7595 = num_groups_7606
                if num_subhistos_7595 == np.int64(1):
                    defunc_1_map_res_subhistos_mem_7596 = mem_7541
                else:
                    defunc_1_map_res_subhistos_mem_7596 = opencl_alloc(
                        self,
                        ((num_subhistos_7595 * np.int64(256)) * np.int64(8)),
                        "defunc_1_map_res_subhistos_mem_7596",
                    )
                    self.futhark_builtinzhreplicate_i64(
                        defunc_1_map_res_subhistos_mem_7596,
                        (num_subhistos_7595 * np.int64(256)),
                        np.int64(0),
                    )
                    if np.int64(2048) != 0:
                        cl.enqueue_copy(
                            self.queue,
                            defunc_1_map_res_subhistos_mem_7596,
                            mem_7541,
                            dest_offset=np.int64(np.int64(0)),
                            src_offset=np.int64(np.int64(0)),
                            byte_count=np.int64(np.int64(2048)),
                        )
                    if synchronous:
                        sync(self)
                chk_i_7616 = np.int32(0)
                one_7785 = np.int32(1)
                for counter_7784 in range(hist_S_7615):
                    num_segments_7617 = np.int64(1)
                    hist_H_chk_7618 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7615))
                    histo_sizze_7619 = hist_H_chk_7618
                    init_per_thread_7620 = sext_i64_i32(
                        sdiv_up64(
                            (sext_i32_i64(hist_M_7612) * histo_sizze_7619), max_group_sizze_7605
                        )
                    )
                    if (1 * (np.int64(num_groups_7606) * np.int64(max_group_sizze_7605))) != 0:
                        self.byte_histogramziseghist_local_7178_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int64(8) * (hist_M_7612 * hist_H_chk_7618))),
                            ct.c_int64(n_6636),
                            ct.c_int32(max_group_sizze_7605),
                            ct.c_int64(num_groups_7606),
                            ct.c_int32(hist_M_7612),
                            ct.c_int32(chk_i_7616),
                            ct.c_int64(num_segments_7617),
                            ct.c_int64(hist_H_chk_7618),
                            ct.c_int64(histo_sizze_7619),
                            ct.c_int32(init_per_thread_7620),
                            xs_mem_7539,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramziseghist_local_7178_var,
                            ((np.int64(num_groups_7606) * np.int64(max_group_sizze_7605)),),
                            (np.int64(max_group_sizze_7605),),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_7616 += one_7785
            else:
                hist_H_7652 = np.int64(256)
                hist_RF_7653 = (np.float64(0.0) + sitofp_i32_f64(np.int64(1))) / np.float64(1.0)
                hist_el_sizze_7654 = np.int32(8)
                hist_C_max_7655 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_groups_7173 * seghist_group_sizze_7171)),
                    (sitofp_i32_f64(hist_H_7652) / np.float64(2.0)),
                )
                hist_M_min_7656 = smax32(
                    np.int32(1),
                    sext_i64_i32(
                        fptosi_f64_i64(
                            sitofp_i32_f64(sext_i64_i32(num_groups_7173 * seghist_group_sizze_7171))
                            / hist_C_max_7655
                        )
                    ),
                )
                L2_sizze_7657 = self.sizes["byte_histogram.L2_size_7657"]
                hist_RACE_exp_7658 = fmax64(
                    np.float64(1.0),
                    (
                        (np.float64(0.75) * hist_RF_7653)
                        / (np.float64(64.0) / sitofp_i32_f64(hist_el_sizze_7654))
                    ),
                )
                if slt64(n_6636, hist_H_7652):
                    hist_S_7659 = np.int32(1)
                else:
                    hist_S_7659 = sext_i64_i32(
                        sdiv_up64(
                            (
                                (sext_i32_i64(hist_M_min_7656) * hist_H_7652)
                                * sext_i32_i64(hist_el_sizze_7654)
                            ),
                            fptosi_f64_i64(
                                (np.float64(0.4) * sitofp_i32_f64(L2_sizze_7657))
                                * hist_RACE_exp_7658
                            ),
                        )
                    )
                hist_H_chk_7660 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7659))
                hist_k_max_7661 = fmin64(
                    (
                        (
                            np.float64(0.4)
                            * (sitofp_i32_f64(L2_sizze_7657) / sitofp_i32_f64(np.int32(8)))
                        )
                        * hist_RACE_exp_7658
                    ),
                    sitofp_i32_f64(n_6636),
                ) / sitofp_i32_f64(sext_i64_i32(num_groups_7173 * seghist_group_sizze_7171))
                hist_u_7662 = np.int64(2)
                hist_C_7663 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_groups_7173 * seghist_group_sizze_7171)),
                    (sitofp_i32_f64(hist_u_7662 * hist_H_chk_7660) / hist_k_max_7661),
                )
                hist_M_7664 = np.int32(1)
                num_subhistos_7595 = sext_i32_i64(hist_M_7664)
                if hist_M_7664 == np.int32(1):
                    defunc_1_map_res_subhistos_mem_7596 = mem_7541
                else:
                    if num_subhistos_7595 == np.int64(1):
                        defunc_1_map_res_subhistos_mem_7596 = mem_7541
                    else:
                        defunc_1_map_res_subhistos_mem_7596 = opencl_alloc(
                            self,
                            ((num_subhistos_7595 * np.int64(256)) * np.int64(8)),
                            "defunc_1_map_res_subhistos_mem_7596",
                        )
                        self.futhark_builtinzhreplicate_i64(
                            defunc_1_map_res_subhistos_mem_7596,
                            (num_subhistos_7595 * np.int64(256)),
                            np.int64(0),
                        )
                        if np.int64(2048) != 0:
                            cl.enqueue_copy(
                                self.queue,
                                defunc_1_map_res_subhistos_mem_7596,
                                mem_7541,
                                dest_offset=np.int64(np.int64(0)),
                                src_offset=np.int64(np.int64(0)),
                                byte_count=np.int64(np.int64(2048)),
                            )
                        if synchronous:
                            sync(self)
                chk_i_7665 = np.int32(0)
                one_7787 = np.int32(1)
                for counter_7786 in range(hist_S_7659):
                    hist_H_chk_7666 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7659))
                    if (1 * (np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171))) != 0:
                        self.byte_histogramziseghist_global_7178_var.set_args(
                            self.global_failure,
                            ct.c_int64(n_6636),
                            ct.c_int64(num_groups_7173),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int32(chk_i_7665),
                            ct.c_int64(hist_H_chk_7666),
                            xs_mem_7539,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramziseghist_global_7178_var,
                            ((np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171)),),
                            (np.int64(seghist_group_sizze_7171),),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_7665 += one_7787
            if num_subhistos_7595 == np.int64(1):
                mem_7541 = defunc_1_map_res_subhistos_mem_7596
            else:
                if slt64((num_subhistos_7595 * np.int64(2)), seghist_group_sizze_7171):
                    segment_sizze_nonzzero_7682 = smax64(np.int64(1), num_subhistos_7595)
                    num_threads_7683 = num_groups_7173 * seghist_group_sizze_7171
                    if (1 * (np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171))) != 0:
                        self.byte_histogramzisegred_small_7681_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int64(8) * seghist_group_sizze_7171)),
                            ct.c_int64(num_groups_7173),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int64(segment_sizze_nonzzero_7682),
                            mem_7541,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramzisegred_small_7681_var,
                            ((np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171)),),
                            (np.int64(seghist_group_sizze_7171),),
                        )
                        if synchronous:
                            sync(self)
                else:
                    groups_per_segment_7711 = sdiv_up64(
                        num_groups_7173, smax64(np.int64(1), np.int64(256))
                    )
                    elements_per_thread_7712 = sdiv_up64(
                        num_subhistos_7595, (seghist_group_sizze_7171 * groups_per_segment_7711)
                    )
                    virt_num_groups_7713 = groups_per_segment_7711 * np.int64(256)
                    num_threads_7714 = num_groups_7173 * seghist_group_sizze_7171
                    threads_per_segment_7715 = groups_per_segment_7711 * seghist_group_sizze_7171
                    segred_tmp_mem_7716 = opencl_alloc(
                        self, (np.int64(8) * virt_num_groups_7713), "segred_tmp_mem_7716"
                    )
                    byte_histogramzicounter_mem_7718 = self.byte_histogramzicounter_mem_7718
                    if (1 * (np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171))) != 0:
                        self.byte_histogramzisegred_large_7681_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int32(1))),
                            cl.LocalMemory(np.int64(np.int64(8) * seghist_group_sizze_7171)),
                            ct.c_int64(num_groups_7173),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int64(groups_per_segment_7711),
                            ct.c_int64(elements_per_thread_7712),
                            ct.c_int64(virt_num_groups_7713),
                            ct.c_int64(threads_per_segment_7715),
                            mem_7541,
                            defunc_1_map_res_subhistos_mem_7596,
                            segred_tmp_mem_7716,
                            byte_histogramzicounter_mem_7718,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramzisegred_large_7681_var,
                            ((np.int64(num_groups_7173) * np.int64(seghist_group_sizze_7171)),),
                            (np.int64(seghist_group_sizze_7171),),
                        )
                        if synchronous:
                            sync(self)
        mem_out_7573 = mem_7541
        return mem_out_7573

    def futhark_entry_chunked_entropy(self, xs_mem_7539, n_6950, chunk_sizze_6951):
        zzero_7040 = chunk_sizze_6951 == np.int64(0)
        nonzzero_7041 = not (zzero_7040)
        nonzzero_cert_7042 = True
        assert (
            nonzzero_7041
        ), "Error: {}\n\nBacktrace:\n-> #0  entropy.fut:13:9-22\n   #1  entropy.fut:12:1-14:67\n".format(
            "division by zero"
        )
        x_7043 = sdiv64(n_6950, chunk_sizze_6951)
        range_end_7044 = x_7043 - np.int64(1)
        bounds_invalid_upwards_7045 = slt64(range_end_7044, np.int64(1))
        valid_7046 = not (bounds_invalid_upwards_7045)
        range_valid_c_7047 = True
        assert valid_7046, (
            "Error: %s%d%s%d%s\n\nBacktrace:\n-> #0  entropy.fut:13:4-27\n   #1  entropy.fut:12:1-14:67\n"
            % ("Range ", np.int64(1), "...", range_end_7044, " is invalid.")
        )
        suff_outer_par_7212 = self.sizes["chunked_entropy.suff_outer_par_0"] <= range_end_7044
        segmap_group_sizze_7419 = self.sizes["chunked_entropy.segmap_group_size_7380"]
        max_num_groups_7575 = self.sizes["chunked_entropy.segmap_num_groups_7382"]
        num_groups_7420 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(range_end_7044, segmap_group_sizze_7419),
                    sext_i32_i64(max_num_groups_7575),
                ),
            )
        )
        nest_sizze_7458 = np.int64(256) * range_end_7044
        segred_group_sizze_7459 = self.sizes["chunked_entropy.segred_group_size_7332"]
        max_num_groups_7576 = self.sizes["chunked_entropy.segred_num_groups_7334"]
        num_groups_7460 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(nest_sizze_7458, segred_group_sizze_7459),
                    sext_i32_i64(max_num_groups_7576),
                ),
            )
        )
        segmap_group_sizze_7479 = self.sizes["chunked_entropy.segmap_group_size_7318"]
        segmap_group_sizze_7265 = self.sizes["chunked_entropy.segmap_group_size_7216"]
        bytes_7545 = np.int64(2048) * range_end_7044
        binop_y_7547 = np.int64(4) * range_end_7044
        bytes_7548 = smax64(np.int64(0), binop_y_7547)
        local_memory_capacity_7685 = self.max_local_memory
        if (suff_outer_par_7212 == True) and sle64(
            np.int64(0), sext_i32_i64(local_memory_capacity_7685)
        ):
            segmap_usable_groups_7266 = sdiv_up64(range_end_7044, segmap_group_sizze_7265)
            mem_7564 = opencl_alloc(self, bytes_7548, "mem_7564")
            virt_num_groups_7577 = sext_i64_i32(sdiv_up64(range_end_7044, segmap_group_sizze_7265))
            if (1 * (np.int64(segmap_usable_groups_7266) * np.int64(segmap_group_sizze_7265))) != 0:
                self.chunked_entropyzisegmap_7269_var.set_args(
                    self.global_failure,
                    self.failure_is_an_option,
                    self.global_failure_args,
                    ct.c_int64(n_6950),
                    ct.c_int64(chunk_sizze_6951),
                    ct.c_int64(range_end_7044),
                    xs_mem_7539,
                    mem_7564,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_7269_var,
                    ((np.int64(segmap_usable_groups_7266) * np.int64(segmap_group_sizze_7265)),),
                    (np.int64(segmap_group_sizze_7265),),
                )
                if synchronous:
                    sync(self)
            self.failure_is_an_option = np.int32(1)
            ext_mem_7565 = mem_7564
        else:
            mem_7546 = opencl_alloc(self, bytes_7545, "mem_7546")
            mem_7549 = opencl_alloc(self, bytes_7548, "mem_7549")
            virt_num_groups_7589 = sext_i64_i32(sdiv_up64(range_end_7044, segmap_group_sizze_7419))
            if (1 * (np.int64(num_groups_7420) * np.int64(segmap_group_sizze_7419))) != 0:
                self.chunked_entropyzisegmap_7425_var.set_args(
                    self.global_failure,
                    self.failure_is_an_option,
                    self.global_failure_args,
                    ct.c_int64(n_6950),
                    ct.c_int64(chunk_sizze_6951),
                    ct.c_int64(range_end_7044),
                    ct.c_int64(num_groups_7420),
                    ct.c_int32(virt_num_groups_7589),
                    xs_mem_7539,
                    mem_7546,
                    mem_7549,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_7425_var,
                    ((np.int64(num_groups_7420) * np.int64(segmap_group_sizze_7419)),),
                    (np.int64(segmap_group_sizze_7419),),
                )
                if synchronous:
                    sync(self)
            self.failure_is_an_option = np.int32(1)
            mem_7549 = None
            mem_7553 = opencl_alloc(self, bytes_7548, "mem_7553")
            if slt64(np.int64(512), segred_group_sizze_7459):
                segment_sizze_nonzzero_7606 = smax64(np.int64(1), np.int64(256))
                num_threads_7607 = num_groups_7460 * segred_group_sizze_7459
                if (1 * (np.int64(num_groups_7460) * np.int64(segred_group_sizze_7459))) != 0:
                    self.chunked_entropyzisegred_small_7465_var.set_args(
                        self.global_failure,
                        cl.LocalMemory(np.int64(np.int64(4) * segred_group_sizze_7459)),
                        ct.c_int64(chunk_sizze_6951),
                        ct.c_int64(range_end_7044),
                        ct.c_int64(num_groups_7460),
                        ct.c_int64(segment_sizze_nonzzero_7606),
                        mem_7546,
                        mem_7553,
                    )
                    cl.enqueue_nd_range_kernel(
                        self.queue,
                        self.chunked_entropyzisegred_small_7465_var,
                        ((np.int64(num_groups_7460) * np.int64(segred_group_sizze_7459)),),
                        (np.int64(segred_group_sizze_7459),),
                    )
                    if synchronous:
                        sync(self)
            else:
                groups_per_segment_7634 = sdiv_up64(
                    num_groups_7460, smax64(np.int64(1), range_end_7044)
                )
                elements_per_thread_7635 = sdiv_up64(
                    np.int64(256), (segred_group_sizze_7459 * groups_per_segment_7634)
                )
                virt_num_groups_7636 = groups_per_segment_7634 * range_end_7044
                num_threads_7637 = num_groups_7460 * segred_group_sizze_7459
                threads_per_segment_7638 = groups_per_segment_7634 * segred_group_sizze_7459
                segred_tmp_mem_7639 = opencl_alloc(
                    self, (np.int64(4) * virt_num_groups_7636), "segred_tmp_mem_7639"
                )
                chunked_entropyzicounter_mem_7641 = self.chunked_entropyzicounter_mem_7641
                if (1 * (np.int64(num_groups_7460) * np.int64(segred_group_sizze_7459))) != 0:
                    self.chunked_entropyzisegred_large_7465_var.set_args(
                        self.global_failure,
                        cl.LocalMemory(np.int64(np.int32(1))),
                        cl.LocalMemory(np.int64(np.int64(4) * segred_group_sizze_7459)),
                        ct.c_int64(chunk_sizze_6951),
                        ct.c_int64(range_end_7044),
                        ct.c_int64(num_groups_7460),
                        ct.c_int64(groups_per_segment_7634),
                        ct.c_int64(elements_per_thread_7635),
                        ct.c_int64(virt_num_groups_7636),
                        ct.c_int64(threads_per_segment_7638),
                        mem_7546,
                        mem_7553,
                        segred_tmp_mem_7639,
                        chunked_entropyzicounter_mem_7641,
                    )
                    cl.enqueue_nd_range_kernel(
                        self.queue,
                        self.chunked_entropyzisegred_large_7465_var,
                        ((np.int64(num_groups_7460) * np.int64(segred_group_sizze_7459)),),
                        (np.int64(segred_group_sizze_7459),),
                    )
                    if synchronous:
                        sync(self)
            mem_7546 = None
            segmap_usable_groups_7480 = sdiv_up64(range_end_7044, segmap_group_sizze_7479)
            mem_7557 = opencl_alloc(self, bytes_7548, "mem_7557")
            virt_num_groups_7676 = sext_i64_i32(sdiv_up64(range_end_7044, segmap_group_sizze_7479))
            if (1 * (np.int64(segmap_usable_groups_7480) * np.int64(segmap_group_sizze_7479))) != 0:
                self.chunked_entropyzisegmap_7483_var.set_args(
                    self.global_failure,
                    ct.c_int64(chunk_sizze_6951),
                    ct.c_int64(range_end_7044),
                    mem_7553,
                    mem_7557,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_7483_var,
                    ((np.int64(segmap_usable_groups_7480) * np.int64(segmap_group_sizze_7479)),),
                    (np.int64(segmap_group_sizze_7479),),
                )
                if synchronous:
                    sync(self)
            mem_7553 = None
            ext_mem_7565 = mem_7557
        mem_out_7573 = ext_mem_7565
        prim_out_7574 = range_end_7044
        return (mem_out_7573, prim_out_7574)

    def futhark_entry_entropy(self, xs_mem_7539, n_6801):
        mem_7541 = opencl_alloc(self, np.int64(2048), "mem_7541")
        self.futhark_builtinzhreplicate_i64(mem_7541, np.int64(256), np.int64(0))
        seghist_group_sizze_7187 = self.sizes["entropy.seghist_group_size_7186"]
        max_num_groups_7594 = self.sizes["entropy.seghist_num_groups_7188"]
        num_groups_7189 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(n_6801, seghist_group_sizze_7187), sext_i32_i64(max_num_groups_7594)
                ),
            )
        )
        h_7598 = np.int64(2048)
        seg_h_7599 = np.int64(2048)
        if seg_h_7599 == np.int64(0):
            pass
        else:
            hist_H_7600 = np.int64(256)
            hist_el_sizze_7601 = sdiv_up64(h_7598, hist_H_7600)
            hist_N_7602 = n_6801
            hist_RF_7603 = np.int32(1)
            hist_L_7604 = self.max_local_memory
            max_group_sizze_7605 = self.max_group_size
            num_groups_7606 = sdiv_up64(
                sext_i32_i64(sext_i64_i32(num_groups_7189 * seghist_group_sizze_7187)),
                max_group_sizze_7605,
            )
            hist_m_prime_7607 = sitofp_i64_f64(
                smin64(
                    sext_i32_i64(squot32(hist_L_7604, hist_el_sizze_7601)),
                    sdiv_up64(hist_N_7602, num_groups_7606),
                )
            ) / sitofp_i64_f64(hist_H_7600)
            hist_M0_7608 = smax64(
                np.int64(1), smin64(fptosi_f64_i64(hist_m_prime_7607), max_group_sizze_7605)
            )
            hist_Nout_7609 = np.int64(1)
            hist_Nin_7610 = n_6801
            work_asymp_M_max_7611 = squot64(
                (hist_Nout_7609 * hist_N_7602), ((np.int64(2) * num_groups_7606) * hist_H_7600)
            )
            hist_M_7612 = sext_i64_i32(smin64(hist_M0_7608, work_asymp_M_max_7611))
            hist_C_7613 = sdiv_up64(
                max_group_sizze_7605, sext_i32_i64(smax32(np.int32(1), hist_M_7612))
            )
            local_mem_needed_7614 = hist_el_sizze_7601 * sext_i32_i64(hist_M_7612)
            hist_S_7615 = sext_i64_i32(
                sdiv_up64((hist_H_7600 * local_mem_needed_7614), hist_L_7604)
            )
            if sle64(hist_H_7600, hist_Nin_7610) and (
                sle64(local_mem_needed_7614, hist_L_7604)
                and (
                    sle32(hist_S_7615, np.int32(3))
                    and (
                        sle64(hist_C_7613, max_group_sizze_7605) and slt32(np.int32(0), hist_M_7612)
                    )
                )
            ):
                num_subhistos_7595 = num_groups_7606
                if num_subhistos_7595 == np.int64(1):
                    defunc_1_map_res_subhistos_mem_7596 = mem_7541
                else:
                    defunc_1_map_res_subhistos_mem_7596 = opencl_alloc(
                        self,
                        ((num_subhistos_7595 * np.int64(256)) * np.int64(8)),
                        "defunc_1_map_res_subhistos_mem_7596",
                    )
                    self.futhark_builtinzhreplicate_i64(
                        defunc_1_map_res_subhistos_mem_7596,
                        (num_subhistos_7595 * np.int64(256)),
                        np.int64(0),
                    )
                    if np.int64(2048) != 0:
                        cl.enqueue_copy(
                            self.queue,
                            defunc_1_map_res_subhistos_mem_7596,
                            mem_7541,
                            dest_offset=np.int64(np.int64(0)),
                            src_offset=np.int64(np.int64(0)),
                            byte_count=np.int64(np.int64(2048)),
                        )
                    if synchronous:
                        sync(self)
                chk_i_7616 = np.int32(0)
                one_7791 = np.int32(1)
                for counter_7790 in range(hist_S_7615):
                    num_segments_7617 = np.int64(1)
                    hist_H_chk_7618 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7615))
                    histo_sizze_7619 = hist_H_chk_7618
                    init_per_thread_7620 = sext_i64_i32(
                        sdiv_up64(
                            (sext_i32_i64(hist_M_7612) * histo_sizze_7619), max_group_sizze_7605
                        )
                    )
                    if (1 * (np.int64(num_groups_7606) * np.int64(max_group_sizze_7605))) != 0:
                        self.entropyziseghist_local_7194_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int64(8) * (hist_M_7612 * hist_H_chk_7618))),
                            ct.c_int64(n_6801),
                            ct.c_int32(max_group_sizze_7605),
                            ct.c_int64(num_groups_7606),
                            ct.c_int32(hist_M_7612),
                            ct.c_int32(chk_i_7616),
                            ct.c_int64(num_segments_7617),
                            ct.c_int64(hist_H_chk_7618),
                            ct.c_int64(histo_sizze_7619),
                            ct.c_int32(init_per_thread_7620),
                            xs_mem_7539,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyziseghist_local_7194_var,
                            ((np.int64(num_groups_7606) * np.int64(max_group_sizze_7605)),),
                            (np.int64(max_group_sizze_7605),),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_7616 += one_7791
            else:
                hist_H_7652 = np.int64(256)
                hist_RF_7653 = (np.float64(0.0) + sitofp_i32_f64(np.int64(1))) / np.float64(1.0)
                hist_el_sizze_7654 = np.int32(8)
                hist_C_max_7655 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_groups_7189 * seghist_group_sizze_7187)),
                    (sitofp_i32_f64(hist_H_7652) / np.float64(2.0)),
                )
                hist_M_min_7656 = smax32(
                    np.int32(1),
                    sext_i64_i32(
                        fptosi_f64_i64(
                            sitofp_i32_f64(sext_i64_i32(num_groups_7189 * seghist_group_sizze_7187))
                            / hist_C_max_7655
                        )
                    ),
                )
                L2_sizze_7657 = self.sizes["entropy.L2_size_7657"]
                hist_RACE_exp_7658 = fmax64(
                    np.float64(1.0),
                    (
                        (np.float64(0.75) * hist_RF_7653)
                        / (np.float64(64.0) / sitofp_i32_f64(hist_el_sizze_7654))
                    ),
                )
                if slt64(n_6801, hist_H_7652):
                    hist_S_7659 = np.int32(1)
                else:
                    hist_S_7659 = sext_i64_i32(
                        sdiv_up64(
                            (
                                (sext_i32_i64(hist_M_min_7656) * hist_H_7652)
                                * sext_i32_i64(hist_el_sizze_7654)
                            ),
                            fptosi_f64_i64(
                                (np.float64(0.4) * sitofp_i32_f64(L2_sizze_7657))
                                * hist_RACE_exp_7658
                            ),
                        )
                    )
                hist_H_chk_7660 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7659))
                hist_k_max_7661 = fmin64(
                    (
                        (
                            np.float64(0.4)
                            * (sitofp_i32_f64(L2_sizze_7657) / sitofp_i32_f64(np.int32(8)))
                        )
                        * hist_RACE_exp_7658
                    ),
                    sitofp_i32_f64(n_6801),
                ) / sitofp_i32_f64(sext_i64_i32(num_groups_7189 * seghist_group_sizze_7187))
                hist_u_7662 = np.int64(2)
                hist_C_7663 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_groups_7189 * seghist_group_sizze_7187)),
                    (sitofp_i32_f64(hist_u_7662 * hist_H_chk_7660) / hist_k_max_7661),
                )
                hist_M_7664 = np.int32(1)
                num_subhistos_7595 = sext_i32_i64(hist_M_7664)
                if hist_M_7664 == np.int32(1):
                    defunc_1_map_res_subhistos_mem_7596 = mem_7541
                else:
                    if num_subhistos_7595 == np.int64(1):
                        defunc_1_map_res_subhistos_mem_7596 = mem_7541
                    else:
                        defunc_1_map_res_subhistos_mem_7596 = opencl_alloc(
                            self,
                            ((num_subhistos_7595 * np.int64(256)) * np.int64(8)),
                            "defunc_1_map_res_subhistos_mem_7596",
                        )
                        self.futhark_builtinzhreplicate_i64(
                            defunc_1_map_res_subhistos_mem_7596,
                            (num_subhistos_7595 * np.int64(256)),
                            np.int64(0),
                        )
                        if np.int64(2048) != 0:
                            cl.enqueue_copy(
                                self.queue,
                                defunc_1_map_res_subhistos_mem_7596,
                                mem_7541,
                                dest_offset=np.int64(np.int64(0)),
                                src_offset=np.int64(np.int64(0)),
                                byte_count=np.int64(np.int64(2048)),
                            )
                        if synchronous:
                            sync(self)
                chk_i_7665 = np.int32(0)
                one_7793 = np.int32(1)
                for counter_7792 in range(hist_S_7659):
                    hist_H_chk_7666 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_7659))
                    if (1 * (np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187))) != 0:
                        self.entropyziseghist_global_7194_var.set_args(
                            self.global_failure,
                            ct.c_int64(n_6801),
                            ct.c_int64(num_groups_7189),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int32(chk_i_7665),
                            ct.c_int64(hist_H_chk_7666),
                            xs_mem_7539,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyziseghist_global_7194_var,
                            ((np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187)),),
                            (np.int64(seghist_group_sizze_7187),),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_7665 += one_7793
            if num_subhistos_7595 == np.int64(1):
                mem_7541 = defunc_1_map_res_subhistos_mem_7596
            else:
                if slt64((num_subhistos_7595 * np.int64(2)), seghist_group_sizze_7187):
                    segment_sizze_nonzzero_7682 = smax64(np.int64(1), num_subhistos_7595)
                    num_threads_7683 = num_groups_7189 * seghist_group_sizze_7187
                    if (1 * (np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187))) != 0:
                        self.entropyzisegred_small_7681_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int64(8) * seghist_group_sizze_7187)),
                            ct.c_int64(num_groups_7189),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int64(segment_sizze_nonzzero_7682),
                            mem_7541,
                            defunc_1_map_res_subhistos_mem_7596,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyzisegred_small_7681_var,
                            ((np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187)),),
                            (np.int64(seghist_group_sizze_7187),),
                        )
                        if synchronous:
                            sync(self)
                else:
                    groups_per_segment_7711 = sdiv_up64(
                        num_groups_7189, smax64(np.int64(1), np.int64(256))
                    )
                    elements_per_thread_7712 = sdiv_up64(
                        num_subhistos_7595, (seghist_group_sizze_7187 * groups_per_segment_7711)
                    )
                    virt_num_groups_7713 = groups_per_segment_7711 * np.int64(256)
                    num_threads_7714 = num_groups_7189 * seghist_group_sizze_7187
                    threads_per_segment_7715 = groups_per_segment_7711 * seghist_group_sizze_7187
                    segred_tmp_mem_7716 = opencl_alloc(
                        self, (np.int64(8) * virt_num_groups_7713), "segred_tmp_mem_7716"
                    )
                    entropyzicounter_mem_7718 = self.entropyzicounter_mem_7718
                    if (1 * (np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187))) != 0:
                        self.entropyzisegred_large_7681_var.set_args(
                            self.global_failure,
                            cl.LocalMemory(np.int64(np.int32(1))),
                            cl.LocalMemory(np.int64(np.int64(8) * seghist_group_sizze_7187)),
                            ct.c_int64(num_groups_7189),
                            ct.c_int32(num_subhistos_7595),
                            ct.c_int64(groups_per_segment_7711),
                            ct.c_int64(elements_per_thread_7712),
                            ct.c_int64(virt_num_groups_7713),
                            ct.c_int64(threads_per_segment_7715),
                            mem_7541,
                            defunc_1_map_res_subhistos_mem_7596,
                            segred_tmp_mem_7716,
                            entropyzicounter_mem_7718,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyzisegred_large_7681_var,
                            ((np.int64(num_groups_7189) * np.int64(seghist_group_sizze_7187)),),
                            (np.int64(seghist_group_sizze_7187),),
                        )
                        if synchronous:
                            sync(self)
        i64_res_7114 = sitofp_i64_f32(n_6801)
        segred_group_sizze_7203 = self.sizes["entropy.segred_group_size_7202"]
        max_num_groups_7753 = self.sizes["entropy.segred_num_groups_7204"]
        num_groups_7205 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(np.int64(256), segred_group_sizze_7203),
                    sext_i32_i64(max_num_groups_7753),
                ),
            )
        )
        mem_7545 = opencl_alloc(self, np.int64(4), "mem_7545")
        entropyzicounter_mem_7754 = self.entropyzicounter_mem_7754
        segred_tmp_mem_7756 = opencl_alloc(
            self, (np.int64(4) * num_groups_7205), "segred_tmp_mem_7756"
        )
        num_threads_7758 = num_groups_7205 * segred_group_sizze_7203
        if (1 * (np.int64(num_groups_7205) * np.int64(segred_group_sizze_7203))) != 0:
            self.entropyzisegred_nonseg_7210_var.set_args(
                self.global_failure,
                cl.LocalMemory(np.int64(np.int64(4) * segred_group_sizze_7203)),
                cl.LocalMemory(np.int64(np.int32(1))),
                ct.c_float(i64_res_7114),
                ct.c_int64(num_groups_7205),
                ct.c_int64(num_threads_7758),
                mem_7541,
                mem_7545,
                entropyzicounter_mem_7754,
                segred_tmp_mem_7756,
            )
            cl.enqueue_nd_range_kernel(
                self.queue,
                self.entropyzisegred_nonseg_7210_var,
                ((np.int64(num_groups_7205) * np.int64(segred_group_sizze_7203)),),
                (np.int64(segred_group_sizze_7203),),
            )
            if synchronous:
                sync(self)
        mem_7541 = None
        read_res_7796 = np.empty(1, dtype=ct.c_float)
        cl.enqueue_copy(
            self.queue,
            read_res_7796,
            mem_7545,
            device_offset=(np.int64(np.int64(0)) * 4),
            is_blocking=synchronous,
        )
        sync(self)
        defunc_0_f_res_7165 = read_res_7796[0]
        mem_7545 = None
        x_7129 = np.float32(-1.0) * defunc_0_f_res_7165
        log2_res_7130 = futhark_log2_32(i64_res_7114)
        defunc_0_f_res_7131 = x_7129 / log2_res_7130
        prim_out_7573 = defunc_0_f_res_7131
        return prim_out_7573

    def byte_histogram(self, xs_mem_7539_ext):
        n_6636 = None
        try:
            assert (type(xs_mem_7539_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_7539_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_6636 == None:
                n_6636 = np.int64(xs_mem_7539_ext.shape[0])
            else:
                assert (
                    n_6636 == xs_mem_7539_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_7539_ext) == cl.array.Array:
                xs_mem_7539 = xs_mem_7539_ext.data
            else:
                xs_mem_7539 = opencl_alloc(self, np.int64(xs_mem_7539_ext.nbytes), "xs_mem_7539")
                if np.int64(xs_mem_7539_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_7539,
                        normaliseArray(xs_mem_7539_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_7539_ext), xs_mem_7539_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            mem_out_7573 = self.futhark_entry_byte_histogram(xs_mem_7539, n_6636)
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return cl.array.Array(self.queue, (np.int64(256),), np.int64, data=mem_out_7573)

    def chunked_entropy(self, chunk_sizze_6951_ext, xs_mem_7539_ext):
        n_6950 = None
        try:
            chunk_sizze_6951 = np.int64(ct.c_int64(chunk_sizze_6951_ext))
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "i64", type(chunk_sizze_6951_ext), chunk_sizze_6951_ext
                )
            )
        try:
            assert (type(xs_mem_7539_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_7539_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_6950 == None:
                n_6950 = np.int64(xs_mem_7539_ext.shape[0])
            else:
                assert (
                    n_6950 == xs_mem_7539_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_7539_ext) == cl.array.Array:
                xs_mem_7539 = xs_mem_7539_ext.data
            else:
                xs_mem_7539 = opencl_alloc(self, np.int64(xs_mem_7539_ext.nbytes), "xs_mem_7539")
                if np.int64(xs_mem_7539_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_7539,
                        normaliseArray(xs_mem_7539_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #1 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_7539_ext), xs_mem_7539_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            (mem_out_7573, prim_out_7574) = self.futhark_entry_chunked_entropy(
                xs_mem_7539, n_6950, chunk_sizze_6951
            )
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return cl.array.Array(self.queue, (prim_out_7574,), np.float32, data=mem_out_7573)

    def entropy(self, xs_mem_7539_ext):
        n_6801 = None
        try:
            assert (type(xs_mem_7539_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_7539_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_6801 == None:
                n_6801 = np.int64(xs_mem_7539_ext.shape[0])
            else:
                assert (
                    n_6801 == xs_mem_7539_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_7539_ext) == cl.array.Array:
                xs_mem_7539 = xs_mem_7539_ext.data
            else:
                xs_mem_7539 = opencl_alloc(self, np.int64(xs_mem_7539_ext.nbytes), "xs_mem_7539")
                if np.int64(xs_mem_7539_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_7539,
                        normaliseArray(xs_mem_7539_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_7539_ext), xs_mem_7539_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            prim_out_7573 = self.futhark_entry_entropy(xs_mem_7539, n_6801)
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return np.float32(prim_out_7573)
